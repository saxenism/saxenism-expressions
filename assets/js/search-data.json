{
  
    
        "post0": {
            "title": "ABI Encode - Solidity",
            "content": "Different types of abi encode . Let us see today when and why do we use abi.encode vs abi.encodePacked. . What is a hash function? . A hash function has the following characterisitics: . A function that takes in arbitrary size input and outputs a data of fixed size | Properties: Deterministic hash(x) = h, every time without fail | . | quick to compute the hash | irreversible given h, (really)hard to find x such that hash(x) = h | . | small change in input changes the output significantly hard to find x, y such that hash(x) = hash(y) | . | . | . String Encoding . The solidity built-in function abi.encode enables to encode any Solidity types into raw bytes, that can be interpreted directly by the EVM. . Note that multiple arguments can be given to this function. . So, if we do something like: abi.encode(&quot;Solidity&quot;); . We get the result in the following format: . 1st (32 bytes) word = offset → indicates at which bytes index the string starts. Here 0x20 (in hex) = 32 (in decimals). If you count 32 from the beginning (= index 32), you will reach the starting point of where the actual encoded string starts. . | 2nd (32 bytes) word = string length → in the case of the string, this indicates how many characters (including whitespaces) are included in the string. So simply the “string.length “ . | 3rd (32 bytes) word = the actual utf8 encoded string → each individual bytes corresponds to hex notation of a letter / character encoded in utf8. If you search each individual bytes from 536f6c6964697479 inside an utf8 table, you will be able to decode the string. For instance, 53 corresponds to uppercase S , 6f corresponds to lowercase o , 6c corresponds to lowercase l , etc… . | . The actual encoded bytes would look something like this: . { &quot;0&quot;: &quot;bytes: 0x00000000000000000000000000000000000000000000000000000000000000200000000000000000000000000000000000000000000000000000000000000008536f6c6964697479000000000000000000000000000000000000000000000000&quot; } . The contract code was as straightforward as it gets: . // SPDX-License-Identifier: GPL-3.0 pragma solidity 0.8.7; contract StringEncoding { bytes public encodedString = abi.encode(&quot;Solidity&quot;); } . Few other ABI Encodings . address payable -&gt; address | contract -&gt; address | enum -&gt; uint8 | struct -&gt; tuple of elementry types | . Few points on abi.encode, abi.encodePacked, abi.encodeWithSelector, abi.encodeWithSignature . When using abi.encode, all elementary types are padded to 32 bytes and dynamic arrays include their length. Therefore, it is also possible to decode the resulting hash using abi.decode if the data type is known. | This encoding is done using the ABI specs. | . | When using abi.encodePacked only the minimum possible memory is utilised. Therefore, if you were hashing an address with this function, it will only take up 20 bytes and the rest of the word remains unpadded. | For dynamic types, the offset and the length is not stored. abi.encodePacked(&quot;Solidity&quot;); // returns -&gt; 0x536f6c6964697479 . | . | Since abi.encodePacked is non-standard hashing and uses the least amount of memory, it is usually gas-efficient . | If you are making calls to an (external) contract, you’ll more likely be using abi.encode (because it uses the ABI specs) and when you simply want to save some space and not call a contract, you’ll be using abi.encodePacked. . | If you are dealing with more than one dynamic data types, use abi.encode as it prevents collision. . | Whereas, in multiple dynamic data types there is a good chance of collision happening if used with abi.encodePacked . | abi.encodeWithSignature is the same as abi.encode but the function selector is used as the first parameter. Use when the signature is known and don’t want to calculate the selector. . | abi.encodeWithSelector, almost same as abi.encodeWithSignature but first param is selector. | . Code Examples of the above encode options: . // Case 1 (success, ) = address(c).call(abi.encodeWithSignature(&quot;myfunction(uint256,uint256)&quot;, 400,500)); // Case 2 (success, ) = address(c).call(abi.encodeWithSelector(bytes4(keccak256(&quot;myfunction(uint256,uint256)&quot;)), 400,500)); // Case 3 contract_instance.myfunction(400,500); . Case 3 is more expensive but safer than the other cases. This is because, the EVM considers a call to a non-existing contract to always succeed. Therefore, Solidity includes an extra check using the extcodesize opcode when performing external calls. This ensures that the contract that is about to be called either actually exists (contains code) or an exception is raised. . | . Low level calls (which operate on address rather than a contract instance) ignore this check and therefore become gas efficient but less safe. Eg. call, transfer, delegatecall, staticcall, send. . A very important point to note is: If a function exists such that: function foo(uint256 _a, address _b) { // do something } . | . Then, the function selector for this particular function would be: . bytes4(keccak256(bytes(&#39;foo(uint256,address)&#39;))); // This is correct bytes4(keccak256(bytes(&#39;foo(uint256, address)&#39;))); // This would be incorrect, because of the space between the two param types bytes4(keccak256(bytes(&#39;foo(uint,address)&#39;))); // Again incorrect, because we cannot use the alias of uint, we have to use the entire uint256 . A more comprehensive example from solidity-by-example | . // SPDX-License-Identifier: MIT pragma solidity ^0.8.13; contract Receiver { event Received(address caller, uint amount, string message); fallback() external payable { emit Received(msg.sender, msg.value, &quot;Fallback was called&quot;); } function foo(string memory _message, uint _x) public payable returns (uint) { emit Received(msg.sender, msg.value, _message); return _x + 1; } } contract Caller { event Response(bool success, bytes data); // Let&#39;s imagine that contract B does not have the source code for // contract A, but we do know the address of A and the function to call. function testCallFoo(address payable _addr) public payable { // You can send ether and specify a custom gas amount (bool success, bytes memory data) = _addr.call{value: msg.value, gas: 5000}( abi.encodeWithSignature(&quot;foo(string,uint256)&quot;, &quot;call foo&quot;, 123) ); emit Response(success, data); } // Calling a function that does not exist triggers the fallback function. function testCallDoesNotExist(address _addr) public { (bool success, bytes memory data) = _addr.call( abi.encodeWithSignature(&quot;doesNotExist()&quot;) ); emit Response(success, data); } } .",
            "url": "https://saxenism.com/web3/solidity/hashing/keccak256/abi/2022/08/30/ABI-Encode-Vs-EncodePacked.html",
            "relUrl": "/web3/solidity/hashing/keccak256/abi/2022/08/30/ABI-Encode-Vs-EncodePacked.html",
            "date": " • Aug 30, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "An EVM Deep Dive",
            "content": "EVM-Varta (Let’s talk about the EVM) . Jet: . Yul is part of a greater family of EVM assembly languages . its basically EVM assembly wrapped into a language with some Ssyntactic sugar . What’s great about that is that the only thing you need to write Yul is an understanding of the EVM. Looking at Yul contracts won’t really get you to that point . So, let’s get a bit of a deeper understanding of the EVM . Start a Discussion . Click Here . Index . What is an EVM | The EVM Instruction Set | Ethereum State | Compiling Solidity to EVM Bytecode | Turing Completeness and Gas | Gas | Gas Accounting During Execution | Gas Accounting Considerations | Gas Cost vs Gas Price | Negative Gas Costs (Refunds) | Block Gas Limit | Decisions regarding block gas Limit | Femboy Capital | WIP | . What is an EVM . Consider Ethereum to be a global computer (with each node having its own permanent data store) and EVM is the processor. It basically handles smart contract deployment and execution. It is just a computation engine, and as such provides an abstraction of just computation and storage, similar to Java Virtual Machine(JVM). . The EVM executes its own bytecode intstruction set which higher level smart contract languages such as LLL, Serpent, Mutan or Solidity are compiled into. The EVM does not require to have any scheduling capability because Ethereum clients run through verified block transactions to determine which smart contract needs executing and in which order. This mechanism makes EVM a single-threaded mechanism. . A Turing machine is a finite (there are a limited number of states, such as a coin toss will have only two states: HEADS or TAILS) state machine that has an unlimited supply of paper tape that it can write on and read back. . | The EVM is a quasi-Turing complete state machine. . | Quasi because all execution processes are limited to a finite number of computational steps by the amount of gas available for any given smart contract execution. | . This property: the requirement of a particular amount of gas to execute transactions on the EVM (absence of which leads to halting of execution) helps us do away with the Halting Problem | Note What is the halting problem? . Halting means that the program on certain input will accept it and halt or reject it and halt, but it would never go into an infinite loop. So essentially halting == terminating. . The EVM has a stack-based architecture, storing all in-memory values on a stack. It works with a word size of 256 bits . | EVM has a few addressable data components such as: . An immutable program code ROM (opcodes) | A volatile memory (memory variables probably includes calldata) | A permanent storage (keyword: storage) | . | The EVM Instruction Set (Bytecode operations) . In addition to the typical bytecode operations (arithmetical, logical, memory access, flow control, logging etc), the EVM also has access to account information (address and balance) &amp; block information (current gas price, block number etc) . Arithmetic Operations | ADD //Add the top two stack items MUL //Multiply the top two stack items SUB //Subtract the top two stack items DIV //Integer division SDIV //Signed integer division MOD //Modulo (remainder) operation SMOD //Signed modulo operation ADDMOD //Addition modulo any number MULMOD //Multiplication modulo any number EXP //Exponential operation SIGNEXTEND //Extend the length of a two&#39;s complement signed integer SHA3 //Compute the Keccak-256 hash of a block of memory . Note All arithmetic is performed modulo 2256 (unless otherwise noted), and the also 00 is taken to be 1. . Stack Operations | POP //Remove the top item from the stack MLOAD //Load a word from memory MSTORE //Save a word to memory MSTORE8 //Save a byte to memory SLOAD //Load a word from storage SSTORE //Save a word to storage MSIZE //Get the size of the active memory in bytes PUSHx //Place x byte item on the stack, where x can be any integer from // 1 to 32 (full word) inclusive DUPx //Duplicate the x-th stack item, where x can be any integer from // 1 to 16 inclusive SWAPx //Exchange 1st and (x+1)-th stack items, where x can be any // integer from 1 to 16 inclusive . Process Flow Operations | STOP //Halt execution JUMP //Set the program counter to any value JUMPI //Conditionally alter the program counter PC //Get the value of the program counter (prior to the increment corresponding to this instruction) JUMPDEST //Mark a valid destination for jumps . System Operations | LOGx //Append a log record with x topics, where x is any integer //from 0 to 4 inclusive CREATE //Create a new account with associated code CALL //Message-call into another account, i.e. run another //account&#39;s code CALLCODE //Message-call into this account with another //account&#39;s code RETURN //Halt execution and return output data DELEGATECALL //Message-call into this account with an alternative //account&#39;s code, but persisting the current values for //sender and value STATICCALL //Static message-call into an account REVERT //Halt execution, reverting state changes but returning //data and remaining gas INVALID //The designated invalid instruction SELFDESTRUCT //Halt execution and register account for deletion . Logic Operations | LT //Less-than comparison GT //Greater-than comparison SLT //Signed less-than comparison SGT //Signed greater-than comparison EQ //Equality comparison ISZERO //Simple NOT operator AND //Bitwise AND operation OR //Bitwise OR operation XOR //Bitwise XOR operation NOT //Bitwise NOT operation BYTE //Retrieve a single byte from a full-width 256-bit word . Environmental Operations | GAS //Get the amount of available gas (after the reduction for //this instruction) ADDRESS //Get the address of the currently executing account BALANCE //Get the account balance of any given account ORIGIN //Get the address of the EOA that initiated this EVM //execution CALLER //Get the address of the caller immediately responsible //for this execution CALLVALUE //Get the ether amount deposited by the caller responsible //for this execution CALLDATALOAD //Get the input data sent by the caller responsible for //this execution CALLDATASIZE //Get the size of the input data CALLDATACOPY //Copy the input data to memory CODESIZE //Get the size of code running in the current environment CODECOPY //Copy the code running in the current environment to //memory GASPRICE //Get the gas price specified by the originating //transaction EXTCODESIZE //Get the size of any account&#39;s code EXTCODECOPY //Copy any account&#39;s code to memory RETURNDATASIZE //Get the size of the output data from the previous call //in the current environment RETURNDATACOPY //Copy data output from the previous call to memory . Block Operations | BLOCKHASH //Get the hash of one of the 256 most recently completed //blocks COINBASE //Get the block&#39;s beneficiary address for the block reward TIMESTAMP //Get the block&#39;s timestamp NUMBER //Get the block&#39;s number DIFFICULTY //Get the block&#39;s difficulty GASLIMIT //Get the block&#39;s gas limit . Ethereum State . The job of the EVM is to update the Ethereum state by computing valid state transactions as a result of smart contract code execution. Therefore, Ethereum can be considered a transaction-based state machine since external actors (ie account holders and miners) initiate state transitions by creating, accepting and ordering transactions. . At the top level, we have the Ethereum world state. The world state is a mapping of Ethereum addresses (160-bit values) to accounts. At the lower level, each Ethereum address represents an account comprising an Ether balance, a nonce (reps the number of txn successfully if EOA or the number of contracts created, if a contract), the account’s storage, and account’s code. An EOA will always have no code and an empty storage. . For a transaction resulting in a smart contract code execution, you can think of the EVM running on a sandboxed copy of the Ethereum world state, with this sandboxed version being discarded completely if execution cannot complete for whatever reason (Eg OOG exception). However if the execution does complete successfully, then the real-world state is updated to match the sandboxed version, including any changes to the called contract’s storage data, any new contracts created, and any ether balance transfers that were initiated. . Note Gas is deducted even in cases of failed execution, because as the code exection progresses, the gas gas supply is reduced according to the gas cost of the operations executed. If at any point the gas supply is reduced to zero we get an “Out of Gas” (OOG) exception; execution immediately halts and the transaction is abandoned. No changes to the Ethereum state are applied, except for the sender’s nonce being incremented and their ether balance going down to pay the block’s beneficiary for the resources used to execute the code upto the halting point. . A contract can call other contracts, with each call resulting in another EVM being instantiated around the new target of the call. Each instantiation has its sandbox world state initialized from the sandbox of the EVM at the level above. . Compiling Solidity to EVM Bytecode . This section basically explains how the opcodes are arranged in stack and how they operate. Things like DUP1, PUSH1, JUMPI, EQ, LT, MLOAD etc are used to demonstrate how a program is executed in the EVM. . Note There is an important but subtle difference between the code used when creating and deploying a new contract on the Ethereum platform and the code of the contract itself. In order to create a new contract, a special transaction is needed that has its to field set to the special 0x0 address and its data field set to the contract’s initiation code. When such a contract creation transaction is processed, the code for the new contract account is not the code in the data field of the transaction. Instead, an EVM is instantiated with the code in the data field of the transaction loaded into its program code ROM, and then the output of the execution of that deployment code is taken as the code for the new contract account. This is so that new contracts can be programmatically initialized using the Ethereum world state at the time of deployment, setting values in the contract’s storage and even sending ether or creating further new contracts. . To get examples on this, the ethereum mastery book is good. . And an awesome resource to pick up how EVM opcode works is this presentation from Ethereum Engineering Group . PS: I made some notes from this YT talk. You can see them here . Turing Completeness and Gas . We have already discussed how the Ethereum Virtual Machine is a quasi-Turing-complete machine since it solves the halting problem. . One more interesting point to note is what happens when a (apparently rich af) attacker supposedly offers infinite gas and asks the EVM to do infinite computations? Well, if after a prespecified maximum amount of computation has been performed, the execution hasn’t ended, the execution of the program is halted by the EVM. That limit isn’t fixed in Ethereum—you can pay to increase it up to a maximum (called the “block gas limit”), and everyone can agree to increase that maximum over time. Nevertheless, at any one time, there is a limit in place, and transactions that consume too much gas while executing are halted. . Gas . Gas is the cost to for on-chain computation and storage. . Each operation performed by a transaction or contract costs a fixed amount of gas. Example: . Addition costs 3 gas | Keccak-256 costs 30 gas + 6 gas for each 256 bits of data being hashed | Sending a transaction costs 21,000 gas | Gas serves two purposes: . Prevents DoS attacks, first by making it financially infeasible and then asking the tx.origin to set a limit to the gas they are willing to pay. | Providing reward to miners (as a hedge against volatile ETH prices) | Gas Accounting During Execution . In the first instance, the EVM is provided with the gas supply equal to the amount specified by the gas limit, and all steps that can be performed with that amount of gas, are performed. . If all the steps were performed, any remaining gas is sent to the sender in form of Ether . refunded ether = remaining gas * gas price . And in either case, the miner gets paid (in ether) because the computations were done in both cases . miner fee = gas cost * gas price . Gas Accounting Considerations . The objective is matching gas cost of transactions to the real-world cost of resources. . Gas Cost vs Gas Price . Gas cost is the number of units of gas required to perform a particular operation. . | Gas price is the amount of ether you are willing to pay per unit of gas when you send your transaction to the Ethereum network. . | . Negative Gas Costs (Refund) . Deleting a contract (SELFDESTRUCT) is worth a refund of 24,000 gas. . | Changing a storage address from a nonzero value to zero (SSTORE[x] = 0) is worth a refund of 15,000 gas. . | . Block Gas Limit . The block gas limit is the maximum amount of gas that may be consumed by all the transactions in a block, and constrains how many transactions can fit into a block. . The block gas limit on the Ethereum mainnet is 8 million gas at the time of writing according to https://etherscan.io, meaning that around 380 basic transactions (each consuming 21,000 gas) could fit into a block. . Decisions regarding block gas limit . The miners on the network collectively decide the block gas limit. Individuals who want to mine on the Ethereum network use a mining program, such as Ethminer, which connects to a Geth or Parity Ethereum client. The Ethereum protocol has a built-in mechanism where miners can vote on the gas limit so capacity can be increased or decreased in subsequent blocks. The miner of a block can vote to adjust the block gas limit by a factor of 1/1,024 (0.0976%) in either direction. The result of this is an adjustable block size based on the needs of the network at the time. This mechanism is coupled with a default mining strategy where miners vote on a gas limit that is at least 4.7 million gas, but which targets a value of 150% of the average of recent total gas usage per block (using a 1,024-block exponential moving average). . ` End of Ethereuem Book ` . Femboy Capital (Definitely not as detailed as the Ethereum book) . Will only include small piece of information from this source which add more clarity to already discussed topics or something that might have been missing above. . The EVM keeps track of the specific section of the bytecode it is currently executing with a pointer called the Program Counter (PC) | A VM execution loop looks something like this: Fetch the instruction the PC points to | Execute the instruction | If the instruction jumps, set the PC to the new target | Otherwise, increment the PC | . | The stack can accomodate a maximum of 1024 elements and each element (word) being 256 bits long | This is a good image to visualize memory and storage inside of Ethereum | . . And this image is a good way to visualize how programs are executed in the EVM: | . . Storage in the EVM operates as a map of 32 byte keys to 32 byte values. It is persistent, meaning that the current storage state sticks around even after contract exectuion completes (STOP or RETURN is called). Any subsequent runs of a contract will have read and write access to the same storage space. There is no opportunity for data races because the EVM does not currently support concurrent execution of a single contract - all transactions are executed sequentially. . | SSTORE cost a whopping 22100 gas! SLOAD cost 100. Reading and writing to storage is very expensive. . | . WIP . About Yul (picked from documentation itself) . Yul provides for loops, if and switch statements | No explicit statements for SWAP, DUP, JUMPDEST, JUMP and JUMPI are provided (as they obfuscate data flow and control flow) | Statements such as mul(add(x, y),z) are preferred over 7 y x add mul, because it becomes easier to see which opcode is being used for which operand | Yul is desigend for a stack based machine (EVM) but it does not expose the programmer to the complexity of the stack itself | Yul is statically typed, but also there is a default type (integer word of the target machine) that can be omitted. | Yul does not have any built-in operations, functions or types in its pure form. 6.1 There exists only one specified dialect of Yul (EVM dialect) and that uses the EVM opcodes as builtin functions and defines only the type u256 (native 256-bit type of EVM) |",
            "url": "https://saxenism.com/evm/solidity/security/deep-dive/evm-internals/2022/08/29/All-About-EVM.html",
            "relUrl": "/evm/solidity/security/deep-dive/evm-internals/2022/08/29/All-About-EVM.html",
            "date": " • Aug 29, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Smart Contract Development - Best Practices",
            "content": "General Contract Development Guidelines (Best Practices) . Smart contract programming requires a different engineering mindset than what you may be used to. . The cost of failure is high and changes can be difficult, making it in some ways similar to hardware programming or financial services programming rather than web or mobile app development. . It is therefore not enough to defend against known vulnerabilities. Instead you will need to learn a new philosophy of development. . Prepare for Failure . Place circuit breakers | Manage money at risk (rate limiting, maximum usage,etc) | Effective mechanism for proxy upgrades | . Stay up to Date . Check your contracts for any new bug as soon as it is discovered | Keep on upgrading all tools and libraries | Adopt new security techniques that emerge (and seem useful) | . Keep it simple . Keep contract logic simple. Modularize code. Use already written code, use as many lego blocks as you can, before writing custom logic | Clarity over performance (Debatable) For example one could argue that the OpenSea Seaport contract is so damned performant that it affects the auditability of the contracts. But realise the fact that the Seaport contract will be deployed on the Ethereum mainnet and will be used to mint hundereds of thousands of NFTs, saving the users millions of dollars over the course of time. . So, based on the nature of your contract, do have healthy, sane discussions on whether you will place more impetus on performance or clarity. . | Roll out in phases. Have a bug bounty in place, test your code-base thoroughly and immediately add relevant tests to your codebase as soon as a new attack is discovered. | . Blockchain Properties . Randomness can be gamified. | Timestamps are imprecise. Miners can influence the time of execution of a txn within a margin of several seconds | Beware of external calls. Private data is not actually private and public functions can be called by anyone in any order. | Prefer reusing contract code only when you have proven previously-deployed contracts which you own. Otherwise go for duplication of code. Efforts such as OpenZeppelin’s Solidity Library seek to provide patterns such that secure code can be re-used without duplication . | . Development best practices: . External Calls . External calls are very risky. Try and avoid doing that, prefer duplicating code over using a call to an external contract. | And when you absolutely have to do that, make sure that the contract is owned/maintained/managed by a trusted party. | Always mark your function making external calls as unsafe via comments and naming convention | Avoid making state changes after the external call. The usual re-entrancy attack and following the check-effects-interactions pattern circus. | . | Prefer call over transfer and send. transfer and send forward exactly 2300 gas to the recipient. This was done to limit the reentrancy vulnerability. However, post the Instanbul hard fork, the cost of SLOAD operation was increased and it made it quite possible that 2300 gas might not be enough for the contract to carry out the logic in its fallback function | But with the same fact, we also have a benefit here that, these methods can act as a filter to ensure that only EOA’s can call the withdraw function instead of contracts. | Therefore, it is a matter of design choice rather than a best practice in this case. | . | A disadvantage of using call is that it does nothing to mitigate the reentrancy attack and that attack has to be handled separately. | . | For low-level call methods(call, callcode, delegatecall), always handle the case of your call failing by checking the return value. | . Example: . someAddress.call.value(100)(bytes(sha3(&quot;deposit()&quot;))); // If deposit throws an exception, the raw call() will only return false and transaction will NOT be reverted . Avoid combining multiple ether transfers in a single transaction. Favor pull over push for external calls. . | delegatecall is made by the caller contract to a callee as if the callee was the same contract. Therefore, we must remain vigilant with delegatecall as it can modify the state of the caller contract. . | . Example: . contract OneBeingCalled { function doSomeGoodWork() external { selfdestruct(0); } } contract OneWhoCalled { function outsourceSomeGoodWork(address _callee) public { _callee.delegatecall(bytes4(keccak256(&quot;doSomeGoodWork()&quot;))); } } . Force Feeding Ether . Do not rely on address(this).balance for your contract logic because it is possible to force send Ether to any contract. . | The contract can implement a fallback function that does a revert, but it will not be able to stop these three method of force sending Ether: . Attacker creates a contract, funds it and calls selfdestruct(victimAddress) | Attacker is a miner, wins some block reward and redirects the award to your address | Attacker pre-computes your contract address and sends some Ether to it even before the victim contract is deployed. | . | . Public on-chain Data . Applications like On Chain Rock-Paper-Scissors require submitted data (player’s move) to be private until some point in time in order to work. . | The best strategy to use here is to use commitment scheme with separate phases: commit phase and then the reveal phase. . | Also, don’t implement your own random number generator. Ethereum is a deterministic protocol, so no variable within this protocol can be used as an unpredictable random number. . Miners can influence the block.blockhash() value . | .",
            "url": "https://saxenism.com/markdown/smart-contract/solidity/security/development/best-practices/2022/08/28/General-Contract-Development-Guidelines.html",
            "relUrl": "/markdown/smart-contract/solidity/security/development/best-practices/2022/08/28/General-Contract-Development-Guidelines.html",
            "date": " • Aug 28, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "DeFi TITS - A Primer on Testing",
            "content": "The International Testing Standard (TITS) for DeFi . DeFi Testing is broken. Doesn&#39;t matter how many auditors had a stab at your protocol, if you haven&#39;t sufficiently tested your protocol, you are basically gambling with your user&#39;s funds. Creating a repo to publicly critique the quality of the test suite of major DeFi protocols. . &mdash; Rahul Saxena 🦀🦀 (@saxenism) July 27, 2022 Mission Statement . I believe that protocols need to be held to a higher standard of testing. Web3 protocols are decentralised, therefore there are no centralised authorities, and subsequently there is no regulatory pressure on the protocols to do quality checks on their protocols. . Is this an issue? YES Is this a big issue?YES . Why? . Well, because, speaking strictly from an economic perspective, it makes much more sense for a protocol to use its time and developer resources on shipping a v2 of their protocol once the initial set of smart contracts are coded rather than spending it on testing their protocol. The protocols presently, try to, conviniently shift the burden of testing and quality assurance on the auditing firms and sometimes on insurance firms. However, Auditing + Insurance is still not enough to offer the level of peace of mind that people should have on software that handles their money. . Therefore, the development team, that is the most intimately familar with the code base, must make it a sacred duty of theirs (just like doctors take the Hippocratic Oath) to test their code to the best of knowledge and ability. . All in all, these softwares (DeFi protocols) handle the hard earned money of everyday Joes like you and me (and also money of stupid funds like 3AC, but yeah, you get the point) so, we cannot let the protocols continue with lax testing, because not everything can and should be viewed with an economic lens, somethings should exist simply because of personal or community ethics. . It does not matter (much) how many auditors have had a stab at your protocol, you, as a developer, do not really understand if your protocol really works and is robust enough to take on the uncertainities of the real world if you have not tested your protocol thoroughly. . Therefore, with this repository, I aim to create a certain set of testing standards that all DeFi protocols should strive to meet. . I plan to create this set of standards via iterations. Iterations of publicly critiquing leading DeFi protocols that are in use today, so that the up and coming protocols in the same space can get an idea and inspiration for the level of testing that the entire community expects out of a protocol that claims to handle money. . List of protocols being evaluated . Maple Finance | Random tid bits about traditional testing that I have picked up… . This is definitely not molded for web3 yet, but consider this a good starting point if you haven’t formally studied Software Engineering. . Testing of software is an extremely imaginative and cognitively demanding task, more so in DeFi. So let your imagination go wild and gather ideas regarding testing from any walk of life, science, religion, parenting, social sciences, etc. Just about everything is fair game in testing. . 1. Old wisdom related to testing . 1.1 Presence of bugs . Testing can esure that defects are present but it cannot prove that a particular software is bug-free. Which isn’t something super nice, but I’m coping too. . 1.2 None can do exhaustive testing . Your software can never be tested for every imaginable and possible test cases. Trust me fellow crypto bro, you cannot. . 1.3 Test Early . Earlier you test, lesser you’ll cry. . 1.4 Defect Clustering . Pareto principle but for origin of software bugs. . 1.5 Pesticide Paradox . Don’t be an idiot and test the same thing over and over with different methods. Find novel ways to screw with your protocol. . 1.6 Testing is context-dependent . Every protocol does something special. Test the shit out of that. . 1.7 Absence of errors fallacy . Just like your hot and caring girlfriend, a 100% bug-free software exists only in your imagination. . 1. Why testing is important . Saves you and your users from getting rekt. | Hoping for your protocol’s success without adequate testing is like going into a gunfight without a bulletproof vest and hoping you don’t get shot. | Time and effort spent on testing can be leveraged to get better terms when you get your protocol insured. | In short, you’ll get your lambo only wen you test. | . Thank you for coming to my TED talk. Bye. . Types of testing . Functional and Non Functional . Non Function includes . Testing the Documentation (which includes) Instructions | Examples | Messages | Samples | . | Installation Testing | Performance Testing Load Testing | Spike Testing | Stress Testing | Endurance Testing | . | Reliability Testing Feature Testing | Regression testing | Load Test | Objectives Testing | . | Security Testing (web2 stuff) Access to application | Data Protection | Brute FOrce | SQL Injection | Service Point | Session Management | Error Handling | Specific Risky Functionalities | . | . 2. SDLC . Requirement | Analysis (outcome from this phase is SRS) | Design (HLD and LLD) | Coding | Testing | Deployment and all | . 2.1 Waterfall Model . Sequential design process. One way street, so back tracking is not possible. . . 2.2 Spiral Model . Combination of iterative development process model and sequential linear development model. . . 3. Validation vs Verification . Verification Validation . Methods involve: review, inspection, unit testing &amp; integration testing | Involves testing the entire system (system testing) | . Usually done by developers while developing | Usually done by tester and after developing of the product by developers | . Concerned with the phase containment of errors | Concerned with making the final product error free | . Involves static and dynamic analysis of code | Involves only dynamic analysis of code | . 4. Types of software testing . 4.1 Unit Testing . Can be done in the development phase itself. Unit means a particularly small piece of (preferrably independent) code such as a function, small module etc. . Smallest element of the software is a unit and testing each of those units is unit testing. . 4.2 Integration Testing . Combine different units of code and test whether they work together as expected to produce the desired output or not. . 4 common integration testing startegies are as follows: . 4.2.1 Big Bang Testing . All units are linked at once, resulting in a complete system. Here, it is difficult to isolate any errors found. . 4.2.2 Top Down . Higher level modules are tested first after which the lower level modules are tested. Higher level modules refer to the main modules and lower level refers to the sub modules. . Stubs (temporary modules) are used to simulate the behaviour of the lower-level modules that are not yet integrated. . Used when software needs to interact with an external system. . 4.2.3 Bottom Up . Lower level modules are tested first and then the higher level modules. . This approach uses test drivers which are mainly used to initiate and pass the required data to the sub modules, implying we pass mock data that should ideally have come from (the not yet implemented) higher modules. . 4.2.4 Mixed (Sandwiched integration testing) . A mixed integration testing follows a combination of top down and bottom-up testing approaches. . 4.3 System Testing or End-to-End Testing . Testing the entire system. Here, we navigate all the necessary modules of an application and check if the end features or the end business works fine, and test the product as a whole system. . 4.3.1.1 Alpha Testing . The testers are people who have built the product. | Done before releasing the product. | Involves both white box and black box testing | . 4.3.1.2 Beta Testing . Beta testing is performed by a select set of clients who are not part of the organization. | User input on the product is collected to ensure the product is ready for real time users | Commonly involves only black box testing | . 4.3.2 Acceptance Testing . It is a formal testing according to user needs, requirements and business processes conducted to determine whether a system satisfies the acceptance criteria or not and to enable the users, customers or other authorized entities to determine whether to accept the system or not. . Smoke Testing or Build Verification Testing . Subset of acceptance testing | . Smoke Testing Sanity Testing . Smoke testing is done to assure that the acute functionalities of program is working fine. | Sanity testing is done to check the bugs have been fixed after the build. | . Smoke testing is documented. | Sanity testing isn’t documented. | . Smoke testing is done to measures the stability of the system/product by performing testing. | Sanity testing is done to measures the rationality of the system/product by performing testing. | . Smoke testing can be performed either manually or by using automation tools. | Sanity testing is commonly executed manually, not by using any automation approach. | . Smoke testing is used to test all over function of the system/product. | Sanity testing is used in the case of only modified or defect functions of system/products. | . Smoke testing is performed when new product is built. | Sanity testing is conducted after the completion of regression testing. | . 4.3.3 Mutation Testing . Type of white box testing | Extremely costly and time consuming but also extremely efficient in finding errors and ambiguities | In this type of testing, you slightly change the value/logic/statements in your code and see if you get the expected output in your tests | . 4.3.4 Performance / Non functional Testing . Non-functional testing is defined as a type of software testing to check non-functional aspects of a software application. It is designed to test the readiness of a system as per nonfunctional parameters which are never addressed by functional testing. . This testing tests the following things (among others): . Volume | Load | Stress | Security | Configuration | Compatibility (BrowserStack :P) | Recovery | Installation etc | . 4.3.5 Recovery Testing in Software Testing . Recovery testing is a type of system testing which aims at testing whether a system can recover from failures or not. | To ensure that a system is fault-tolerant and can recover well from failures, recovery testing is important to perform. | . 4.4 Regression Testing . Regression testing is the process of testing the modified parts of the code and the parts that might get affected due to the modification to ensure that no new errors have been introduced in the software after the modifications have been made. . 4.4.1 Techniques for the selection of test cases for regression testing . Select all test cases (Most thorough but inefficient approach) | Select test cases randomly (Dangerous approach) | Select modification traversing test cases (Huge upfront work required to identify these test cases) | Select higher priority test cases (Assign priority values to all your tests, then re-test all your highest priority tests) | . 4.4.2 Sanity Testing . Subset if regression testing | Done to ensure that the code changes that have been made are working properly or not | Focus of the team during sanity testing is to validate the functionality of the application and not detailed testing | Usually performed on builds where the production deployment is required immediately like a critical bug fix. | Performed only after the software product has passed the smoke test and the QA team has accepted for further testing | . 5. STLC (Software Testing Life Cycle) . Requirement Analysis (Truly truly understand what your protocol is supposed to do) | Test Planning / Strategy Phase (Based on the context of the protocol in question, zero in on a testing strategy) | Test Case Development (This should take the maximum amout of time. List down all test cases that you think are appropriate.) | Environment Setup (Independent of other stages) (Don’t tell me you don’t already have Forge installed) | Test Execution (Code up all the test cases you came up with earlier. You can do back and forth between Test Execution and Case Development phase, but try to keep it minimal) | Test Cycle Closure (Create a good report. Remember, chads keep their work presentable) | . 6. Non Functional Testing . This is based on customer expectations as opposed to functional testing which is based on customer requirements. | Non functional testing describes how the product works rather that what the product does | Includes things like performance testing, scalability, volume testing, load testing, stress testing etc. | . 6.1 Performace Testing . Ensures software application will perform well under their expected workload | Goal is not to find bugs but to elimiate performance bottle-necks | Provides accurate information about the speed, scalability and stability of the software | Types of performance testing types Load Testing (Multiple users access application simultaneously) | Stress Testing | Endurance Testing | Spiking Testing | Volume &amp; Scalability Testing | . | Pay attention to: Long load time | Poor response time | Poor scalability | Bottlenecking | . | Examples of performance Test cases: Verify response time is not more than 4 seconds when 1000 users access the website simultaneously | Check the maximum number of users that the application can handle before it crashes | Verify response time of the application under low, normal, moderate and heavy load conditions | . | . 6.2 Cross browser Tests and Mobile Testing and API Testing . See if this is applicable and test if you have the resources to do so. . Types of API Testing . Functionality Testing | Reliability Testing | Load Testing | UI/UX Testing | Interoperability Testing | Security Testing | Penetration Testing | Negative Testing | . 7. Agile Testing (Test Driven Development (TDD)) . Testing is continuous | Continuous Feedback | Decreased time of feedback response | Less documentation | Test Drive | Simplified Code | . . 7. Software Testing Documentation . 7.1 Test Plan . Provides the outline strategy which will be implemented for testing the application and also the resources that will be required. Test environement will also be described. . Make sure that you also set up a defect/bug life cycle . 7.2 Test Scenario . Notifies the area in which your application will experiment . 7.3 Test Case . Collected steps and conditions with inputs that can be implemented at the time of testing. . 7.4 Traceability Matrix . A table where you can relate test case IDs with protocol requirement IDs. . 8. Defect Management Process (What to do when you find bugs) . Detect the defect | Formulate the bug report | Fix bug | Bug list creation (so that, yk, history doesn’t repeat itself and everyone sees that you have 3 brain cells) | . It is important to note in the first two points, whenever you encounter a bug, you have to reach to the root cause of the bug and report that. Because, it is very much possible that the actual coding error that caused the bug might create many more bugs in the future. . In short, treat the root cause and not just the symptoms. . 9. When to choose manual testing . 9.1 Exploratory Testing . Carried out by domain experts. Minimal planning . 9.2 Usability Testing . User friendliness of an app . 9.3 Ad Hoc Testing . Informal testing. No documents are followed. . 9.4 How to do manual testing . Understand the requirements | Write the test cases | Conducting the tests | Log Good Bug Reports | Report the results (Detailed test report) | What to automate? . Repetitive Task | Capturing Results | Data Entry Tasks | Timing or Screening Responsiveness | Non functional Testing | Environment Setup/Tear down | . Approaches to Test Automation (Look them up) . Code driven Testing | Graphical User Interface | Framework Approach Linear Scripting framework | Data driven framework | Keyword driven framework | Modular testing framework | Hybrid Testing Framework | . | .",
            "url": "https://saxenism.com/defi/testing/web3/forge/defi-tits/2022/08/28/A-Primer-To-Testing.html",
            "relUrl": "/defi/testing/web3/forge/defi-tits/2022/08/28/A-Primer-To-Testing.html",
            "date": " • Aug 28, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Maple Finance - An overview",
            "content": "Maple Finance: A brief overview . To get a detailed idea about Maple visit: . Maple Official Wiki . Brief Overview: Maple Finance . Decentralised corporate credit market protocol. Note This is a decentralised protocol but not trustless, since we always HAVE to assume Pool Delegates to be fair and non-malicious actors . | Borrowers can leverage their reputations to get undercollateralized loans over time. They do so by getting access to capital pools of different Pool Delegates after liaisoning with them. . | Interest Compounds: Interest is accrued and reinvested to enable capital to compound over time . | Pool Delegates carry out the entire due diligence. Lenders chill out. LPs (Lenders) earn revenue by claiming interest generated by the pool. . | Pool Delegates use Maple to attract funds, crack good deals with blue chip borrowers and then earn good performance fee. But they have to stake a good amount of MPL-USDC 50-50 BPTs (Balancer Pool Tokens) so that their incentives are aligned with the LPs. . | After agreeing on terms with a borrower, one or more Pool Delegates will fund the loan with funds available in their pools. . | Stakers are MPL holders and deposit BPT as first loss reserve against loan defaults. BPTs are burned to cover the shortfall after liquiditing the collateral of a borrower. . | Concept of ideal collateral ratio, grace period, late fee and liquidation post grace period exists. . | Governor is a multi-sig wallet that controls the administrative functions in the protocol (admin) . | Contract Instance Admins or local admins are admins for a particular task. Eg. These admins are set by: Governor in case of factories | Pool Delegate in case of a Pool | Borrower in case of a loan | . | Protocol Admin/Global Admin: Can call only one function, that pauses every outward facing function of the protocol. Called only when things have got really bad. | Maple Protocol Architecture . The architecture is pretty straightforward. Doesn’t need much explaining. . There is a Pool Factory, which will create Pools, which will be managed by Pool Delegates. Simple. Each pool will have a Liquidity Locker (created from its factory) to store the pool’s liquidity | Each pool will have a Debt Locker (created from its factory) to store the debt that is given out from that particular pool | Each pool will have a Stake Locker (created from its factory) for the Pool Delegate to stake their MPL-USDC BPT tokens. This is where the stakers would also stake their tokens. | Each pool will generate some MPL rewards as a result of this staking and will be distributed among the LPs. | . | Similarly there is a Loan factory, which will be used by Borrowers to create Loan requests(contracts). Simple Each loan will have a Collateral Locker (created from its factory) to store the borrower’s collateral | Each loan will have a Funding Locker (created from its factory) which I am not sure why it exists. Probably to store the repaid amount? IDK | . | Ofcourse Chainlink oracles are being used to fetch prices and execute functions dependent on price action. | . Security Considerations: . Pool Delegates are supposed to be trusted actors. Can’t really do anything if they turn out to be malicious. | dapp.tools (HEVM) has been used for extensive unit testing + fuzzing If you know anything James Bach, you’ll know that he’ll call this checking rather than actual testing. And this is what basically interests us here. . | External code audits by Deduab, PeckShield, TrailOfBits, Code4rena. | 2 week internal audit by the Maple team This kind of audit is often susceptible to developer biases. But it is complimented by external audits here… So, shouldn’t be much of an issue. Anyway, we are still more interested in testing rather than the auditing and the plethora of audit reports of Maple. . | OZ Defender is in use to inform of any emergencies. | Incase of a oracle outage, all transactions requesting asset prices will be reverted. Manual override possible. Hmm interesting claim. Will be fun to check this. . | Incase of emergencies, contract instance admins (local admins) and/or protocol admins/global admins will come into play. | Smart contract logic that is deployed on the mainnet cannot be altered in any way. Fuck proxies. This is good. Significantly reduces the surface area of possible attacks. . | Understanding Pools . If as a LP or staker you want to withdraw your funds, you’ll first have to trigger a cooldown function and wait for it get over before you can withdraw your funds or even cancel your staking as a staker. . In the following image it is not depicted properly, but the Pool Delegate also has to stake a shit ton of BPTs to be whitelisted as a Pool Delegate by the MapleDAO in the first place. . . Understanding Loans . The Loan contracts are created by Borrowers out of the LoanFactory contracts, which are whitelisted in MapleGlobals to ensure that only certain types of Loan contracts are used in the protocol. . | Loan contracts are used to: Set terms such as: | . APR, Payment Interval Length, Term Lenght, Collateral Ratio, Collateral and Borrow asset, etc. + Receiving capital from lenders + Withdrawing the loan + Interest Payments + Liquidating Collaterals | . | Important point to note is the use of Payment Calculators. These are used to calculate interest payments, late fees, premium fees etc. These are also whitelisted in the MapleGlobals to ensure no malicious payment calculators are used. | At first glance this looks like a whitelisted library which will be used for calculations based on the specifications of the loans, such as simple/compound interest. This also means that no calculation would be happening inside of the Loan contract . Need to check if these calculation libraries can somehow be tampered with. . A Loan can be funded by any number of pools, but those pools must be instantiated from PoolFactory contract itself. The LPs get LoanFDTs. | LoanFDTs are similar to LP Tokens as they represent a claim over a part of principal plus any proportional interest that gets generated. . LoanFDTs that Maple is using isn’t the same old ERC20, they are using a relatively unknown ERC2222 standard. Need to check that thoroughly then. . Borrowers can drawdown any amount that is both above the request Loan amount, and below the current balance of the FundingLocker. | The question here is, why would Maple allow lenders to deposit funds in the Loan contract past their requested amount? Wouldn’t that essentially be wasted amount? . At the time of the drawdown: a percentage of the drawdown amount is paid to the MapleTreasury from the FundingLocker as the treasury fee. | investor fee is paid to the lenders (a % of the drawdown amount). Sent from FundingLocker to the Loan to be claimed by the lenders. Seems a bit off. Investigate again. . | Drawdown minus fee is transferred to the Borrower | . | Excess funds are sent to Loan contract to be claimed by the lenders. . | Normally, interest is paid in constant amounts at regular intervals, and principal is returned on last repayment. Otherwise, you can also pay the entire remaining balance of the loan in one transaction including principal and the amount the interest that should be paid (we use a function called PremiumCalc here). . | Liquidations work as usual apart from the fact that you can only call it as a pool delegate if your equity in the loan is more than the minLoanEquity | This again will be interesting to test. Should already be heavily testsed. . Another (unnatural) thing that Maple is doing in the Liquidation is that, post the calling of liquidation, they are taking the collateral from the CollateralLocker and converting it into the Borrow Asset using Uniswap and then transferring it to be to the Loan contract for being claimed by the lenders. | I don’t understand why didn’t Maple just let the lenders claim their share of the collateral in terms of collateral asset itself. Perhaps it has got to do something with the LoanFDT which is an ERC2222 instead of pure ERC20. Need to get more clarity here. . Understanding MPL Token . MPL token is the native token of Maple Protocol and it inherits: ERC20 for standard token behavior | ERC2222 for profit distribution of USDC from the Maple Treasury | . | Interestingly, the MPL token repo has only been audited by Peckshield. So, this token particularly must have stringent testing. . Also, what’s more interesting is that the scope of Peckshield’s audit is just ERC20-compliance of the Maple token . So, everyone already knows what ERC20 is, so let’s skip it. But what’s interesting…is the use of ERC2222 standard, which adds the functionality to represent claims on any type of crypto cash flow on top of ERC20 functionalities. Think of it like this standard enables dividend like payouts in crypto where token holders are treated akin to share holders and all withdrawals which is based on the proportion of the withdrawing party’s MPL holdings is taken care of, by ERC2222. . MPL token is used in the 50-50 MPL-USDC Balancer pool created during the protocol deployment and will be used in all other Balancer pools which will have BPTs used in StakeLockers. . | The MPL token recieves fee periodically from the Treasury (at the discretion of the Governor). Basically funds are gathered in the Maple Treasury from all kinds of protocol fee, converted to USDC and sent to the MPL token contract. . | When MPL tokens are added as liquidity to the Balancer Pool, the Balancer pool is the owner of those tokens, which are accruing USDC interest (from the Maple treasury, read point 3). To account for this, the FDT (MPL token contract) has an additional function called withdrawFundsOnBehalf which allows for the following: Claims USDC interest from MPL contract, transferring it into the Balancer pool contract address | The USDC supply increases and the MPL supply stays constant, increasing the implied value of MPL (since the buy pressure on MPL has increased) | . | Why did the buy pressure on MPL increase when the quantity of USDC increased in the MPL-USDC 50-50 balancer pool? . Well, because according to the constraints of the pool the quantity of both MPL and USDC must remain equal (50-50), and when the quantity of USDC is increased in the pool, the traders are incentivized to take out the excess USDC by supplying MPL. And to supply this MPL, they’ll have to buy it from some DEX/CEX. . Understanding Pool Cover . Simple Concept. Lender funds need to be protected in case of a loan default | This protection(cover) is provided by volunteers. How can they do this? | Well, first they have to add liquidity to the MPL-USDC 50-50 Balancer Pool and get Balancer Pool Tokens (BPTs). Users can also directly buy these tokens. | Now every pool has a stakeLocker where these users can stake their BPT tokens and get StakeLockerFDTs in return. | Users use these StakeLockerFDTs to claim all future interest, since Pools reward the StakeLockers with a portion of the revenue generated in compensation for assuming more risk. | And at the time of liquidation, if these tokens are enough to compensate the lenders for the difference between the collateral required and pending repayments, then these users get the remaining BPTs, else, tata, bye bye. | . | The actual calculation of the minimum amount needed to compensate the lenders is a bit complicated (atleast looks complicated), since it requires you to be a little familiar with the Balancer protocol too. . Need to study, understand and potentially test this calculation. . Understanding Lockers . Dedicated smart contracts to hold custody assets. They’re kinda paranoid. I like this. Ok, no they are not paranoid. It’ll be holding assets only in the v1. In later version it is supposed to all sorts of weird things. . | Lockers and what they hold: LiquidityLocker: asset used for liquidity for funding Loans | DebtLocker: Holds custody of LoanFDTs (to claim revenue and make liquidation calls) | StakeLocker: BPTs (used as a reserve to cover losses from defaulted Loans) | FundingLocker: Asset that will be borrowed during the funding period (pre-drawdown) | CollateralLocker: Collateral (against any loan) | . | In order for any new Locker strategy to be implemented, its corresponding Factory must be whitelisted in MapleGlobals using setValidSubFactory | Understanding Oracles . Chainlink oracles are used as price feeds. | An oracle wrapper contract acts as a safeguard against oracle downtime. I think a better solution would have been to have two oracle integrations (both Chainlink and Uni) so that if one fails, we always have the second one to fall back on. . | and yeah, even after those two, we could have had a oracle wrapper contract as a safeguard against orale downtime. . For USDC prices, a constant USD oracle will be deployed, with a constant price of 1 * 10 ** 8. Note that USDC has 6 decimals only but Chainlink price feeds use 8 decimals of precision | Planning for a zombie apocalype: Oracle wrappers have the capability to provide a manual price in the event of an oracle outage, using the security multisig. In all other cases, it will simply pass through the value from getLatestPrice in the Chainlink oracle. | . | ERC 2222 Working Mechanism: Example . Would be really cool and prolly helpful, if you go through this example and actually understand it. . Normal functioning of FDTs . Link . Functioning of ExtendedFDTs . These FDTs are extending the functionality of FDT to include functionality to account for losses that must also be distributed for liquidity providers and staker. . For Pools, it happens in the case when a loan has defaulted, all the BPTs are burnt and still there is a deficit. . For Stakers(StakeLocker), it happens in the case when a loan has defaulted and any number of BPTs are burnt. . Formulae used for accounting for losses are the exact same as normal FDTs. Check them out. . Link . Handling custodial ownership using ERC2258 . Another awesome ERC that Maple brings to light is the ERC2258, which allows tokens to be custodied by an entity such that they cannot be transferred/redeemed for underlying liquidity, yet allow the rightful owner to retain all future benefits and all losses. . Example: It allows users to stake PoolFDTs in the MplRewards contract without changing their PoolFDT ERC-20 balance. This allows them to earn MPL rewards in the MplRewards contract, while simultaneously accruing interest earned by the Pool. This would not have been possible with the original SNX-fork of the liquidity mining contract, since in that implementation, all Pool interest would have been accrued to the MplRewards contract itself, since it would hold a balance of PoolFDTs . This of it like pledging your stonks to someone. . Need to test this a bit.. can we transfer funds after giving custody and so on… . Invariant . This equation must always be satisfied: . liquidityLockerBal + principalOut = fdtTotalSupply + interestSum - poolLosses .",
            "url": "https://saxenism.com/web3/solidity/defi-tits/lending/protocol-deep-dive/maple/maple-finance/2022/08/02/maple-finance-rundown.html",
            "relUrl": "/web3/solidity/defi-tits/lending/protocol-deep-dive/maple/maple-finance/2022/08/02/maple-finance-rundown.html",
            "date": " • Aug 2, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Solidity Contract Proxies",
            "content": "Migration or Social Yeet (CT Lingo) . You keep all your deployed contracts immutable and non-upgradable. So, when you actually need to modify your deployed contract’s logic or add some functionality, you have to deploy a new contract and ask the users to start making their calls to this newly deployed version of your protocol’s smart contract address. . This is the truest form of upgrading your contracts, without compromising on the trustless (no onlyAdmin functions) and decentralisation facets of web3. However, as is amply clear pulling this type of an upgrade isn’t really a breeze. . Proxies . Proxy Terminologies . The Implementation Contract Which has all our code of our protocol. When we upgrade, we launch a brand new implementation contract. | . | The Proxy Contract Which points to which implementation is the “correct” one, and routes everyone’s function calls to that contract | . | The User The make calls to the proxy | . | The admin This is the user(or group of users/voters) who upgrade to new implementation contracts. | . | Storage Variables . The cool thing about proxies and delegate call is that all our storage variables are going to be stored in the proxy contract and not in the implementation contract. Therefore, when you deploy a new contract and your proxy starts pointing to this new contract, you don’t have to migrate the data from the old contract as it is already in the proxy contract. . Issues with proxies . 1. Storage Clashes . When we do delegateCall from the proxyContract, we do the logic of implementationContract inside the proxyContract. . In Solidity storage layout begins at position 0 and increments for each new state variable. A proxy contract and its delegate/logic contracts share the same storage layout! . Here is an example to illustrate the problem. ProxyA defines two state variables, facetA and owner . . contract ProxyA { address facetA; address owner; constructor() public { owner = msg.sender; facetA = 0x0b22380B7c423470979AC3eD7d3c07696773dEa1; } fallback() external payable { address facetAddress = facetA; assembly { ... code omitted for simplicity } } } . FacetA declares one state variable. . contract FacetA { address user; function getUser() external view returns(address) { return user; } function setUser(address newUser) external { user = newUser; } } . ProxyA delegates function calls to FacetA. The problem is that, when delegating, ProxyA and FacetA share the same storage layout. The state variable facetA is at position 0. And The state variable user is also at position 0. So if the setUser function is called it will set user and facetA to the newUser value, which is obviously not the intention, the intention just being to set user only. . So, basically, you can only ever append variables to your implementation contract and not really change or re-order the old ones. . Now,ideally if you called setValue using delegateCall from your proxy contract, it should set the value of differentValue but it sets the value . 2. Function Selector Clashes . Function Selector: A 4 byte hash of a function name and function signature that define a function. . Now it is possible that a function in the implementation contract has the same function selector as an admin function in the proxy contract. Think of a scenario where function getPrice in the implementationContract has the same Function Selector as function destroyProxy. Definitely would not be good. . For example, the following two functions have the exact same function selector . function collate_propagate_storage(bytes16) external{} function burn(uint256) external {} . Contract to verify this statement is as follows and also can be found on this link: https://gist.github.com/saxenism/02af4e7a7fdb42801157571a3dab2c05 . // SPDX-License-Identifier: MIT pragma solidity &gt;=0.7.0 &lt;0.9.0; contract ProxyExperimentation { function getFunctionSignature(string memory signature) internal pure returns (bytes4) { return bytes4(keccak256(bytes(signature))); } function checkFunctionSelectorSimilarity() external pure returns (bool) { bytes4 functionSelector1 = getFunctionSignature(&quot;collate_propagate_storage(bytes16)&quot;); bytes4 functionSelector2 = getFunctionSignature(&quot;burn(uint256)&quot;); bool success = (functionSelector1 == functionSelector2); return success; } function verifyOtherFunctionDisimilarity() external pure returns (bool) { bytes4 functionSelector1 = getFunctionSignature(&quot;collate_propagate_storage(bytes16)&quot;); bytes4 functionSelector2 = getFunctionSignature(&quot;burnn(uint256)&quot;); bool result = (functionSelector1 == functionSelector2); return result; } } . Proxy Patterns . 1. Transparent Proxy Pattern . In this pattern, the admin can call only call the admin functions in the proxy contract and the users can only call the functions in the implementation contract. Admin functions are the functions that govern the upgrades. . This way, as an admin or as a user you can’t mix up functions from different contracts with the same function selector and no problems should occur. As a side note, now the admin cannot participate in their own DeFi protocol :P . 2. Universal Upgradable Proxies . Admin Only functions are kept in the implementation contract itself, instead of the proxy. . The advantage here is, if that happens, and two functions have the same function selector, then the Solidity compiler will let us know. Also, since there is one less read that we have to do, we save on gas costs. . So, it is necessary here that you implement the upgradation functions in the implementation contract, because otherwise you would be stuck and we get back to the YEET method . 3. Diamond Pattern . Allows for multiple implementation contracts. Is probably the best method to implement upgradable contracts, since it allows you to make granular changes/upgrades, but it can get really complex. So to use this, you need to be really really good at smart contract development. .",
            "url": "https://saxenism.com/web3/solidity/security/proxy/upgradation/2022/04/30/All-About-Proxies.html",
            "relUrl": "/web3/solidity/security/proxy/upgradation/2022/04/30/All-About-Proxies.html",
            "date": " • Apr 30, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "Solana Anchor Tutorial: Build a Calculator ",
            "content": "Solana development 101: Building a calculator using Solana programs . Welcome to the Solana crypto-currency quest. With this quest you’ll get upto speed with the most rapidly rising blockchain in the market: Solana. It would be awesome if you know a bit of Rust (or even C++ concepts) already and are familiar with how blockchains work, but even if you do not have any specific background of Rust or Solana development, we will have all bases covered. If you have a high level of interest and motivation, we should be good to go ahead. . In this quest, we will be developing a simple calculator on the Solana blockchain. This essentially means that once you are done with this quest, you will be well versed with the basics of development on the Solana blockchain using the Anchor framework and would be much better equipped to take on the other Solana quests. . Setting up the Environment: . There are a few things that we need to get up and running before we move forward in this quest. Before we move forward make sure you’ve a working NodeJS environment set up. We need rust, Solana, Mocha(a JS testing framework), Anchor and Phantom wallet for this quest. To install rust, run . curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh source $HOME/.cargo/env rustup component add rustfmt . To install Solana, run . sh -c &quot;$(curl -sSfL https://release.solana.com/v1.8.0/install)&quot; . To install mocha globally, run . npm install -g mocha . Now we’ll be installing Anchor. If you’re on a linux system, run . # Only on linux systems npm i -g @project-serum/anchor-cli . Fair Warning : If you are using a Windows system, we highly suggest using WSL2 (Windows sub-system for Linux) or switching to a Linux environment. Setting up WSL is also quick and easy. A good walk-through can be found here For any other OS, you need to build from source. Run the following command . cargo install --git https://github.com/project-serum/anchor --tag v0.17.0 anchor-cli --locked . To verify that Anchor is installed, run . anchor --version . . Since Solana is still a pretty new blockchain compared to the establised ones out there, it’s developer tooling too is pretty limited and cumbersome as of now. However, it is rapidly improving and it does so on a daily basis. At the forefront of this development is Anchor, by Armani Ferrante. You can think of it like the Ruby on Rails framework for Ruby, that means yes, you can develop things on vanilla Ruby, but Ruby on Rails makes your life much much easier, right? That’s the same with Anchor and Solana development. Anchor is the Hardhat of Solana development plus much more. It offers a Rust DSL (basically, an easier Rust) to work with along with IDL, CLI and workspace management. Anchor abstracts away a lot of potential security holes from a conventional Solana program, takes care of the serialization and deserialization, reduces large boilder-platey code to macros and lot of other good good stuff. . Running configurations on Solana CLI . The first command you should run on your terminal (assuming Solana CLI was properly installed in the last quest) is: . solana config get . This should throw up a result similar to something like: . . If you didnot set up your keypair earlier, then you won’t be having the Keypair Path in your results. To set that up, follow the instructions over here . We would want to remain on the local network for building our program and later shift to the devent or mainnet-beta if required. If the RPC URL field of your last result did not show localhost, you can set it to localhost using the following command: . solana config set --url localhost . Next, we would want to know our account/wallet address and airdrop some SOL tokens into it, to handle all the deployment, transactions etc costs that come with interacting with and using a Solana program. To do that first let’s find our address. The command to do that is: . solana address . This would result into something like this: . . Then, for more comprehensive details of your account, use the following command with the address that you got from the last command . solana account &lt;your address from the last command&gt; . This would result into something like this: . . Next, we want to spin up our local network. Think of this local network as a mock Solana blockchain running on your own single system. This network would be required for development and testing of our program. To spin it up, in a separate tab, use the following command: . solana-test-validator . Once you get an image, like the one below, you know that your local validator (local network) is now up and running . . Now, our last task is to top up our account with some SOL, which you can do by using: . solana airdrop 100 . This should result in something like: . . Setting up our Anchor project . In this sub-quest all we would do is initialize an Anchor project and see whether everything’s there and working fine or not and after move on ahead to make our own changes. Head over to your preferred destination for the project using your terminal and then type the following command: . anchor init mymoneydapp cd mycalculatordapp . This would result in a screen somewhat similar to this: . . First we check whether we can see the programs, app, programs, migrations directory among others or not. If we can, we would head over to programs/messengerapp/src/lib.rs to see the default program that Anchor provides us. This is the most basic example possible on Anchor and what’s happening here is simply that a user-defined function Initialize whenever called would successfully exit the program. That’s all, nothing fancy. Now, let’s try to compile this program using the following command: . anchor build . This would trigger a build function and would something like this upon completion: . . This build creates a new folder in your project directory called, target. This target folder contains the idl directory, which would also contain the idl for our program. The IDL or Interface Description Language describes the instructions exposed by the contract and is very similar to ABI in Solidity and user for similar purposes, ie, for tests and front-end integrations. Next, we can move onto testing this program, so that we can get familiar with how testing is done in Anchor. Head to tests/messengerapp.js. Here, you’ll see a test written in javascript to interact and test the default program. There are a lot of things in the test, that may not make sense to you right now, but stick around and we’ll get to those shortly. The test would look something like this: . . Next, to actually run these tests, first head over to the tab where you ran the solana-test-validator command and kill that process (using Ctrl-C). Now, use the following command: . anchor test . The passing tests should result in the following screen: . . Now, let’s head over to the programs directory and start importing some cool Rust crates provided by Anchor which will help us build our calculator app. . Defining our programs . Head over to programs/mycalculatordapp/src/lib.rs and clear the code written there apart from the boilerplate code written over there. After clearing, your coding screen should look something like this: . . You can also copy paste the below code to get started (assuming that you’ve also named your project as mycalculatordapp) . use anchor_lang::prelude::*; declare_id!(&quot;Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS&quot;); #[program] pub mod mycalculatordapp { use super::*; } . Now let us simply define the function signatures that we will require to code up our calculator dapp without writing the logic yet. The bulk of the program goes in a module under the #[program] macro. We’ll just define them under the pub mod mycalculatordapp and write the logic later. These function definitions would look like this: . pub fn create(ctx:Context&lt;Create&gt;, init_message: String) -&gt; ProgramResult { } pub fn add(ctx: Context&lt;Addition&gt;, num1: i64, num2: i64) -&gt; ProgramResult { } pub fn multiply(ctx: Context&lt;Multiplication&gt;, num1: i64, num2: i64) -&gt; ProgramResult { } pub fn subtract(ctx: Context&lt;Subtraction&gt;, num1: i64, num2: i64) -&gt; ProgramResult { } pub fn divide(ctx: Context&lt;Division&gt;, num1: i64, num2: i64) -&gt; ProgramResult { } . Here pub means public and fn means function, implying that they are public functions that can be invoked from our program, ie it becomes a client-callable program function. The first argument of these functions is always Context&lt;T&gt; which consist of the solana accounts array and the program ID, which in essence is the required data to call just about any progarm on Solana. The next parameter of both the first function is a String named init_message, which we will be using as our message that is stored on our calculator (think how you see some text every time you boot up your phone, pc, calculator etc). In the other functions, the num1 and num2 parameters are of type integers and are the numbers on which we will be performing our mathematical operations. The ProgramResult is the return type of both these functions, which actually is just an easier method to serve function results and/or errors. . After defining the above functions, your code should look something like this: . . Writing the logic for our first Solana program . Now let’s write the logic for the create function first, ok? Let’s first make our intentions clear for this function and the program in general. We want to keep track of three things here. First is the greeting message that we would be storing in our calculator, the second would be the result of all the mathematical operations and third is the remainder, which will be used in case of division, since Anchor currently does not support floating values. So we would want our calculator account (the main account that will handle all the calculation stuff of the program) to have three fields, namely: greeting, result, remainder. Also, since the same account will be used for the calculations and with different parameteres, we would want the calculator account to be mutable, ie, to be able to persist changes. Write the following code logic inside the create function now. . let calculator = &amp;mut ctx.accounts.calculator; calculator.greeting = init_message; Ok(()) . The Ok(()) syntax is used for error handling of the ProgramResult type. You can think of Ok(()) like a gate, that lets the program continue if there are no errors but sends the program into another state if an error is encountered. . Now, your coding screen should look something like this: . . A small note about accounts on Solana . An account is not actually a wallet. Instead, it’s a way for the contract to persist data between calls. This includes information such as the count in our base_account, and also information about permissions on the account. Accounts pay rent in the form of lamports, and if it runs out, then the account is purged from the blockchain. Accounts with two years worth of rent attached are “rent-exempt” and can stay on the chain forever. . Defining the structure of calculator account . In the last sub-quest, we talked about what is our expectation with the calculator account, right? Also, we used the calculator account already in the create function. So, now let’s go ahead and define what actually our calculator account is. As mentioned earlier, everything on Solana is an account, so we will be using the awesome macros of Anchor to convert a struct into our calculator account. . Write the code provided below outside of pub mod mycalculatordapp. . #[account] pub struct Calculator { pub greeting: String, pub result: i64, pub remainder: i64, } . With this, your code screen would look something like this: . . Good, now you are on track to implement actual functionalities of a calculator. Let’s see how do we do that. . First calculation function logic . With the last sub-quest, we are all set to write the logic for our first calculation function. Let’s write the logic for addition first. As you might be thinking, here we simply have to save the result of the addition of the two parameters in the result field of the calculator account. If you were thinking along that lines, then congratulations, you’re right on the money. Write the following code inside of the add function . let calculator = &amp;mut ctx.accounts.calculator; calculator.result = num1 + num2; Ok(()) . With this, your coding screen would look something like this: . Notice the Context&lt;Addition? As discussed earlier, it is the list of accounts that must be passed to this particular function for it to run. What accounts do you think would we require to send to this function to make it work? Yes, correct, we only need to send the calculator account, nothing else xD. So, now with this knowledge, let’s define Addition, write the following code below with your declaration of the calculator account: . #[derive(Accounts)] pub struct Addition&lt;&#39;info&gt; { #[account(mut)] pub calculator: Account&lt;&#39;info, Calculator&gt;, } . With this, your coding screen would look something like this: . . Congratulations…. now you have a Solana blockchain program that is capable of adding two number…. How cool is that, right? Now I want you to take a pause and re-collect whatever you’ve learnt in the quest uptil now, because the next sub-quest is going to be a challenge sub-quest :D . Challenge sub-quest . This sub-quest is a challenge for you. Trust me, at this moment, you are perfectly capable to write more Solana code by yourself. Keep in mind how we defined the add function and the Addition struct in the last quest and with that knowledge, I want you all to write the code for all the remaining functions, that is, multiply, subtract and divide and then declare the corresponding structs, that is Multiplication, Subtraction and Division. . The only function that will be slightly different would be the divide function, so trust in yourself and give this sub-quest your best shot. . Solution to the challenge sub-quest . I hope that you did your best to try and complete the remaining functions, now you can tally them with the below code. . The code for the multiply function is as follows: . let calculator = &amp;mut ctx.accounts.calculator; calculator.result = num1 * num2; Ok(()) . The Multiplication struct would look something like this: . #[derive(Accounts)] pub struct Multiplication&lt;&#39;info&gt; { #[account(mut)] pub calculator: Account&lt;&#39;info, Calculator&gt;, } . The code for the subtract function is as follows: . let calculator = &amp; mut ctx.accounts.calculator; calculator.result = num1 - num2; Ok(()) . The code for Subtraction struct is as follows: . #[derive(Accounts)] pub struct Subtraction&lt;&#39;info&gt; { #[account(mut)] pub calculator: Account&lt;&#39;info, Calculator&gt;, } . And finally, the code for the divide function is as follows: . let calculator = &amp;mut ctx.accounts.calculator; calculator.result = num1 / num2; calculator.remainder = num1 % num2; Ok(()) . The Division struct also looks like this . #[derive(Accounts)] pub struct Division&lt;&#39;info&gt; { #[account(mut)] pub calculator: Account&lt;&#39;info, Calculator&gt;, } . With all this, your coding screen should look something like this: . . . Did you get them right, or most of them right or even one right? Wasn’t this exciting? You’re able to write Solana code yourself right off the bat. . Now, is our program complete? Sadly no, there is one more, last remaining piece of the puzzle that we must address before we can say that we done with the program coding part. Before jumping onto the next sub-quest, try and guess what could we be missing from our program, and yes, you can guess that. It is within your grasp. . Final piece of the puzzle . If you could guess that we had used the Create struct in the first create function itself but never defined it anywhere like we defined the Addition, Multiplication etc structs, then, congratulations you were absolutely right. . With this struct, we want to pass three accounts, the first is obviously the calculator account, since it is being used in the function itself. The second account is the user account and the third account is the system_program. What makes this struct a bit more special is that, in this struct we have to give the command to actually create the calculator account (which we have used in the subsequent functions). The creation of this calculator account will cost us some money (SOL) which will be paid by the user account that we just mentioned, along with that we have the space parameter where we specify how much space do we require in our account (here, calculator account) and finally the system_program is just system specifications for the Solana blockchain, again in the form of an account. . Write the following code to define the Create struct: . #[derive(Accounts)] pub struct Create&lt;&#39;info&gt; { #[account(init, payer = user, space = 8 + 64 + 64 + 64 + 64)] pub calculator: Account&lt;&#39;info, Calculator&gt;, #[account(mut)] pub user: Signer&lt;&#39;info&gt;, pub system_program: Program&lt;&#39;info, System&gt;, } . As discussed earlier, we used the derive Accounts macro since we had to incorporate 3 accounts here and for all these three accounts individually, we used the account macro. Now onto the arguments used with these macros. The init macro is used to create a new account owned by the current program which is our mycalculatordapp program. Whenever init parameter is used, we must always specify the payer or the account that will be paying for creation of the account on the Solana blockchain, along with the space param which is the space with which the new account is created. . The mut parameter marks an account as mutable, which essentially means our account will be altered and Solana will need to update the data in your account. So, always use the mut parameter for persisting changes. . Another new concept used here is the Signer type. This is used to enforce the constraint that the authority account (messengerapp in this case) signed the transaction. . With this, your coding screen should look something like this: . . Further reading: . You can read up on different types of account constraints here. . Testing our calculator program . Head over to tests/mycalculatordapp.js and delete everything that’s written there. We are going to be writing our tests from scratch. The first step would be to import the necessary libraries and constants. To do that, use the following code: . const assert = require(&#39;assert&#39;); const anchor = require(&#39;@project-serum/anchor&#39;); const { SystemProgram } = anchor.web3; . Now, since we will be using Mocha for testing our programs, we will create the skeleton of where we will be putting our tests. So, basically, how Mocha works is that it takes describe blocks as testing blocks and within those describe blocks there are numerous tests written using the it blocks. So, use the following code to create the skeleton: . describe(&#39;mycalculatordapp&#39;, () =&gt; { const provider = anchor.Provider.local(); anchor.setProvider(provider); const calculator = anchor.web3.Keypair.generate(); const program = anchor.workspace.Mycalculatordapp; it(&#39;Creates a calculator&#39;, async () =&gt; { }); it(&quot;Adds two numbers&quot;, async function() { }); it(&#39;Multiplies two numbers&#39;, async function() { }) it(&#39;Subtracts two numbers&#39;, async function() { }); it(&#39;Divides two numbers&#39;, async function() { }); }); . With this, your code screen should look something like this: . . The additional things that we coded there were the introduction of provider. The provider is the abstraction of a connection to the Solana network. In the test, the Anchor framework will create the provider for us based on the environment (anchor.Provider.local()). . Now, the program is an abstraction that combines the Provider, idl, and the programID (which is generated when the program is built) and allows us to call RPC methods against our program. . The calculator variable you see is the keypair generated using anchor.web3 that we will be using to test our program. . When we have these three things, we can start calling functions in our program, which is what we will be doing in our next sub-quest. . Writing our first test . The method to call the functions of our program is pretty straight-forward. We will use the program RPCs (Remote procedure calls) to access the function and then we will use the web3.js library to create accounts which have to be passed as the parameters to those functions. Let’s first jump into the code of our first test and see things in action. . it(&#39;Creates a calculator&#39;, async () =&gt; { await program.rpc.create(&quot;Welcome to Solana&quot;, { accounts: { calculator: calculator.publicKey, user: provider.wallet.publicKey, systemProgram: SystemProgram.programId, }, signers: [calculator] }); const account = await program.account.calculator.fetch(calculator.publicKey); assert.ok(account.greeting === &quot;Welcome to Solana&quot;); _calculator = calculator; }); . Now, what we have done in the code above is simply create a calculator account by generating a new account using the web3 library. Then using the program RPC, we have called the create function and to that function we have supplied the required parameters, which were the calculator, user, systemProgram and the init_message string. . After this function is run, we simply grabbed hold of the calculator account and checked it’s greeting field and verify whether it has changed to Welcome to Solana or not. After that we save the calculator account in a variable called _calculator so that it can be referenced later. . With this, your code screen would look something like this: . . Writing our second test . With this second test, we begin testing the calculations of the Solana program that we wrote. Firstly, we will write the test for the correct functioning of the add function and then with that as the inspiration, the next sub-quest will be a challenge sub-quest where the learner will write the tests for multiply, subtract and divide. For testing, we cannot directly use numbers and we will therefore have to cast them into Anchor big numbers. Now, write the code below to test the add function of our mycalculatordapp program. . it(&quot;Adds two numbers&quot;, async function() { const calculator = _calculator; await program.rpc.add(new anchor.BN(2), new anchor.BN(3), { accounts: { calculator: calculator.publicKey, }, }); const account = await program.account.calculator.fetch(calculator.publicKey); assert.ok(account.result.eq(new anchor.BN(5))); assert.ok(account.greeting === &quot;Welcome to Solana&quot;); }); . It is very similar to the test we wrote in the last sub-quest with the only changes being that we are supplying 2 and 3 as the numbers to be added and passing the list of accounts as per the Addition struct which requires only the calculator account. After the add function is run using the RPC, we fetch the calculator account and check the fields of the calculator account. The greeting field should remain unaffected and still be “Welcome to Solana”, along with that the result field should now be equal to the sum of 2 and 3, ie, 5. . That is all that was required to test the add function. With this, your coding screen should look like this: . . Challenge sub-quest . As discussed in the previous sub-quest, in this sub-quest you are required to come up with the tests for the multiply, subtract and divide functions by yourself. You can take inspiration from the earlier two tests we wrote and trust me when I say that you can very easily write the tests for these three functions too. All you need to do is make sure that the entire quest uptil this point was clear to you. . All the best. . Solution to the challenge sub-quest . I hope that you gave your best attempt to the challenge in the last sub-quest and now let’s tally what you’ve written with the tests can be. The values of the parameters (num1 and num2) being passed can change, make sure you are writing your assert statements accordingly. . Here’s the code for the multiply function check: . it(&#39;Multiplies two numbers&#39;, async function() { const calculator = _calculator; await program.rpc.multiply(new anchor.BN(2), new anchor.BN(3), { accounts: { calculator: calculator.publicKey, }, }); const account = await program.account.calculator.fetch(calculator.publicKey); assert.ok(account.result.eq(new anchor.BN(6))); assert.ok(account.greeting === &quot;Welcome to Solana&quot;); }) . Here’s the code for the subtract function check: . it(&#39;Subtracts two numbers&#39;, async function() { const calculator = _calculator; await program.rpc.subtract(new anchor.BN(32), new anchor.BN(33), { accounts: { calculator: calculator.publicKey, }, }); const account = await program.account.calculator.fetch(calculator.publicKey); assert.ok(account.result.eq(new anchor.BN(-1))); assert.ok(account.greeting === &quot;Welcome to Solana&quot;); }); . Here’s the code for the divide function check: . it(&#39;Divides two numbers&#39;, async function() { const calculator = _calculator; await program.rpc.divide(new anchor.BN(10), new anchor.BN(3), { accounts: { calculator: calculator.publicKey, }, }); const account = await program.account.calculator.fetch(calculator.publicKey); assert.ok(account.result.eq(new anchor.BN(3))); assert.ok(account.remainder.eq(new anchor.BN(1))); assert.ok(account.greeting === &quot;Welcome to Solana&quot;); }); . Wasn’t this exhilarating? You’ve only just started with Solana development and now not only can you just write program functions on your own, you can also write tests to verify their functioning. Isn’t this seriously mind-blowing? Anyway, congratulations on this feet and just tally your code with the code snapshot below and after which we move onto actaully running these tests. . . . . Running the tests . Now, that we are done running all the tests, make sure that your local validator is not running. That means make sure that the solana-test-validator process is not running and the network is set as localhost by inspecting the results of solana config get. Once all this is done, it is time for us to actually test the progarm that we wrote. To do that use the following command: . anchor test . If all the tests pass, you’ll get a screen similar to this: . . If you get some errors, try debugging those using the error messages you get. Make sure you have accurately followed the code presented in the quests and you are on the same Anchor version as that followed in the quest (0.17.0). With that you’ll find your way out of most of the errors that you might run into. . Congratulations . Congratulations on succesfully creating your own calculator on the Solana blockchain and testing its functioning :D . Next steps . Now you’ve dipped your toes in the ocean of Solana development. To learn more about it, you can try and mess around with the data types that we used in the function declarations and see what effect does that have on the program; you can try to use just one struct in place of the Addition, Multiplication, Subtraction and Division struct since they were all similar. You can try to combine all the four calculator functions into one function where the operation is decided using the parameter passed, and apart from this you can experiment with the contents of this quest to your heart’s content and then you can move onto the other quests on Solana development. .",
            "url": "https://saxenism.com/solana/anchor/tutorial/web3/2021/11/28/Solana-Tutorial-Build-A-Calculator.html",
            "relUrl": "/solana/anchor/tutorial/web3/2021/11/28/Solana-Tutorial-Build-A-Calculator.html",
            "date": " • Nov 28, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "Solana Anchor Tutorial: Build a Messaging App ",
            "content": "Building a messaging app on Solana: Starting with a blockchain time capsule . Welcome to the Solana messaging app quest. With this quest you’ll get upto speed with the most rapidly rising blockchain in the market: Solana. It would be awesome if you know a bit of Rust or C++ already and are familiar with how blockchains work, but even if you do not have any specific background of Rust or Solana development, we will have all bases covered. If you have a high level of interest and motivation, we should be good to go ahead. . In this quest, we will be developing a blockchain based time-capsule. This essentially means that you’ll be able to leave a message on the Solana blockchain and anyone can view it for as long as the Solana blockchain itself exists. Your message will survive the test of time and could not be taken down by anyone. . This time-capsule quest will set us up for extending this project and creating an entire messaging app. How cool is that, right? . Setting up the Environment: . There are a few things that we need to get up and running before we move forward in this quest. Before we move forward make sure you’ve a working NodeJS environment set up. We need rust, Solana, Mocha(a JS testing framework), Anchor and Phantom wallet for this quest. To install rust, run . curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh source $HOME/.cargo/env rustup component add rustfmt . To install Solana, run . sh -c &quot;$(curl -sSfL https://release.solana.com/v1.8.0/install)&quot; . To install mocha globally, run . npm install -g mocha . Now we’ll be installing Anchor. If you’re on a linux system, run . # Only on linux systems npm i -g @project-serum/anchor-cli . Fair Warning : If you are using a Windows system, we highly suggest using WSL2 (Windows sub-system for Linux) or switching to a Linux environment. Setting up WSL is also quick and easy. A good walk-through can be found here For any other OS, you need to build from source. Run the following command . cargo install --git https://github.com/project-serum/anchor --tag v0.18.0 anchor-cli --locked . To verify that Anchor is installed, run . anchor --version . Since Solana is still a pretty new blockchain compared to the establised ones out there, it’s developer tooling too is pretty limited and cumbersome as of now. However, it is rapidly improving and it does so on a daily basis. At the forefront of this development is Anchor, by Armani Ferrante. You can think of it like the Ruby on Rails framework for Ruby, that means yes, you can develop things on vanilla Ruby, but Ruby on Rails makes your life much much easier, right? That’s the same with Anchor and Solana development. Anchor is the Hardhat of Solana development plus much more. It offers a Rust DSL (basically, an easier Rust) to work with along with IDL, CLI and workspace management. . Running configurations on Solana CLI . The first command you should run on your terminal (assuming Solana CLI was properly installed in the last quest) is: . solana config get . This should throw up a result similar to something like: . . If you didnot set up your keypair earlier, then you won’t be having the Keypair Path in your results. To set that up, follow the instructions over here . We would want to remain on the local network for building our program and later shift to the devent or mainnet-beta if required. If the RPC URL field of your last result did not show localhost, you can set it to localhost using the following command: . solana config set --url localhost . Next, we would want to know our account/wallet address and airdrop some SOL tokens into it, to handle all the deployment, transactions etc costs that come with interacting with and using a Solana program. To do that first let’s find our address. The command to do that is: . solana address . This would result into something like this: . . Then, for more comprehensive details of your account, use the following command with the address that you got from the last command . solana account &lt;your address from the last command&gt; . This would result into something like this: . . Next, we want to spin up our local network. Think of this local network as a mock Solana blockchain running on your own single system. This network would be required for development and testing of our program. To spin it up, in a separate tab, use the following command: . solana-test-validator . Once you get an image, like the one below, you know that your local validator (local network) is now up and running . . Now, our last task is to top up our account with some SOL, which you can do by using: . solana airdrop 100 . This should result in something like: . . Setting up our Anchor project . In this sub-quest all we would do is initialize an Anchor project and see whether everything’s there and working fine or not and after move on ahead to make our own changes. Head over to your preferred destination for the project using your terminal and then type the following command: . anchor init messengerapp cd messengerapp . This would result in a screen somewhat similar to this: . . First we check whether we can see the programs, app, programs, migrations directory among others or not. If we can, we would head over to programs/messengerapp/src/lib.rs to see the default program that Anchor provides us. This is the most basic example possible on Anchor and what’s happening here is simply that a user-defined function Initialize whenever called would successfully exit the program. That’s all, nothing fancy. Now, let’s try to compile this program using the following command: . anchor build . This would trigger a build function and would something like this upon completion: . . This build creates a new folder in your project directory called, target. This target folder contains the idl directory, which would also contain the idl for our program. The IDL or Interface Description Language describes the instructions exposed by the contract and is very similar to ABI in Solidity and user for similar purposes, ie, for tests and front-end integrations. Next, we can move onto testing this program, so that we can get familiar with how testing is done in Anchor. Head to tests/messengerapp.js. Here, you’ll see a test written in javascript to interact and test the default program. There are a lot of things in the test, that may not make sense to you right now, but stick around and we’ll get to those shortly. The test would look something like this: . . Next, to actually run these tests, first head over to the tab where you ran the solana-test-validator command and kill that process (using Ctrl-C). Now, use the following command: . anchor test . The passing tests should result in the following screen: . . Now, let’s head over to the programs directory again and start making changes to create our messaging app. . Writing our first program function . Head over to programs/messengerapp/src/lib.rs and clear the code written there apart from the macro declarations and crates (libraries) that we will be using. After the clearning, your coding screen should look somehting like this: . . Now let us simply define two functions that we will be using in our Solana program. The bulk of the program goes in a module under the #[program] macro. We’ll just define them under the pub mod messengerapp and write the logic later. These two function definitions would look like this: . pub fn initialize(ctx: Context&lt;Initialize&gt;, data: String) -&gt; ProgramResult { } pub fn update(ctx: Context&lt;Update&gt;, data: String) -&gt; ProgramResult { } . Here pub means public and fn means function, implying that they are public functions that can be invoked from our program, ie it becomes a client-callable program function. The first argument of these functions is always Context&lt;T&gt; which consist of the solana accounts array and the program ID, which in essence is the required data to call just about any progarm on Solana. The next parameter of both these functions is a String named data, which we will be using as our message. The ProgramResult is the return type of both these functions, which actually is just an easier method to serve function results and/or errors. . After defining the above two functions, your code should look something like this: . . Now, let’s write our logic for the initialize function, ok? Let’s first make our intentions clear for this function and the program in general. We want to keep track of two things here. First, is the data that is being passed while calling the function and the second is the list of all the data(messages) that have been passed to our specific account. So, we would want our main account (the account that will handle all the messaging stuff of the program) to have two fields, one for storing the incoming data and the other for keeping a record of all earlier data. We call this account the base_account. Also, keep in mind that since we will be adding to the data_list everytime a new data is introduced, we will need the account to be mutable, ie, the account should be able to accept changes. Write the following logic inside the initialize function now: . let base_account = &amp;mut ctx.accounts.base_account; let copy = data.clone(); base_account.data = data; base_account.data_list.push(copy); Ok(()) . The Ok(()) syntax is used for error handling of the ProgramResult type. You can think of Ok(()) like a gate, that lets the program continue if there are no errors but sends the program into another state if an error is encountered. . Now, your coding screen should look something like this: . A small note about Accounts on Solana: An account is not actually a wallet. Instead, it’s a way for the contract to persist data between calls. This includes information such as the count in our base_account, and also information about permissions on the account. Accounts pay rent in the form of lamports, and if it runs out, then the account is purged from the blockchain. Accounts with two years worth of rent attached are “rent-exempt” and can stay on the chain forever. . Writing out our second function . In the last sub-quest we defined the update function, right? Now let’s go ahead and write the logic for this function. . let base_account = &amp;mut ctx.accounts.base_account; let copy = data.clone(); base_account.data = data; base_account.data_list.push(copy); Ok(()) . Your code screen should now look like this: . Wasn’t this funny? We wrote the same code again, right? Well, yes, the logic of both the functions were same and the only real difference is in the Account inside of the Context&lt;&gt; struct. This is a simple container for the currently executing program_id generic over Accounts. This essentially is what would differentiate between whether the message coming in our program is the first message or some later messages. Now, the natural question would be where are all these structs defined? Calm down, champ. We haven’t yet defined them, but that is exactly what we will be doing next. . Defining the first Account struct used in our program . Let’s first define the Initialize struct used in our initialize function that we defined two sub-quests back. We already have gone over what Accounts and Context are. So, here just keep in mind that whenever we need to include multiple accounts in a struct, we would use the derive Accounts macro, which is #[derive(Accounts)], basically when we want to derive an account to pass to the function using other accounts, we use the derive accounts macro and while defining a singular account we would simply use the normal account macro, which is [account]. Now the normal account marco can also consist of many parameters which denote the permissions related to that particular account and we will look into those as we move ahead. Write the following code into your editor: . #[derive(Accounts)] pub struct Initialize&lt;&#39;info&gt; { #[account(init, payer = user, space = 64 + 64)] pub base_account: Account&lt;&#39;info, BaseAccount&gt;, #[account(mut)] pub user: Signer&lt;&#39;info&gt;, pub system_program: Program&lt;&#39;info, System&gt;, } . As discussed earlier, we used the derive Accounts macro since we had to incorporate 3 accounts here and for all these three accounts individually, we used the account macro. Now onto the arguments used with these macros. The init macro is used to create a new account owned by the current program which is our messengerapp program. Whenever init parameter is used, we must always specify the payer or the account that will be paying for creation of the account on the Solana blockchain, along with the space param which is the space with which the new account is created. . The mut parameter marks an account as mutable, which essentially means our account will be altered and Solana will need to update the data in your account. So, always use the mut parameter for persisting changes. . Another new concept used here is the Signer type. This is used to enforce the constraint that the authority account (messengerapp in this case) signed the transaction. . The peculiar thing you might notice here is that the base_account field is of type BaseAccount, but that BaseAccount is not to be found anywhere, right? As always, we will be defining that in just the next sub-quest. So hold on and re-read all the info that you just recieved if you feel the need. In the next sub-quest we will be defining the Update and BaseAccount structs. . Your coding screen should look like this right now: . . Further Reading: . You can read up on different types of account constraints here. . Defining all remaining Accounts of our program . With the understanding about all kinds of Account marcos and the associated parameters with them, let’s get straight into writing the other two account structs. . pub struct Update&lt;&#39;info&gt; { #[account(mut)] pub base_account: Account&lt;&#39;info, BaseAccount&gt;, . and now the final BaseAccount struct: . #[account] pub struct BaseAccount { pub data: String, pub data_list: Vec&lt;String&gt;, . Now, for the Update account struct, we notice that it is essentially the same as the Initialize account struct, it’s just that we are using an existing field base_account of type BaseAccount and not creating it. After which, we define the BaseAccount that was being used everywhere. As discussed earlier, it has two fields, one is data of type String to store the incoming value of the message while the other is a vector of strings to store/persist all the messages in that account. A vector is a list of elements with no specified size. But, bear in mind that initially we had createed our base account with the space of 64 + 64 so there will be a limit to thow many messages can be stored. You can explore the limits at different sizes as a side quest. . After writing these definitions, your code screen should be looking something like this: . . Good, now we are just one step away from being completely done with the smart contract (programs in Solana lingo) side of our project. . Updating our program_id . Remember the declare_id! macro of our program that was declared at the top with a random looking string, that we did not talk about? It is time to fix that. Currently, it looks something like this: . . Since, we already discussed that we would be working on our local network, we need to deploy our program on our local network and then put the program_id recieved from there here at this macro. First make sure that your local validator is running in a different tab. If it is not, run it again in a different tab using the solana-test-validator command. Now use the following command to deploy your anchor program: . anchor deploy . The above command should result in a screen similar to this: . . Now, copy the program ID from the above output to the declare_id macro in our program. Something like this: . . Congratulations, we are now done with writing the programs of our project. You just completed the smart contract (programs in Solana lingo) side of the Time Capsule project :D . Creating the testing skeleton of our program . Head over to tests/messengerapp.js and delete everything that’s written there. We are going to be writing our tests from scratch. The first step would be to import the necessary libraries and constants. To do that, use the following code: . const assert = require(&#39;assert&#39;); const anchor = require(&#39;@project-serum/anchor&#39;); const { SystemProgram } = anchor.web3; . Now, since we will be using Mocha for testing our programs, we will create the skeleton of where we will be putting our tests. So, basically, how Mocha works is that it takes describe blocks as testing blocks and within those describe blocks there are numerous tests written using the it blocks. So, use the following code to create the skeleton: . describe(&quot;Testing our messaging app: &quot;, function() { const provider = anchor.Provider.env(); anchor.setProvider(provider); const program = anchor.workspace.Messengerapp; it(&quot;An account is initialized&quot;, async function() { }); it(&quot;Update the account previously created: &quot;, async function() { }); }); . Now, your code screen should look something like: . . The additional things that we coded there were the introduction of provider. The provider is the abstraction of a connection to the Solana network. In the test, the Anchor framework will create the provider for us based on the environment (anchor.Provider.env()). . Now, the program is an abstraction that combines the Provider, idl, and the programID (which is generated when the program is built) and allows us to call RPC methods against our program. . When we have these two things, we can start calling functions in our program, which is what we will be doing in our next sub-quest. . Writing our first test . The method to call the functions of our program is pretty straight-forward. We will use the program RPCs (Remote procedure calls) to access the function and then we will use the web3.js library to create accounts which have to be passed as the parameters to those functions. Let’s first jump into the code of our first test and see things in action. . it(&quot;An account is initialized&quot;, async function() { const baseAccount = anchor.web3.Keypair.generate(); await program.rpc.initialize(&quot;My first message&quot;, { accounts: { baseAccount: baseAccount.publicKey, user: provider.wallet.publicKey, systemProgram: SystemProgram.programId, }, signers: [baseAccount] }); }); . Now, what we have done in the code above is simply create a baseAccount by generating a new account using the web3 library. Then using the program RPC, we have called the initialize function and to that function we have supplied the required parameters, which were the baseAccount, user, systemProgram and the signer. . After this function is run, we simply need to grab hold of the baseAccount and check it’s data field and verify whether it has changed to My first message or not. To do that, we use the following lines of code: . const account = await program.account.baseAccount.fetch(baseAccount.publicKey); console.log(&#39;Data: &#39;, account.data); assert.ok(account.data === &quot;My first message&quot;); _baseAccount = baseAccount; . After this, your coding screen should look like this: . . What we did here fetch the baseAccount from the program after the initialize function has been run and store it in a variable called account. Then we check whether the data field of account is the same as our message or not. In the last step, we save the state of this baseAccount in a variable called _baseAccount, so that we can check that later in the other tests. . Now let us write the second test, where we update the previously created baseAccount which we stored in _baseAccount and check whether new messages get stored in the data_list field or not. . Writing the second test . As mentioned in the last quest, our objective with this test is to update the data_list field of the baseAccount and then verify this updation. To do that, we will write the below code: . const baseAccount = _baseAccount; await program.rpc.update(&quot;My second message&quot;, { accounts: { baseAccount: baseAccount.publicKey, }, }); . With the above code, we assigned the _baseAccount to a new baseAccount. This step can be skipped. After that, just like how we called the initialize function earlier, we called the update function and provided it with the required params, which are the new message and the baseAccount. After that to verify whether the update took place or not, we will use the following code: . const account = await program.account.baseAccount.fetch(baseAccount.publicKey); console.log(&quot;Updated data: &quot;, account.data); assert.ok(account.data === &quot;My second message&quot;); console.log(&quot;All account data: &quot;, account); console.log(&quot;All data: &quot;, account.dataList); assert.ok(account.dataList.length === 2); . With this, your coding screen should look something like this: . . The console.logs can be skipped, but they are there for our own better understanding. So, in this block of code, we again fetch the baseAccount after the update function and check whether the data of the account has been updated or not. Then we print the details of the account itself, then the entire list of all the messages and finally we check whether the length of this data_list field of the baseAccount is 2 or not (since it should ideally contain [My first message, My second message]). . With this we are done writing our tests, now all that remains is to actually run these tests. . Testing our program . Remember, some time back we changed the program_id in the declare_id macro of our program? We will follow a similar step in the Anchor.toml file now. Open the Anchor.toml file and replace the old program_id with the new program_id, like so: . . Now, it’s the moment of truth. Head over to the console and type the following command if you have not stopped the solana-test-validator running in a different tab: . anchor test --skip-local-validator . This will hopefully give a result similar to this: . . And if this didn’t work for you go to your local validator tab and close it using Ctrl + C and after come back to the tab where you were testing and type the following command: . anchor test . This should yield a result similar to: . . Congratulations . Congratulations on not only building the building blocks of a chat application on Solana, which you can use as time-capsule on the blockchain, but also successfully testing that. In the next quest, we can go on ahead to see how to connect the front-end of a website with our program and see for ourselves how well our program is working. See you all soon :) .",
            "url": "https://saxenism.com/solana/anchor/tutorial/web3/2021/11/26/Solana-Tutorial-Build-A-Messaging-App.html",
            "relUrl": "/solana/anchor/tutorial/web3/2021/11/26/Solana-Tutorial-Build-A-Messaging-App.html",
            "date": " • Nov 26, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "Solana Anchor Tutorial: Create your own tokens ",
            "content": "Building your own crypto-currency using Solana programs . Welcome to the Solana crypto-currency quest. With this quest you’ll get upto speed with the most rapidly rising blockchain in the market: Solana. It would be awesome if you know a bit of Rust (or even C++ concepts) already and are familiar with how blockchains work, but even if you do not have any specific background of Rust or Solana development, we will have all bases covered. If you have a high level of interest and motivation, we should be good to go ahead. . In this quest, we will be developing our own crypto-currency on the Solana blockchain or our own spl-token in the Solana lingo. This essentially means that once you are done with this quest, you will be able to make your crypto-currency using Solana programs and use that to do whatever you can think of, including using it as a fan token, a social token, a governance token, a utility token or a coin. . Setting up the Environment: . There are a few things that we need to get up and running before we move forward in this quest. Before we move forward make sure you’ve a working NodeJS environment set up. We need rust, Solana, Mocha(a JS testing framework), Anchor and Phantom wallet for this quest. To install rust, run . curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh source $HOME/.cargo/env rustup component add rustfmt . To install Solana, run . sh -c &quot;$(curl -sSfL https://release.solana.com/v1.8.0/install)&quot; . To install mocha globally, run . npm install -g mocha . Now we’ll be installing Anchor. If you’re on a linux system, run . # Only on linux systems npm i -g @project-serum/anchor-cli . Fair Warning : If you are using a Windows system, we highly suggest using WSL2 (Windows sub-system for Linux) or switching to a Linux environment. Setting up WSL is also quick and easy. A good walk-through can be found here For any other OS, you need to build from source. Run the following command . cargo install --git https://github.com/project-serum/anchor --tag v0.17.0 anchor-cli --locked . To verify that Anchor is installed, run . anchor --version . Since Solana is still a pretty new blockchain compared to the establised ones out there, it’s developer tooling too is pretty limited and cumbersome as of now. However, it is rapidly improving and it does so on a daily basis. At the forefront of this development is Anchor, by Armani Ferrante. You can think of it like the Ruby on Rails framework for Ruby, that means yes, you can develop things on vanilla Ruby, but Ruby on Rails makes your life much much easier, right? That’s the same with Anchor and Solana development. Anchor is the Hardhat of Solana development plus much more. It offers a Rust DSL (basically, an easier Rust) to work with along with IDL, CLI and workspace management. Anchor abstracts away a lot of potential security holes from a conventional Solana program, takes care of the serialization and deserialization, reduces large boilder-platey code to macros and lot of other good good stuff. . Running configurations on Solana CLI . The first command you should run on your terminal (assuming Solana CLI was properly installed in the last quest) is: . solana config get . This should throw up a result similar to something like: . . If you didnot set up your keypair earlier, then you won’t be having the Keypair Path in your results. To set that up, follow the instructions over here . We would want to remain on the local network for building our program and later shift to the devent or mainnet-beta if required. If the RPC URL field of your last result did not show localhost, you can set it to localhost using the following command: . solana config set --url localhost . Next, we would want to know our account/wallet address and airdrop some SOL tokens into it, to handle all the deployment, transactions etc costs that come with interacting with and using a Solana program. To do that first let’s find our address. The command to do that is: . solana address . This would result into something like this: . . Then, for more comprehensive details of your account, use the following command with the address that you got from the last command . solana account &lt;your address from the last command&gt; . This would result into something like this: . . Next, we want to spin up our local network. Think of this local network as a mock Solana blockchain running on your own single system. This network would be required for development and testing of our program. To spin it up, in a separate tab, use the following command: . solana-test-validator . Once you get an image, like the one below, you know that your local validator (local network) is now up and running . . Now, our last task is to top up our account with some SOL, which you can do by using: . solana airdrop 100 . This should result in something like: . . Setting up our Anchor project . In this sub-quest all we would do is initialize an Anchor project and see whether everything’s there and working fine or not and after move on ahead to make our own changes. Head over to your preferred destination for the project using your terminal and then type the following command: . anchor init mymoneydapp cd mymoneydapp . This would result in a screen somewhat similar to this: . . First we check whether we can see the programs, app, programs, migrations directory among others or not. If we can, we would head over to programs/messengerapp/src/lib.rs to see the default program that Anchor provides us. This is the most basic example possible on Anchor and what’s happening here is simply that a user-defined function Initialize whenever called would successfully exit the program. That’s all, nothing fancy. Now, let’s try to compile this program using the following command: . anchor build . This would trigger a build function and would something like this upon completion: . . This build creates a new folder in your project directory called, target. This target folder contains the idl directory, which would also contain the idl for our program. The IDL or Interface Description Language describes the instructions exposed by the contract and is very similar to ABI in Solidity and user for similar purposes, ie, for tests and front-end integrations. Next, we can move onto testing this program, so that we can get familiar with how testing is done in Anchor. Head to tests/messengerapp.js. Here, you’ll see a test written in javascript to interact and test the default program. There are a lot of things in the test, that may not make sense to you right now, but stick around and we’ll get to those shortly. The test would look something like this: . . Next, to actually run these tests, first head over to the tab where you ran the solana-test-validator command and kill that process (using Ctrl-C). Now, use the following command: . anchor test . The passing tests should result in the following screen: . . Now, let’s head over to the programs directory and start importing some cool Rust crates provided by Anchor which will help us build our money app. . Importing the Anchor SPL Crates . Head over to programs/mymoneydapp/Cargo.toml and under dependencies, add the two following lines: . anchor-spl = &quot;0.17.0&quot; spl-token = { version = &quot;3.1.1&quot;, features = [&quot;no-entrypoint&quot;] } . Make sure that the version of the anchor-spl you write here, matches the version of anchor-lang that you had installed. It would be much more convenient for you if install the same version that we are using in the quest. After these changes, the Cargo.toml file would look something like this: . . Now that we are done adding the dependencies in the Cargo file, let’s call it inside our program too. Write down the following use statments at the very top of your programs/mymoneydapp/src/lib.rs file: . use anchor_spl::token::{self, Burn, MintTo, SetAuthority, Transfer}; . After this, clear all the default code that we were provided with, this would make your coding screen look something like: . . Writing our first program function . Head over to programs/mymoneydapp/src/lib.rs and clear the code written there apart from the macro declarations and crates (libraries) that we will be using. After the clearning, your coding screen should look something like the last screen of the last quest. . Now let us simply define four functions that we will be using in our Solana program. The bulk of the program goes in a module under the #[program] macro. We’ll just define them under the pub mod mymoneydapp and write the logic later. These four function definitions would look like this: . pub fn proxy_transfer(ctx: Context&lt;ProxyTransfer&gt;, amount: u64) -&gt; ProgramResult { } pub fn proxy_mint_to(ctx: Context&lt;ProxyMintTo&gt;, amount: u64) -&gt; ProgramResult { } pub fn proxy_burn(ctx: Context&lt;ProxyBurn&gt;, amount: u64) -&gt; ProgramResult { } pub fn proxy_set_authority( ctx: Context&lt;ProxySetAuthority&gt;, authority_type: AuthorityType, new_authority: Option&lt;Pubkey&gt;, ) -&gt; ProgramResult { } . Notice the use of the word proxy in each function name? That is because we would be doing Cross Program Invocation or CPI for short in this program of ours. This essentially means that we would be calling functions of other Solana programs from our program. As you might have guessed, we would be calling the functions from the anchor_spl programs, which is the (abstracted) Anchor implementation of the spl-programs that you can find in the Solana Rust SDK. To look at the structure and explore the anchor_spl programs more, visit https://github.com/project-serum/anchor/tree/v0.17.0/spl. Reading through that would also help us understand the implementations later on. . Here pub means public and fn means function, implying that they are public functions that can be invoked from our program, ie it becomes a client-callable program function. The first argument of these functions is always Context&lt;T&gt; which consist of the solana accounts array and the program ID, which in essence is the required data to call just about any progarm on Solana. The next parameter of these functions is a u64 or an unsigned integer named amount, which we will be using as our the amount of our tokens in different functions. The ProgramResult is the return type of both these functions, which actually is just an easier method to serve function results and/or errors. . As discussed earlier, the Context parameter in each function is essentially a list of all the accounts that must be passed for the function to work as expected and the different structs you see in all Contexts such as ProxyTransfer, ProxyMintTo, etc will be defined later. . After defining the above four functions, your code should look something like this: . . Writing the logic for our functions . The logic of all of our functions would be very straight-forward. We would simply call the functions provided by anchor_spl with the correct parameters. That’s it. Simple. First update your code as the following: . pub fn proxy_transfer(ctx: Context&lt;ProxyTransfer&gt;, amount: u64) -&gt; ProgramResult { token::transfer(ctx.accounts.into(), amount) } pub fn proxy_mint_to(ctx: Context&lt;ProxyMintTo&gt;, amount: u64) -&gt; ProgramResult { token::mint_to(ctx.accounts.into(), amount) } pub fn proxy_burn(ctx: Context&lt;ProxyBurn&gt;, amount: u64) -&gt; ProgramResult { token::burn(ctx.accounts.into(), amount) } pub fn proxy_set_authority( ctx: Context&lt;ProxySetAuthority&gt;, authority_type: AuthorityType, new_authority: Option&lt;Pubkey&gt;, ) -&gt; ProgramResult { token::set_authority(ctx.accounts.into(), authority_type.into(), new_authority) } . With this, your coding screen would look something like: . . If you want to further investigate the functions that we called here, you can head over to the official docs of the anchor_spl crate. . Let’s learn to serialize and deserialize . You might already be familiar with the concept of enumerate or enum as that is a fairly language agnostic concept. However, if you are not, you can think of enums as a convenient way of naming states or conditions in your code. . Coming to what is serialization and deserialization, the good news is that Anchor does all the heavy lifting in this regards and we just need to know what these terms mean. Simple. So, serialize in general means to put together some data in a standard format and conversely deserealize means to break down a monolith into a standard format of many pieces of data. In terms of Anchor programming, AccountSerialize macro is used when a data structure can be serialized and stored into account storage, ie in an AccountInfo’s mutable data slice. Similarly, AccountDeserialize macro is used when a data structure can be de-serialized from binary format. This macro deserializes the instance from a given slice of bytes and updates the buffer to point at the remaining bytes. . Let’s see the above concepts in action. Write the following code outside of the #[program] module: . #[derive(AnchorSerialize, AnchorDeserialize)] pub enum AuthorityType { MintTokens, FreezeAccount, AccountOwner, CloseAccount } . Since literally everything on the Solana blockchain should be in form of an account, the derive macro is used to convert this enum in the format of an account. MintTokens here would represent the authority to mint new tokens, FreezeAccount to freeze accounts associated with the Mint, AccountOwner being the owners of a token account and CloseAccount representing the authority to close a token account. . After this, your screen would look something like: . . A small note about Accounts on Solana: . An account is not actually a wallet. Instead, it’s a way for the contract to persist data between calls. This includes information such as the count in our base_account, and also information about permissions on the account. Accounts pay rent in the form of lamports, and if it runs out, then the account is purged from the blockchain. Accounts with two years worth of rent attached are “rent-exempt” and can stay on the chain forever. . Defining our first account struct . In the first function, we used the ProxyTransfer struct, right? Now, let’s define it so that every relevant information along with the correct constraints on those information (accounts) can be passed to our proxy_transfer function. Write the following lines of codes below your Serialize and Deserialize code: . #[derive(Accounts)] pub struct ProxyTransfer&lt;&#39;info&gt; { #[account(signer)] pub authority: AccountInfo&lt;&#39;info&gt;, #[account(mut)] pub from: AccountInfo&lt;&#39;info&gt;, #[account(mut)] pub to: AccountInfo&lt;&#39;info&gt;, pub token_program: AccountInfo&lt;&#39;info&gt;, } . As discussed earlier, everything on Solana is an account, so we convert the ProxyTransfer struct (with all the relevant information for the proxy_transfer function) into an account using the derive account macro in the code above. The account signer macro you see is used to enforce the constraint that the authority is the one who signs the transaction (of calling the function) and the account mut macro is used to mark an account as mutable, ie, we want to persist changes in those accounts. Now coming onto the accounts themselves, these are a from account from which the transfer will take place and the to account, to which the tokens will go to. Then the authority is the one who should be able to execute these programs and the token_program is used to identify which function to call from the original crate. . After this, your code screen should look something like: . Small note about the Access Control macros . The Accounts macro implements the Accounts trait. Transforms a struct from the untrusted &amp;[AccountInfo] slice given to a Solana progam into a validated struct of deserialized account types . #[account]: It is an attribute macro implementing AccountSerialize and AccountDeserialize . Account Wrapper type for a deserialized account implementing AccountDeserialize. Using this type within an Accounts struct ensures the account is owned by the address defined by declare_id! where the inner account was defined. . With the above (and more Account Constraints and Access Controllers) we can define preconditions for our any instruction handler expecting a certain set of accounts, allowing us to more easily reason about the security of our programs. . Defining all other accounts . In a similar fashion to the ProxyTransfer account struct, we can define ProxyMintTo, ProxyBurn and ProxySetAuthority structs with the desired information (accounts) in each of them as required by their respective functions. It’ll be a fun exercise for you to open up the anchor-spl crate in Anchor’s github and try to figure out what would be structure of all the remaining account structs. . Once you have given it your best shot, comapre your structs with what we have here. Up first is the ProxyMintTo struct that will be used to call the proxy_mint_to function. . #[derive(Accounts)] pub struct ProxyMintTo&lt;&#39;info&gt; { #[account(signer)] pub authority: AccountInfo&lt;&#39;info&gt;, #[account(mut)] pub mint: AccountInfo&lt;&#39;info&gt;, #[account(mut)] pub to: AccountInfo&lt;&#39;info&gt;, pub token_program: AccountInfo&lt;&#39;info&gt;, } . This structure is pretty similar to the ProxyTransfer struct we defined in the last quest, right? The difference here is with the Mint account that is essentially the account of your token, and we would want that to be mutable since you can change supplies and so on. . Let’s tackle the ProxyBurn struct next that will be used to call the proxy_burn function. That would have a structure similar to this: . #[derive(Accounts)] pub struct ProxyBurn&lt;&#39;info&gt; { #[account(signer)] pub authority: AccountInfo&lt;&#39;info&gt;, #[account(mut)] pub mint: AccountInfo&lt;&#39;info&gt;, #[account(mut)] pub to: AccountInfo&lt;&#39;info&gt;, pub token_program: AccountInfo&lt;&#39;info&gt;, } . This structure is again pretty similar to our earlier structs, right? This also requires a mint account so that the function could know which token account has to be disabled. . With that let’s tackle the final account struct, the ProxySetAuthority and as you might have guessed, it is slightly different than the rest of the structs: . #[derive(Accounts)] pub struct ProxySetAuthority&lt;&#39;info&gt; { #[account(signer)] pub current_authority: AccountInfo&lt;&#39;info&gt;, #[account(mut)] pub account_or_mint: AccountInfo&lt;&#39;info&gt;, pub token_program: AccountInfo&lt;&#39;info&gt;, } . The accounts here are used to determine who the current authority is and whether that authority is the one who has signed this transaction or not and whether the new authority of the token account is going to be another account or a mint and then there’s the token program again to identify the correct program call. . After defining these accounts, your code screen should look something like this: . . Say hi to Cross Program Invocations (CPIs) . We did briefly talk about Cross Program Invocations, right? We don’t really need to get into the details of it and a simple understanding that CPIs are used to invoke instructions (functions) on another program. To do so on Anchor is pretty straight-forward since it does a lot of stuff for us under the hood. All we need to is: . Create a CpiContext object with the target instructin’s accounts and program. | To perform CPI, just use the cpi module | Accounts used for CPI are not specifically denoted as such with the CpiAccount label since v0.15. Accounts used for CPI are not fundamentally different from Program or Signer accounts except for their role and ownership in the specific context in which they are used. | So now with the above points in mind, let’s create implementation blocks impl which we will use to create the CpiContexts. We will later use these CpiContexts to invoke instructions from other programs. Create impl blocks for all account structs and write the following lines of code: . For ProxyTransfer . impl &lt;&#39;a, &#39;b, &#39;c, &#39;info&gt; From&lt;&amp;mut ProxyTransfer&lt;&#39;info&gt;&gt; for CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, Transfer&lt;&#39;info&gt;&gt; { } . For ProxyMintTo . impl&lt;&#39;a, &#39;b, &#39;c, &#39;info&gt; From&lt;&amp;mut ProxyMintTo&lt;&#39;info&gt;&gt; for CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, MintTo&lt;&#39;info&gt;&gt; { } . For ProxyBurn . impl&lt;&#39;a, &#39;b, &#39;c, &#39;info&gt; From&lt;&amp;mut ProxyBurn&lt;&#39;info&gt;&gt; for CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, Burn&lt;&#39;info&gt;&gt; { } . For ProxySetAuthority . impl&lt;&#39;a, &#39;b, &#39;c, &#39;info&gt; From&lt;&amp;mut ProxySetAuthority&lt;&#39;info&gt;&gt; for CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, SetAuthority&lt;&#39;info&gt;&gt; { } . After writing all these, your code screen should look something like this: . . Our first CPI . In the last quest we created all the impl (implementatuon) blocks for creating the CpiContexts that we will now use to call the functions from the other program. . Now, let me apologise very quickly, since I hadn’t been very transparent with you. Remember the strange into keyword we used earlier while writing our program functions without any explanation? Well, let me then introduce you to the wonders of the Rust language. The Rust language provides something called the From and Into traits which is essentially a cool way to convert typeA into typeB. Since we know from last quest that we require a CpiContext and a list of CpiAccounts to perform CPI and we also know that the functions that we had written in the very beginning are performing CPI, so logically we come to the conclusion that now we must write from implementations for those into that we used, so that they can be converted into the required format which is CpiContexts and CpiAccounts. . So, let’s see the first implementation of our from block that can help convert the parameters of the functions inside of our functions into CpiContext and CpiAccounts. Write down the below code: . impl&lt;&#39;a, &#39;b, &#39;c, &#39;info&gt; From&lt;&amp;mut ProxyTransfer&lt;&#39;info&gt;&gt; for CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, Transfer&lt;&#39;info&gt;&gt; { fn from(accounts: &amp;mut ProxyTransfer&lt;&#39;info&gt;) -&gt; CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, Transfer&lt;&#39;info&gt;&gt; { let cpi_accounts = Transfer { from: accounts.from.clone(), to: accounts.to.clone(), authority: accounts.authority.clone(), }; let cpi_program = accounts.token_program.clone(); CpiContext::new(cpi_program, cpi_accounts) } } . In the above code block we first create a list of our CpiAccounts called cpi_accounts, then we reference the program that we want to call with the variable name of cpi_program and create the new context using CpiContext::new. With this implementation our first program proxy_transfer is completely ready for doing CPIs. . Writing the above code, your code screen should look something like this: . . Implementing all other from blocks . Based on how we wrote the from implementation block for ProxyTransfer, we can write the from implementation blocks for ProxyMintTo, ProxyBurn and ProxySetAuthority in a very similar fashion. A good exercise for you would be to write all these implementations yourselves. . After your best attempt, match your code with the one that is provided below: . For ProxyMintTo . impl&lt;&#39;a, &#39;b, &#39;c, &#39;info&gt; From&lt;&amp;mut ProxyMintTo&lt;&#39;info&gt;&gt; for CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, MintTo&lt;&#39;info&gt;&gt; { fn from(accounts: &amp;mut ProxyMintTo&lt;&#39;info&gt;) -&gt; CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, MintTo&lt;&#39;info&gt;&gt; { let cpi_accounts = MintTo { mint: accounts.mint.clone(), to: accounts.to.clone(), authority: accounts.authority.clone(), }; let cpi_program = accounts.token_program.clone(); CpiContext::new(cpi_program, cpi_accounts) } } . For ProxyBurn . impl&lt;&#39;a, &#39;b, &#39;c, &#39;info&gt; From&lt;&amp;mut ProxyBurn&lt;&#39;info&gt;&gt; for CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, Burn&lt;&#39;info&gt;&gt; { fn from(accounts: &amp;mut ProxyBurn&lt;&#39;info&gt;) -&gt; CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, Burn&lt;&#39;info&gt;&gt; { let cpi_accounts = Burn { mint: accounts.mint.clone(), to: accounts.to.clone(), authority: accounts.authority.clone(), }; let cpi_program = accounts.token_program.clone(); CpiContext::new(cpi_program, cpi_accounts) } } . For ProxySetAuthority . impl&lt;&#39;a, &#39;b, &#39;c, &#39;info&gt; From&lt;&amp;mut ProxySetAuthority&lt;&#39;info&gt;&gt; for CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, SetAuthority&lt;&#39;info&gt;&gt; { fn from( accounts: &amp;mut ProxySetAuthority&lt;&#39;info&gt;, ) -&gt; CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, SetAuthority&lt;&#39;info&gt;&gt; { let cpi_accounts = SetAuthority { account_or_mint: accounts.account_or_mint.clone(), current_authority: accounts.current_authority.clone(), }; let cpi_program = accounts.token_program.clone(); CpiContext::new(cpi_program, cpi_accounts) } } . Hope that you fared well with writing your own implementations. Now, all the proxy functions that we wrote earlier are ready to work perfectly, except for one fine detail. Since, the implementations are more or less identical we can move onto the next quest, where we figure out the one final piece of this token-program puzzle before it becomes complete. . Now your screen should look something like: . The last implementation block . Remember the quest where we talked about enums and AccountSerialize and AccountDeserialize? Well, you might be wondering all is good with enums being used to refer to different states with convenient names, but where exactly did we define the states? You are correct, we did not define the states and in this quest we will be doing exactly the same. We will be assigning meaning to the names within enums using the concept of impl for blocks. . Write the below piece of code to implement the enum that we defined before defining the different account structs. The below skeleton would be later on filled to match the enum with corresponding meaningful values. . impl From&lt;AuthorityType&gt; for spl_token::instruction::AuthorityType { fn from(authority_ty: AuthorityType) -&gt; spl_token::instruction::AuthorityType { } } . This skeleton of the impl block is almost the same as previous blocks apart from the difference of from vs for. right? Good. Now the implementation going inside the block would be different since we are assiging values to a constant (enum) and not converting anything into anything. Update the above block with the following code: . impl From&lt;AuthorityType&gt; for spl_token::instruction::AuthorityType { fn from(authority_ty: AuthorityType) -&gt; spl_token::instruction::AuthorityType { match authority_ty { AuthorityType::MintTokens =&gt; spl_token::instruction::AuthorityType::MintTokens, AuthorityType::FreezeAccount =&gt; spl_token::instruction::AuthorityType::FreezeAccount, AuthorityType::AccountOwner =&gt; spl_token::instruction::AuthorityType::AccountOwner, AuthorityType::CloseAccount =&gt; spl_token::instruction::AuthorityType::CloseAccount, } } } . The match keyword is used in Rust and can be thought of as a sophisticated series of if-else block. Rust provides pattern matching via the match keyword, which can be used like a C switch. The first matching arm is evaluated and all possible values must be covered. . With this, your coding part for the Anchor program to create your own crypto-currency comes to an end with your screen looking something like: . . Checking our code . Before writing the tests to interact with our Anchor program, we can make sure that there are no errors in our code, by running the following command: . anchor build . If the code compiles without any error and gets built, that’s good news. Our Anchor program code is working fine and we can move ahead. If you are facing some errors, re-verify that you properly followed all instructions from all the quests. Also, if you are using a different version of anchor make sure that there no changes in the newer version for the code that we wrote, if there are revert to v0.17.0 or update your code accordingly. . Once your program is successfully built, you’ll get a screen similar to this: . . Importing the necessary code required for testing our contract . To begin testing, head over to tests/messengerapp.js and delete everything that’s written there. We are going to be writing our tests from scratch. The first step would be to import the necessary libraries and constants. To do that, use the following code: . const anchor = require(&quot;@project-serum/anchor&quot;); const assert = require(&quot;assert&quot;); . Now, since we will be using Mocha for testing our programs, we will create the skeleton of where we will be putting our tests. So, basically, how Mocha works is that it takes describe blocks as testing blocks and within those describe blocks there are numerous tests written using the it blocks. So, use the following code to create the skeleton: . describe(&#39;mymoneydapp&#39;, () =&gt; { const provider = anchor.Provider.local(); anchor.setProvider(provider); const program = anchor.workspace.Mymoneydapp; let mint = null; let from = null; let to = null; it(&quot;Initializes test state&quot;, async () =&gt; { }); it(&quot;Mints a token&quot;, async () =&gt; { }); it(&quot;Transfers a token&quot;, async () =&gt; { }); it(&quot;Burns a token&quot;, async () =&gt; { }); it(&quot;Set new mint authority&quot;, async () =&gt; { }); }); . Now, your screen should look something similar to: . The additional things that we coded there were the introduction of provider. The provider is the abstraction of a connection to the Solana network. In the test, the Anchor framework will create the provider for us based on the environment (anchor.Provider.local()). . Now, the program is an abstraction that combines the Provider, idl, and the programID (which is generated when the program is built) and allows us to call RPC methods against our program. . Apart from that we have initialized three variables, namely mint, from and to which we will use throughout our testing. . When we have the above things, we can start calling functions in our program, which is what we will be doing in our next sub-quest. . The SPL Token testing boilerplate . Ideally, while testing this contract, we should have been able to simply use @solana/web3.js to interact with our Anchor program, but it so happens that Anchor is built off a lot of components from Serum and is thus dependent on Serum. What that also means is that, we cannot simply import and use @solana/web3.js until @project-serum/serum uses the same version of @solana/web3.js as anchor. . So, to mimick the functions from @solana/web3.js, simply copy and paste the following code. Consider this code as the SPL token client boilerplate for test initialization. Paste this code right below the describe block we wrote in the last sub-quest. . const serumCmn = require(&quot;@project-serum/common&quot;); const TokenInstructions = require(&quot;@project-serum/serum&quot;).TokenInstructions; const TOKEN_PROGRAM_ID = new anchor.web3.PublicKey( TokenInstructions.TOKEN_PROGRAM_ID.toString() ); async function getTokenAccount(provider, addr) { return await serumCmn.getTokenAccount(provider, addr); } async function getMintInfo(provider, mintAddr) { return await serumCmn.getMintInfo(provider, mintAddr); } async function createMint(provider, authority) { if (authority === undefined) { authority = provider.wallet.publicKey; } const mint = anchor.web3.Keypair.generate(); const instructions = await createMintInstructions( provider, authority, mint.publicKey ); const tx = new anchor.web3.Transaction(); tx.add(...instructions); await provider.send(tx, [mint]); return mint.publicKey; } async function createMintInstructions(provider, authority, mint) { let instructions = [ anchor.web3.SystemProgram.createAccount({ fromPubkey: provider.wallet.publicKey, newAccountPubkey: mint, space: 82, lamports: await provider.connection.getMinimumBalanceForRentExemption(82), programId: TOKEN_PROGRAM_ID, }), TokenInstructions.initializeMint({ mint, decimals: 0, mintAuthority: authority, }), ]; return instructions; } async function createTokenAccount(provider, mint, owner) { const vault = anchor.web3.Keypair.generate(); const tx = new anchor.web3.Transaction(); tx.add( ...(await createTokenAccountInstrs(provider, vault.publicKey, mint, owner)) ); await provider.send(tx, [vault]); return vault.publicKey; } async function createTokenAccountInstrs( provider, newAccountPubkey, mint, owner, lamports ) { if (lamports === undefined) { lamports = await provider.connection.getMinimumBalanceForRentExemption(165); } return [ anchor.web3.SystemProgram.createAccount({ fromPubkey: provider.wallet.publicKey, newAccountPubkey, space: 165, lamports, programId: TOKEN_PROGRAM_ID, }), TokenInstructions.initializeAccount({ account: newAccountPubkey, mint, owner, }), ]; } . With this, your code screen should look something like: . Before moving onto the next quest, notice that we are using two new packages in the above code. You can download them using the following command: . npm install @project-serum/common @project-serum/serum . Successfull installation shall lead to this kind of screen: . . Initializing the test state . Let us fill in the first it block which isn’t exactly testing anything, but is essential as it is setting the state of mint, the from account and the to account that will be used throughout all the tests. Let’s see how we can set the states in the first it block. Update the first it block of code as follows: . it(&quot;Initializes test state&quot;, async () =&gt; { mint = await createMint(provider); from = await createTokenAccount(provider, mint, provider.wallet.publicKey); to = await createTokenAccount(provider, mint, provider.wallet.publicKey); }); . With this, your code screen should look something like this: . . All the functions used during the initialization have self-explanatory names, however if you want more depth of understanding and more clarity go through the boilerplate code that we copy pasted in the last quest. . Writing the test to check minting of our token . The method to call the functions of our program is pretty straight-forward. We will use the program RPCs (Remote procedure calls) to access the function. The method to do that is call functions using the format: program.rpc.proxyMintTo where proxyMintTo can be any of the functions that we have in the porgram (Solana contract) that we are calling. Let’s now write the test to mint a token. Write the below code to update the Mints a token it block. . it(&quot;Mints a token&quot;, async () =&gt; { await program.rpc.proxyMintTo(new anchor.BN(1000), { accounts: { authority: provider.wallet.publicKey, mint, to: from, tokenProgram: TokenInstructions.TOKEN_PROGRAM_ID, }, }); const fromAccount = await getTokenAccount(provider, from); assert.ok(fromAccount.amount.eq(new anchor.BN(1000))); }); . What’s happening in the test is pretty straight-forward. We first call the proxyMintTo function from our program (remember, the function names get converted to camel case from snake case when interacting through JS here) with amount being 1000, where BN stands for BigNumber and the list of accounts that we specified in the context of this function. Then, once the function has executed, we grab the tokenAccount from using the getTokenAccount function and then check it’s balance which should be equal to the number of tokens we just minted and sent to the from address. . After this, your code screen should look something like this: . Test to transfer and burn our tokens . Now in this quest, let’s test if we can correctly transfer our tokens and also if we can burn some of our supply or not. Let’s directly jump into the code to transfer a token. Write the code below to update the Transfers a token it block: . it(&quot;Transfers a token&quot;, async () =&gt; { await program.rpc.proxyTransfer(new anchor.BN(400), { accounts: { authority: provider.wallet.publicKey, to, from, tokenProgram: TokenInstructions.TOKEN_PROGRAM_ID, }, }); const fromAccount = await getTokenAccount(provider, from); const toAccount = await getTokenAccount(provider, to); assert.ok(fromAccount.amount.eq(new anchor.BN(600))); assert.ok(toAccount.amount.eq(new anchor.BN(400))); }); . As discussed earlier, we use the rpc handlers to call the proxy_transfer function with the required list of accounts and 400 as the amount from the from account to the to account. Since we minted 1000 tokens, after this transfer, the from account should have 600 (1000 - 400) tokens and the to account should have 400 tokens with them. This is exactly what we check in the test after the execution of the proxy_transfer function by grabbing both the accounts and then checking their balances. . Now, similarly to test whether we can burn our tokens or not, write the code below and update the Burns a token it block. . it(&quot;Burns a token&quot;, async () =&gt; { await program.rpc.proxyBurn(new anchor.BN(350), { accounts: { authority: provider.wallet.publicKey, mint, to, tokenProgram: TokenInstructions.TOKEN_PROGRAM_ID, }, }); const toAccount = await getTokenAccount(provider, to); assert.ok(toAccount.amount.eq(new anchor.BN(50))); }); . As discussed earlier, we use the rpc handlers to call the proxy_transfer function with the required list of accounts and 350 as the amount from the to account. Since the to account received 400 tokens in just the last test, if we burn 350 tokens then that account should be left with 50 tokens which is exactly what we are testing in this test. . After writing the above tests, you’ll have a code screen that looks something like: . . Testing the transfer of authority . In this quest, let’s test if we can correctly transfer the authority of our token to some other account correctly or not. Let’s directly jump into the code to transfer the ownership of our token. Write the code below to update the Setnew mint authority it block: . it(&quot;Set new mint authority&quot;, async () =&gt; { const newMintAuthority = anchor.web3.Keypair.generate(); await program.rpc.proxySetAuthority( { mintTokens: {} }, newMintAuthority.publicKey, { accounts: { accountOrMint: mint, currentAuthority: provider.wallet.publicKey, tokenProgram: TokenInstructions.TOKEN_PROGRAM_ID, }, } ); const mintInfo = await getMintInfo(provider, mint); assert.ok(mintInfo.mintAuthority.equals(newMintAuthority.publicKey)); }); . As discussed earlier, we use the rpc handlers to call the proxy_set_authority function with the required list of accounts, the new authority and the authority_type which is that of mintTokens. The address for the new mint authority is generated using the web3 function called Keypair.generate. Later after the execution of the function, we check the mint authority of our token and it should ideally check out to be the new addresss we just generated. . Running the tests . Now, that we are done running all the tests, make sure that your local validator is not running. That means make sure that the solana-test-validator process is not running and the network is set as localhost by inspecting the results of solana config get. Once all this is done, it is time for us to actually test the progarm that we wrote. To do that use the following command: . anchor test . If all the tests pass, you’ll get a screen similar to this: . . If you get some errors, try debugging those using the error messages you get. Make sure you have accurately followed the code presented in the quests. You are on the same Anchor version as that followed in the quest. With that you’ll find your way out of most of the errors that you might run into. . Congratulations on succesfully creating your own token and testing its functioning :D .",
            "url": "https://saxenism.com/solana/anchor/tutorial/web3/2021/11/24/Solana-Tutorial-Create-Tokens.html",
            "relUrl": "/solana/anchor/tutorial/web3/2021/11/24/Solana-Tutorial-Create-Tokens.html",
            "date": " • Nov 24, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "Enums",
            "content": "What are enums in Solidity? . enums or members of enumerated lists, in Solidity work much like enums in any other language. For me, it is basically a tool to reduce the stress on my mental RAM while writing code or smart contracts. . Typical Use Case: . Suppose you want to give your user an option to choose his favorite squad among 9 available options. The available options would be: . Black Bull | Silver Eagle | Blue Rose | Golden Dawn | Green Mantis | Crimson Lion | Aqua Deer | Purple Orca | Coral Peacock | . Suppose you intend to use the variable favSquad to denote your user’s favorite Black Clover squad and use that variable in subsequent logic. . One option (particularly messy one) would be to allow users to enter strings that denote their favorite squads, but that would bring forth a whole new hell of matching proper cases (upper cases and lower cases), also someone could enter a string that is out of scope, like Spade Kingdom for example. . Another option would be to assign numbers to each squad (0-8) based on their index, most probably like a mapping. That would work, but you’ll have to always remember which number represents which squad while coding, which would be pretty uncomfortable. . Hence, we pivot towards using enums. Enums restrict a variable to have one of only a few predefined values. The values in this enumerated list are called enums. With the use of enums it is possible to reduce the number of bugs in your code. This helps you to not make a mistake, to enter something out of the domain, while entering data and also improves the program readability. . For example, this is how we would use enums: . pragma solidity ^ 0.8.0; contract testEnums { enum CloverSquad { BlackBull, GoldenDawn, SilverEagle, BlueRose, CrimsonLion, GreenMantis, CoralPeacock, PurpleOrca, AquaDeer } CloverSquad favSquad; CloverSquad firstRankedSquad = CloverSquad.GoldenDawn; function getFirstRankedSquad() public view returns (CloverSquad) { return firstRandkedSquad; } } . Taking enum inputs and checking invalid inputs . A question that might arise in your minds (it did in mine too 😅) is how do we take enums as input from the user of our smart contract. We do this by typecasting the enums and checking if it is out of range or not. . Example: . // Yes, you can use your enums in mappings. mapping (address =&gt; CloverSquad) public playerSquad; function selectFavoriteSquad(uint userFavSquad) external { require(userFavSquad &lt;= uint(CloverSquads.AquaDeer), &quot;Choose from 0 to 8&quot;); playerSquad[msg.sender] = CloverSquad(userFavSquad); // Further Logic.... } . Further Reading . That is about everything that you will need to know about enums to be well on your way, but if you really want to get deeper into enums, I would suggest reading this incredibly detailed article on enums. . Thank you &amp; Godspeed. .",
            "url": "https://saxenism.com/web3/solidity/enums/beginner/2021/06/17/Enums-In-Solidity.html",
            "relUrl": "/web3/solidity/enums/beginner/2021/06/17/Enums-In-Solidity.html",
            "date": " • Jun 17, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "CryptoZombies - Lesson 5",
            "content": "Lesson 5: . Tokens on Ethereum: A token on Ethereum is basically just a smart contract that follows some common rules — namely it implements a standard set of functions that all other token contracts share. The token standard that’s a much better fit for crypto-collectibles like CryptoZombies — is called ERC721 tokens. ERC721 tokens are not interchangeable since each one is assumed to be unique, and are not divisible. You can only trade them in whole units, and each one has a unique ID. using a standard like ERC721 has the benefit that we don’t have to implement the auction or escrow logic within our contract that determines how players can trade / sell our zombies. If we conform to the spec, someone else could build an exchange platform for crypto-tradable ERC721 assets, and our ERC721 zombies would be usable on that platform. So there are clear benefits to using a token standard instead of rolling your own trading logic. . | The contract of ERC721 standard looks pretty much like an interface, waiting to be implemented: contract ERC721 { event Transfer(address indexed _from, address indexed _to, uint256 indexed _tokenId); event Approval(address indexed _owner, address indexed _approved, uint256 indexed _tokenId); function balanceOf(address _owner) external view returns (uint256); function ownerOf(uint256 _tokenId) external view returns (address); function transferFrom(address _from, address _to, uint256 _tokenId) external payable; function approve(address _approved, uint256 _tokenId) external payable; } . | In Solidity, we can inheirt from multiple contracts. . | To avoid overflows and underflows, we use the SafeMath library. A library is a special type of contract in Solidity. One of the things it is useful for is to attach functions to native data types. For example, with the SafeMath library, we’ll use the syntax using SafeMath for uint256. The SafeMath library has 4 functions — add, sub, mul, and div. And now we can access these functions from uint256 as follows: using SafeMath for uint256; uint256 a = 5; uint256 b = a.add(3); // 5 + 3 = 8 uint256 c = a.mul(2); // 5 * 2 = 10 . | assert is similar to require, where it will throw an error if false. The difference between assert and require is that require will refund the user the rest of their gas when a function fails, whereas assert will not. So most of the time you want to use require in your code; assert is typically used when something has gone horribly wrong with the code (like a uint overflow). . | The standard in the Solidity community is to use a format called natspec. | Also, thanks for Loom Network for bringing such awesome animations to us :D . . Solidity code from Lesson 5: . erc721.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; contract ERC721 { event Transfer(address indexed _from, address indexed _to, uint256 indexed _tokenId); event Approval(address indexed _owner, address indexed _approved, uint256 indexed _tokenId); function balanceOf(address _owner) external view returns (uint256); function ownerOf(uint256 _tokenId) external view returns (address); function transferFrom(address _from, address _to, uint256 _tokenId) external payable; function approve(address _approved, uint256 _tokenId) external payable; } . safemath.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; /** * @title SafeMath * @dev Math operations with safety checks that throw on error */ library SafeMath { /** * @dev Multiplies two numbers, throws on overflow. */ function mul(uint256 a, uint256 b) internal pure returns (uint256) { if (a == 0) { return 0; } uint256 c = a * b; assert(c / a == b); return c; } /** * @dev Integer division of two numbers, truncating the quotient. */ function div(uint256 a, uint256 b) internal pure returns (uint256) { // assert(b &gt; 0); // Solidity automatically throws when dividing by 0 uint256 c = a / b; // assert(a == b * c + a % b); // There is no case in which this doesn&#39;t hold return c; } /** * @dev Subtracts two numbers, throws on overflow (i.e. if subtrahend is greater than minuend). */ function sub(uint256 a, uint256 b) internal pure returns (uint256) { assert(b &lt;= a); return a - b; } /** * @dev Adds two numbers, throws on overflow. */ function add(uint256 a, uint256 b) internal pure returns (uint256) { uint256 c = a + b; assert(c &gt;= a); return c; } } /** * @title SafeMath32 * @dev SafeMath library implemented for uint32 */ library SafeMath32 { function mul(uint32 a, uint32 b) internal pure returns (uint32) { if (a == 0) { return 0; } uint32 c = a * b; assert(c / a == b); return c; } function div(uint32 a, uint32 b) internal pure returns (uint32) { // assert(b &gt; 0); // Solidity automatically throws when dividing by 0 uint32 c = a / b; // assert(a == b * c + a % b); // There is no case in which this doesn&#39;t hold return c; } function sub(uint32 a, uint32 b) internal pure returns (uint32) { assert(b &lt;= a); return a - b; } function add(uint32 a, uint32 b) internal pure returns (uint32) { uint32 c = a + b; assert(c &gt;= a); return c; } } /** * @title SafeMath16 * @dev SafeMath library implemented for uint16 */ library SafeMath16 { function mul(uint16 a, uint16 b) internal pure returns (uint16) { if (a == 0) { return 0; } uint16 c = a * b; assert(c / a == b); return c; } function div(uint16 a, uint16 b) internal pure returns (uint16) { // assert(b &gt; 0); // Solidity automatically throws when dividing by 0 uint16 c = a / b; // assert(a == b * c + a % b); // There is no case in which this doesn&#39;t hold return c; } function sub(uint16 a, uint16 b) internal pure returns (uint16) { assert(b &lt;= a); return a - b; } function add(uint16 a, uint16 b) internal pure returns (uint16) { uint16 c = a + b; assert(c &gt;= a); return c; } } . zombieownership.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./zombieattack.sol&quot;; import &quot;./erc721.sol&quot;; import &quot;./safemath.sol&quot;; contract ZombieOwnership is ZombieAttack, ERC721 { using SafeMath for uint256; mapping (uint =&gt; address) zombieApprovals; function balanceOf(address _owner) external view returns (uint256) { return ownerZombieCount[_owner]; } function ownerOf(uint256 _tokenId) external view returns (address) { return zombieToOwner[_tokenId]; } function _transfer(address _from, address _to, uint256 _tokenId) private { ownerZombieCount[_to] = ownerZombieCount[_to].add(1); ownerZombieCount[msg.sender] = ownerZombieCount[msg.sender].sub(1); zombieToOwner[_tokenId] = _to; emit Transfer(_from, _to, _tokenId); } function transferFrom(address _from, address _to, uint256 _tokenId) external payable { require (zombieToOwner[_tokenId] == msg.sender || zombieApprovals[_tokenId] == msg.sender); _transfer(_from, _to, _tokenId); } function approve(address _approved, uint256 _tokenId) external payable onlyOwnerOf(_tokenId) { zombieApprovals[_tokenId] = _approved; emit Approval(msg.sender, _approved, _tokenId); } } . zombieattack.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./zombiehelper.sol&quot;; contract ZombieAttack is ZombieHelper { uint randNonce = 0; uint attackVictoryProbability = 70; function randMod(uint _modulus) internal returns(uint) { randNonce = randNonce.add(1); return uint(keccak256(abi.encodePacked(now, msg.sender, randNonce))) % _modulus; } function attack(uint _zombieId, uint _targetId) external onlyOwnerOf(_zombieId) { Zombie storage myZombie = zombies[_zombieId]; Zombie storage enemyZombie = zombies[_targetId]; uint rand = randMod(100); if (rand &lt;= attackVictoryProbability) { myZombie.winCount = myZombie.winCount.add(1); myZombie.level = myZombie.level.add(1); enemyZombie.lossCount = enemyZombie.lossCount.add(1); feedAndMultiply(_zombieId, enemyZombie.dna, &quot;zombie&quot;); } else { myZombie.lossCount = myZombie.lossCount.add(1); enemyZombie.winCount = enemyZombie.winCount.add(1); _triggerCooldown(myZombie); } } } . zombiefactory.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./ownable.sol&quot;; import &quot;./safemath.sol&quot;; contract ZombieFactory is Ownable { using SafeMath for uint256; using SafeMath32 for uint32; using SafeMath16 for uint16; event NewZombie(uint zombieId, string name, uint dna); uint dnaDigits = 16; uint dnaModulus = 10 ** dnaDigits; uint cooldownTime = 1 days; struct Zombie { string name; uint dna; uint32 level; uint32 readyTime; uint16 winCount; uint16 lossCount; } Zombie[] public zombies; mapping (uint =&gt; address) public zombieToOwner; mapping (address =&gt; uint) ownerZombieCount; function _createZombie(string memory _name, uint _dna) internal { uint id = zombies.push(Zombie(_name, _dna, 1, uint32(now + cooldownTime), 0, 0)) - 1; zombieToOwner[id] = msg.sender; ownerZombieCount[msg.sender] = ownerZombieCount[msg.sender].add(1); emit NewZombie(id, _name, _dna); } function _generateRandomDna(string memory _str) private view returns (uint) { uint rand = uint(keccak256(abi.encodePacked(_str))); return rand % dnaModulus; } function createRandomZombie(string memory _name) public { require(ownerZombieCount[msg.sender] == 0); uint randDna = _generateRandomDna(_name); randDna = randDna - randDna % 100; _createZombie(_name, randDna); } } . zombiefeeding.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./zombiefactory.sol&quot;; contract KittyInterface { function getKitty(uint256 _id) external view returns ( bool isGestating, bool isReady, uint256 cooldownIndex, uint256 nextActionAt, uint256 siringWithId, uint256 birthTime, uint256 matronId, uint256 sireId, uint256 generation, uint256 genes ); } contract ZombieFeeding is ZombieFactory { KittyInterface kittyContract; modifier onlyOwnerOf(uint _zombieId) { require(msg.sender == zombieToOwner[_zombieId]); _; } function setKittyContractAddress(address _address) external onlyOwner { kittyContract = KittyInterface(_address); } function _triggerCooldown(Zombie storage _zombie) internal { _zombie.readyTime = uint32(now + cooldownTime); } function _isReady(Zombie storage _zombie) internal view returns (bool) { return (_zombie.readyTime &lt;= now); } function feedAndMultiply(uint _zombieId, uint _targetDna, string memory _species) internal onlyOwnerOf(_zombieId) { Zombie storage myZombie = zombies[_zombieId]; require(_isReady(myZombie)); _targetDna = _targetDna % dnaModulus; uint newDna = (myZombie.dna + _targetDna) / 2; if (keccak256(abi.encodePacked(_species)) == keccak256(abi.encodePacked(&quot;kitty&quot;))) { newDna = newDna - newDna % 100 + 99; } _createZombie(&quot;NoName&quot;, newDna); _triggerCooldown(myZombie); } function feedOnKitty(uint _zombieId, uint _kittyId) public { uint kittyDna; (,,,,,,,,,kittyDna) = kittyContract.getKitty(_kittyId); feedAndMultiply(_zombieId, kittyDna, &quot;kitty&quot;); } } . zombiehelper.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./zombiefeeding.sol&quot;; contract ZombieHelper is ZombieFeeding { uint levelUpFee = 0.001 ether; modifier aboveLevel(uint _level, uint _zombieId) { require(zombies[_zombieId].level &gt;= _level); _; } function withdraw() external onlyOwner { address _owner = owner(); _owner.transfer(address(this).balance); } function setLevelUpFee(uint _fee) external onlyOwner { levelUpFee = _fee; } function levelUp(uint _zombieId) external payable { require(msg.value == levelUpFee); zombies[_zombieId].level = zombies[_zombieId].level.add(1); } function changeName(uint _zombieId, string calldata _newName) external aboveLevel(2, _zombieId) onlyOwnerOf(_zombieId) { zombies[_zombieId].name = _newName; } function changeDna(uint _zombieId, uint _newDna) external aboveLevel(20, _zombieId) onlyOwnerOf(_zombieId) { zombies[_zombieId].dna = _newDna; } function getZombiesByOwner(address _owner) external view returns(uint[] memory) { uint[] memory result = new uint[](ownerZombieCount[_owner]); uint counter = 0; for (uint i = 0; i &lt; zombies.length; i++) { if (zombieToOwner[i] == _owner) { result[counter] = i; counter++; } } return result; } } .",
            "url": "https://saxenism.com/web3/solidity/cryptozombies/beginner/2021/06/16/CryptoZombies-Lesson-5.html",
            "relUrl": "/web3/solidity/cryptozombies/beginner/2021/06/16/CryptoZombies-Lesson-5.html",
            "date": " • Jun 16, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "CryptoZombies - Lesson 4",
            "content": "Lesson 4: . view tells us that by running the functions, no data will be saved/changed. pure tells us that not only does the function not save any data to the blockchain, but it also doens’t read any data from the blockchain. Both of these don’t cost any gas to call if they’re called from outside the contract, but the do cost gas if called internally by another function because the calling function is eventually making changes on the blockchain. | The function modifiers can all be stacked together on a function definition, as follows: function test() external view onlyOwner anotherModifier { // Some function-y stuff } . | The payable modifier: They are a special type of functions that can recieve Ether. In Ethereum, because both the money (Ether), the data (transaction payload), and the contract code itself all live on Ethereum, it’s possible for you to call a function and pay money to the contract at the same time. This allows us to have some really cool logic, such as: requiring a certain payment to the contract in order to execute a function. Here’s an example: contract OnlineStore { function buySomething () external payable { require(msg.value == 0.01 ether); //ether is an inbuilt uint; transferStuff(msg.sender); } } . msg.value is a way to see how much Ether was sent to the contract. If a function is not marked as payable, and you try to send Ether to it, the function will reject your transaction. . | The payment can only be done to a data type that’s called address payable. Example: function withdraw() external onlyOwner() { address payable _owner = address(uint16(owner())); _owner.transfer(address(this).balance); } address(this).balance will return the total balance stored on the contract. . | A make-shift way of generating random numbers in Solidity is as follows: // Generate a random number between 1 and 100: uint randNonce = 0; uint random = uint(keccak256(abi.encodePacked(now, msg.sender, randNonce))) % 100; randNonce++; uint random2 = uint(keccak256(abi.encodePacked(now, msg.sender, randNonce))) % 100; . But, this is unsafe, because technically, this can be hacked. How? Read on: In Ethereum, when you call a function on a contract, you broadcast it to a node or nodes on the network as a transaction. The nodes on the network then collect a bunch of transactions, try to be the first to solve a computationally-intensive mathematical problem as a “Proof of Work”, and then publish that group of transactions along with their Proof of Work (PoW) as a block to the rest of the network. Once a node has solved the PoW, the other nodes stop trying to solve the PoW, verify that the other node’s list of transactions are valid, and then accept the block and move on to trying to solve the next block. This makes our random number function exploitable. Let’s say we had a coin flip contract —heads you double your money, tails you lose everything. Let’s say it used the above random function to determine heads or tails. (random &gt;= 50 is heads, random &lt; 50 is tails). If I were running a node, I could publish a transaction only to my own node and not share it. I could then run the coin flip function to see if I won — and if I lost, choose not to include that transaction in the next block I’m solving. I could keep doing this indefinitely until I finally won the coin flip and solved the next block, and profit. . | One relatively safe method is to use an Oracle to access a random number from outside the Ethereum blockchain | . Solidity Code from Lesson 4 . zombieattack.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./zombiehelper.sol&quot;; contract ZombieAttack is ZombieHelper { uint randNonce = 0; uint attackVictoryProbability = 70; function randMod(uint _modulus) internal returns(uint) { randNonce++; return uint(keccak256(abi.encodePacked(now, msg.sender, randNonce))) % _modulus; } function attack(uint _zombieId, uint _targetId) external ownerOf(_zombieId) { Zombie storage myZombie = zombies[_zombieId]; Zombie storage enemyZombie = zombies[_targetId]; uint rand = randMod(100); if (rand &lt;= attackVictoryProbability) { myZombie.winCount++; myZombie.level++; enemyZombie.lossCount++; feedAndMultiply(_zombieId, enemyZombie.dna, &quot;zombie&quot;); } else { myZombie.lossCount++; enemyZombie.winCount++; _triggerCooldown(myZombie); } } } . zombiehelper.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./zombiefeeding.sol&quot;; contract ZombieHelper is ZombieFeeding { uint levelUpFee = 0.001 ether; modifier aboveLevel(uint _level, uint _zombieId) { require(zombies[_zombieId].level &gt;= _level); _; } function withdraw() external onlyOwner { address _owner = owner(); _owner.transfer(address(this).balance); } function setLevelUpFee(uint _fee) external onlyOwner { levelUpFee = _fee; } function levelUp(uint _zombieId) external payable { require(msg.value == levelUpFee); zombies[_zombieId].level++; } function changeName(uint _zombieId, string calldata _newName) external aboveLevel(2, _zombieId) ownerOf(_zombieId) { zombies[_zombieId].name = _newName; } function changeDna(uint _zombieId, uint _newDna) external aboveLevel(20, _zombieId) ownerOf(_zombieId) { zombies[_zombieId].dna = _newDna; } function getZombiesByOwner(address _owner) external view returns(uint[] memory) { uint[] memory result = new uint[](ownerZombieCount[_owner]); uint counter = 0; for (uint i = 0; i &lt; zombies.length; i++) { if (zombieToOwner[i] == _owner) { result[counter] = i; counter++; } } return result; } } . zombiefactory.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./ownable.sol&quot;; contract ZombieFactory is Ownable { event NewZombie(uint zombieId, string name, uint dna); uint dnaDigits = 16; uint dnaModulus = 10 ** dnaDigits; uint cooldownTime = 1 days; struct Zombie { string name; uint dna; uint32 level; uint32 readyTime; uint16 winCount; uint16 lossCount; } Zombie[] public zombies; mapping (uint =&gt; address) public zombieToOwner; mapping (address =&gt; uint) ownerZombieCount; function _createZombie(string memory _name, uint _dna) internal { uint id = zombies.push(Zombie(_name, _dna, 1, uint32(now + cooldownTime), 0, 0)) - 1; zombieToOwner[id] = msg.sender; ownerZombieCount[msg.sender]++; emit NewZombie(id, _name, _dna); } function _generateRandomDna(string memory _str) private view returns (uint) { uint rand = uint(keccak256(abi.encodePacked(_str))); return rand % dnaModulus; } function createRandomZombie(string memory _name) public { require(ownerZombieCount[msg.sender] == 0); uint randDna = _generateRandomDna(_name); randDna = randDna - randDna % 100; _createZombie(_name, randDna); } } . zombiefeeding.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./ownable.sol&quot;; contract ZombieFactory is Ownable { event NewZombie(uint zombieId, string name, uint dna); uint dnaDigits = 16; uint dnaModulus = 10 ** dnaDigits; uint cooldownTime = 1 days; struct Zombie { string name; uint dna; uint32 level; uint32 readyTime; uint16 winCount; uint16 lossCount; } Zombie[] public zombies; mapping (uint =&gt; address) public zombieToOwner; mapping (address =&gt; uint) ownerZombieCount; function _createZombie(string memory _name, uint _dna) internal { uint id = zombies.push(Zombie(_name, _dna, 1, uint32(now + cooldownTime), 0, 0)) - 1; zombieToOwner[id] = msg.sender; ownerZombieCount[msg.sender]++; emit NewZombie(id, _name, _dna); } function _generateRandomDna(string memory _str) private view returns (uint) { uint rand = uint(keccak256(abi.encodePacked(_str))); return rand % dnaModulus; } function createRandomZombie(string memory _name) public { require(ownerZombieCount[msg.sender] == 0); uint randDna = _generateRandomDna(_name); randDna = randDna - randDna % 100; _createZombie(_name, randDna); } } . ownable.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; /** * @title Ownable * @dev The Ownable contract has an owner address, and provides basic authorization control * functions, this simplifies the implementation of &quot;user permissions&quot;. */ contract Ownable { address private _owner; event OwnershipTransferred( address indexed previousOwner, address indexed newOwner ); /** * @dev The Ownable constructor sets the original `owner` of the contract to the sender * account. */ constructor() internal { _owner = msg.sender; emit OwnershipTransferred(address(0), _owner); } /** * @return the address of the owner. */ function owner() public view returns(address) { return _owner; } /** * @dev Throws if called by any account other than the owner. */ modifier onlyOwner() { require(isOwner()); _; } /** * @return true if `msg.sender` is the owner of the contract. */ function isOwner() public view returns(bool) { return msg.sender == _owner; } /** * @dev Allows the current owner to relinquish control of the contract. * @notice Renouncing to ownership will leave the contract without an owner. * It will not be possible to call the functions with the `onlyOwner` * modifier anymore. */ function renounceOwnership() public onlyOwner { emit OwnershipTransferred(_owner, address(0)); _owner = address(0); } /** * @dev Allows the current owner to transfer control of the contract to a newOwner. * @param newOwner The address to transfer ownership to. */ function transferOwnership(address newOwner) public onlyOwner { _transferOwnership(newOwner); } /** * @dev Transfers control of the contract to a newOwner. * @param newOwner The address to transfer ownership to. */ function _transferOwnership(address newOwner) internal { require(newOwner != address(0)); emit OwnershipTransferred(_owner, newOwner); _owner = newOwner; } } .",
            "url": "https://saxenism.com/web3/solidity/cryptozombies/beginner/2021/06/15/CryptoZombies-Lesson-4.html",
            "relUrl": "/web3/solidity/cryptozombies/beginner/2021/06/15/CryptoZombies-Lesson-4.html",
            "date": " • Jun 15, 2021"
        }
        
    
  
    
        ,"post12": {
            "title": "CryptoZombies - Lesson 3",
            "content": "Lesson 3: . After you deploy a contract to Ethereum, it is immutable. It can never be modified/updated again. For this reason, if often makes sense to have functions that will allow you to update key portions of your dApp | Ownable contract: Owners(contract creators) have special priviliges. It has the following three functions: a. When a contract is deployed, its constructor sets the owner to msg.sender (the person who deployed it) b. It adds an onlyOwner modifier, which can restirct access to certain functions to only the owner c. It allows you to transfer the contract to a new owner | Once you inherit from the Ownable contract, you can use the onlyOwner function modifier. This ensures that the function caller is indeed the contract owner or not | In Solidity, your users have to pay every time they execute a function on your DApp using a currency called gas. So, basically, users have to spend ETH in order to execute functions on your DApp. | How much gas is required to execute a function depends on how complex that function’s logic is. Each individual operation has a gas cost based roughly on how much computing resources will be required to perform that operation. The total gas cost of your function is the sum of the gas costs of all its individual operations. Therefore, code optimization is much much more important in Ethereum than in other programming languages. Because, if your code is slopp, then your users are going to pay a premium to execute your functions – and this could add up to millions of dollars in unnecessary fees across thousand of users. | Choosing either of uint8, uint16, uint32, uint256 will result in the same gas fee because Ethereum reserves the same space for each, irrespective of what uint you choose. But you can save on costs when working with multiple uints inside of a struct. Also, for this to happen, you would want to cluster identical data types together (ie put them next to each other in the struct) | Solidity provides some native units for dealing with time. The variable now will return the current unix timestamp of the latest block (the number of seconds that have passed since January 1st 1970). Solidity also contains the time units seconds, minutes, hours, days, weeks and years. | We can pass a storage pointer to a struct as an argument to a private or internal function. | An important security practice is to examine all your public and external functions, and try to think of ways users might abuse them. Because, unless these functions have a modifier like onlyOwner, any user can call them and pass them any data they want to. | The custom function modifier (like onlyOwner) can also take some parameters. The following example will clear things up: mapping (uint =&gt; uint) public age; // Modifier that requires this user to be older than a certain age: modifier olderThan(uint _age, uint _userId) { require(age[_userId] &gt;= _age); _; } function driveCar(uint _userId) public olderThan(16, _userId) { // Some function logic } . | Remember how we used memory pointer type along with string in function parameters. Similar to memory we have calldata but it’s only available to external functions | Since view functions only needs to query your local Ethereum node to run the function, it doesn’t actually have to create a transaction on the blockchain, which would need to run on every single node, and cost gas. Therefore, view functions don’t cost any gas when they’re called externally by a user. Optimize your DApp’s gas usage for your users by using read-only external view functions wherever possible. If a view function is called internally from another function in the same contract that is not a view function, it will still cost gas. This is because the other function creates a transaction on Ethereum, and will still need to be verified from every node. So view functions are only free when they’re called externally. | One of the more expensive operations in Solidity is using storage — particularly writes. This is because every time you write or change a piece of data, it’s written permanently to the blockchain. Forever! Thousands of nodes across the world need to store that data on their hard drives, and this amount of data keeps growing over time as the blockchain grows. So there’s a cost to doing that. In order to keep costs down, you want to avoid writing data to storage except when absolutely necessary. Sometimes this involves seemingly inefficient programming logic — like rebuilding an array in memory every time a function is called instead of simply saving that array in a variable for quick lookups. In most programming languages, looping over large data sets is expensive. But in Solidity, this is way cheaper than using storage if it’s in an external view function, since view functions don’t cost your users any gas. (And gas costs your users real money!). An example illustrating how to declare arrays in memory: function getArray() external pure returns(uint[] memory) { // Instantiate a new array in memory with a length of 3 uint[] memory values = new uint[](3); // Put some values to it values[0] = 1; values[1] = 2; values[2] = 3; return values; } . | for loops will be preferred over mapping solutions, if it can save gas cost. | . Solidity Code from Lesson 3: . ##ownable.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; /** * @title Ownable * @dev The Ownable contract has an owner address, and provides basic authorization control * functions, this simplifies the implementation of &quot;user permissions&quot;. */ contract Ownable { address private _owner; event OwnershipTransferred( address indexed previousOwner, address indexed newOwner ); /** * @dev The Ownable constructor sets the original `owner` of the contract to the sender * account. */ constructor() internal { _owner = msg.sender; emit OwnershipTransferred(address(0), _owner); } /** * @return the address of the owner. */ function owner() public view returns(address) { return _owner; } /** * @dev Throws if called by any account other than the owner. */ modifier onlyOwner() { require(isOwner()); _; } /** * @return true if `msg.sender` is the owner of the contract. */ function isOwner() public view returns(bool) { return msg.sender == _owner; } /** * @dev Allows the current owner to relinquish control of the contract. * @notice Renouncing to ownership will leave the contract without an owner. * It will not be possible to call the functions with the `onlyOwner` * modifier anymore. */ function renounceOwnership() public onlyOwner { emit OwnershipTransferred(_owner, address(0)); _owner = address(0); } /** * @dev Allows the current owner to transfer control of the contract to a newOwner. * @param newOwner The address to transfer ownership to. */ function transferOwnership(address newOwner) public onlyOwner { _transferOwnership(newOwner); } /** * @dev Transfers control of the contract to a newOwner. * @param newOwner The address to transfer ownership to. */ function _transferOwnership(address newOwner) internal { require(newOwner != address(0)); emit OwnershipTransferred(_owner, newOwner); _owner = newOwner; } } . zombiefactory.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./ownable.sol&quot;; contract ZombieFactory is Ownable { event NewZombie(uint zombieId, string name, uint dna); uint dnaDigits = 16; uint dnaModulus = 10 ** dnaDigits; uint cooldownTime = 1 days; struct Zombie { string name; uint dna; uint32 level; uint32 readyTime; } Zombie[] public zombies; mapping (uint =&gt; address) public zombieToOwner; mapping (address =&gt; uint) ownerZombieCount; function _createZombie(string memory _name, uint _dna) internal { uint id = zombies.push(Zombie(_name, _dna, 1, uint32(now + cooldownTime))) - 1; zombieToOwner[id] = msg.sender; ownerZombieCount[msg.sender]++; emit NewZombie(id, _name, _dna); } function _generateRandomDna(string memory _str) private view returns (uint) { uint rand = uint(keccak256(abi.encodePacked(_str))); return rand % dnaModulus; } function createRandomZombie(string memory _name) public { require(ownerZombieCount[msg.sender] == 0); uint randDna = _generateRandomDna(_name); randDna = randDna - randDna % 100; _createZombie(_name, randDna); } } . zombiefeeding.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./zombiefactory.sol&quot;; contract KittyInterface { function getKitty(uint256 _id) external view returns ( bool isGestating, bool isReady, uint256 cooldownIndex, uint256 nextActionAt, uint256 siringWithId, uint256 birthTime, uint256 matronId, uint256 sireId, uint256 generation, uint256 genes ); } contract ZombieFeeding is ZombieFactory { KittyInterface kittyContract; function setKittyContractAddress(address _address) external onlyOwner { kittyContract = KittyInterface(_address); } function _triggerCooldown(Zombie storage _zombie) internal { _zombie.readyTime = uint32(now + cooldownTime); } function _isReady(Zombie storage _zombie) internal view returns (bool) { return (_zombie.readyTime &lt;= now); } function feedAndMultiply(uint _zombieId, uint _targetDna, string memory _species) internal { require(msg.sender == zombieToOwner[_zombieId]); Zombie storage myZombie = zombies[_zombieId]; require(_isReady(myZombie)); _targetDna = _targetDna % dnaModulus; uint newDna = (myZombie.dna + _targetDna) / 2; if (keccak256(abi.encodePacked(_species)) == keccak256(abi.encodePacked(&quot;kitty&quot;))) { newDna = newDna - newDna % 100 + 99; } _createZombie(&quot;NoName&quot;, newDna); _triggerCooldown(myZombie); } function feedOnKitty(uint _zombieId, uint _kittyId) public { uint kittyDna; (,,,,,,,,,kittyDna) = kittyContract.getKitty(_kittyId); feedAndMultiply(_zombieId, kittyDna, &quot;kitty&quot;); } } . zombiehelper.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./zombiefeeding.sol&quot;; contract ZombieHelper is ZombieFeeding { // 1. Define levelUpFee here modifier aboveLevel(uint _level, uint _zombieId) { require(zombies[_zombieId].level &gt;= _level); _; } // 2. Insert levelUp function here function changeName(uint _zombieId, string calldata _newName) external aboveLevel(2, _zombieId) { require(msg.sender == zombieToOwner[_zombieId]); zombies[_zombieId].name = _newName; } function changeDna(uint _zombieId, uint _newDna) external aboveLevel(20, _zombieId) { require(msg.sender == zombieToOwner[_zombieId]); zombies[_zombieId].dna = _newDna; } function getZombiesByOwner(address _owner) external view returns(uint[] memory) { uint[] memory result = new uint[](ownerZombieCount[_owner]); uint counter = 0; for (uint i = 0; i &lt; zombies.length; i++) { if (zombieToOwner[i] == _owner) { result[counter] = i; counter++; } } return result; } } .",
            "url": "https://saxenism.com/web3/solidity/cryptozombies/beginner/2021/06/14/CryptoZombies-Lesson-3.html",
            "relUrl": "/web3/solidity/cryptozombies/beginner/2021/06/14/CryptoZombies-Lesson-3.html",
            "date": " • Jun 14, 2021"
        }
        
    
  
    
        ,"post13": {
            "title": "CryptoZombies - Lesson 2",
            "content": "Lesson 2: . Addresses: The ethereum blockchain is made up of accounts, which you can think of as bank accounts. An account has a balance of Ether, and you can send and recieve Ether payments to other accounts, just like your bank account can wire transfer money to other bank accounts Each bank account has an address which you can think of like a bank account number.Its a unique identifier that points to an account. An address is owned by a specific user or a smart contract. Mapping: So we can use it as a unique ID for ownership of our zombies. When a user creates new zombies by interacting with our app, we’ll set ownership of those zombies to the Ethereum address that called the function A mapping is essentially a key-value store for storing and looking up data mapping(uint =&gt; string) userIdToName; | msg.sender In solidity, there are certain global variables that are available to all functions. One of them is msg.sender msg.sender refers to the address of the person (or the smart contract) who called the current function In solidity, function execution always needs to start with an external caller. A contract will just sit on the blockchain doing nothing until someone calls one of its functions. So, there will always be a msg.sender | require is a keyword in Solidity used for condition checking. If this condition is met, then only a function is executed otherwise, it terminates with an error. Example: function sayHiToVitalik (string memory _name) public returns (string memory) { require(keccak256(abi.encodePacked(_name)) == keccak256(abi.encodePacked(&quot;Vitalik&quot;))); return &quot;Hi Vitalik, thank you for Ethereum!!&quot;; } . | Solidity does not support string comparison natively, so we simply compare the keccak256 hashes of the two strings. | Solidity supports inheritence. Hence, instead of writing one big long contract, it makes sense to split your code logic across multiple contracts to organize the code. | Really cool and succint inheritence syntax: contract cat is animal { } // Here the contract cat inherits from the contract animal :D . | Syntax to import one file into another: import &#39;./someOtherContract.sol&#39;; contract newContract is someOtherContract { } . | In solidity, there are two locations in which you can store variables - in storage and in memory. Storage refers to variables permanently stored on the blockchain. Memory variables are temporary, and are erased between external function calls to your contract. Think of it like a computer’s Hard Disk vs RAM Example: contract SandwichFactory { struct Sandwich { string name; string status; } Sandwich[] sandwiches; function eatSandwich(uint _index) public { // Sandwich mySandwich = sandwiches[_index]; // ^ Seems pretty straightforward, but solidity will give you a warning // telling you that you should explicitly declare storage or memory here. // So instead, you should declare with the storage keyword, like: Sandwich storage mySandwich = sandwiches[_index]; // ...in which case mySandwich is a pointer to sandwiches[_index] // in storage, and... mySandwich.status = &quot;Eaten!&quot;; // ...this will permanently change `sandwiches[_index]` on the blockchain. // If you just want a copy, you can use memory: Sandwich memory anotherSandwich = sandwiches[_index + 1]; // ...in which case anotherSandwich will simply be a copy of the // data in memory, and... anotherSandwich.status = &quot;Eaten!&quot;; // ...will just modify the temporary variable and have no effect // on sandwiches[_index + 1]. But you can do this: sandwiches[_index + 1] = anotherSandwich; // ...if you want to copy the changes back into blockchain storage. } } . | For a struct People such as: struct People { string name; uint age; } People randomMan = People(&quot;Sam&quot;, &quot;22&quot;); . You can access the properties of this struct as follows: randomMan.age or randomMan.name . | Types of functions in solidity: a. Private b. Internal c. Public d. External internal is the same as private, except that it’s also accessible to contracts that inherit from this contract. external is the same public, except that these functions can ONLY be called outside the contract. | Interacting with other smart contracts on the Ethereum blockchain: a. Define an interface (almost the same syntax as that of a contract, but only function signatures are mentioned here.) b. Only those function signatures need to be written in the interface, that we actually need to call c. Grab the address of the smart contract, you want to call the function from d. Initialise the interface you built with this address (much like creating an object) e. Example: contract NumberInterface { function getNum(address _myAddress) public view returns (uint); } contract MyContract { address NumberInterfaceAddress = 0xabcde122...... NumberInterface numberContract = NumberInterface(NumberInterfaceAddress); function someFunction() public { uint num = numberContract.getNum(msg.sender); } } . | In Solidity you can return more than one value from a function :D | This example illustrates, how we manage multiple return values from Solidity function: function multipleReturns() internal returns(uint a, uint b, uint c) { return (1, 2, 3); } function processMultipleReturns() external { uint a; uint b; uint c; // This is how you do multiple assignment: (a, b, c) = multipleReturns(); } // Or if we only cared about one of the values: function getLastReturnValue() external { uint c; // We can just leave the other fields blank: (,,c) = multipleReturns(); } . . | Solidity code from Lesson2 . zombiefactory.sol . pragma solidity &gt;= 0.8.4; contract ZombieFactory { event NewZombie(uint zombieId, string name, uint dna); uint dnaDigits = 16; uint dnaModulus = 10 ** dnaDigits; //(10^16) struct Zombie { string name; uint dna; } Zombie[] public zombies; mapping (uint =&gt; address) public zombieToOwner; mapping (address =&gt; uint) ownerZombieCount; function _createZombie(string memory _name, uint _dna) internal { zombies.push(Zombie(_name, _dna)); uint id = zombies.length - 1; zombieToOwner[id] = msg.sender; ownerZombieCount[msg.sender]++; emit NewZombie(id, _name, _dna); } function _generateRandomDna(string memory _str) private view returns (uint) { uint rand = uint(keccak256(abi.encodePacked(_str))); return rand % dnaModulus; } function createRandomZombie(string memory _name) public { require(ownerZombieCount[msg.sender] == 0); uint randDna = _generateRandomDna(_name); randDna = randDna - randDna % 100; _createZombie(_name, randDna); } } . zombiefeeding.sol . pragma solidity ^ 0.8.4; import &quot;lesson2_zombiefactory.sol&quot;; contract KittyInterface { function getKitty(uint256 _id) external view returns ( bool isGestating, bool isReady, uint256 cooldownIndex, uint256 nextActionAt, uint256 siringWithId, uint256 birthTime, uint256 matronId, uint256 sireId, uint256 generation, uint256 genes ); } contract ZombieFeeding is ZombieFactory { address ckAddress = 0x06012c8cf97BEaD5deAe237070F9587f8E7A266d; KittyInterface kittyContract = KittyInterface(ckAddress); function feedAndMultiply(uint _zombieId, uint _targetDna, string memory _species) public { require(msg.sender == zombieToOwner[_zombieId]); Zombie storage myZombie = zombies[_zombieId]; _targetDna = _targetDna % dnaModulus; uint newDna = (myZombie.dna + _targetDna) / 2; if (keccak256(abi.encodePacked(_species)) == keccak256(abi.encodePacked(&quot;kitty&quot;))) { newDna = newDna - newDna % 100 + 99; } _createZombie(&quot;NoName&quot;, newDna); } function feedOnKitty(uint _zombieId, uint _kittyId) public { uint kittyDna; (,,,,,,,,,kittyDna) = kittyContract.getKitty(_kittyId); feedAndMultiply(_zombieId, kittyDna, &quot;kitty&quot;); } } .",
            "url": "https://saxenism.com/web3/solidity/cryptozombies/beginner/2021/06/13/CryptoZombies-Lesson-2.html",
            "relUrl": "/web3/solidity/cryptozombies/beginner/2021/06/13/CryptoZombies-Lesson-2.html",
            "date": " • Jun 13, 2021"
        }
        
    
  
    
        ,"post14": {
            "title": "CryptoZombies - Lesson 1",
            "content": "Lesson 1: . Solidity code is encapsulated in contracts. A contract is the fundamental building block of Ethereum applications. All variables and functions belong to a contract and this will be the starting point of all projects | State Variables: Permanently stored in contract storage (they are written to the Ethereum Blockchain) Think of declaring state variables like writing to a DB | Arithmetic operations: x+y, x-y, x*y, x/y, x%y, x**y(same as x^y) | structs struct Person { uint age; string name; } . | Arrays {Possible to create an array of structs as well as native data types} Fixed arrays -&gt; uint [2] fixedArr Dynamic arrays -&gt; uint [] dynamicArr If an array is declared as public, other contracts can read from but not write to this array | function createZombies (string memory _name, uint _dna) public { underscore is a naming convention to separate the private variables from the global variables(_name) } . Notice the word memory along with the string parameter, it signifies that _name would be memory and not in stack, therefore would not be written to the blockchain, hence cheaper The memory keyword is required for reference type varialbles: arrays, structs, mapping, strings, etc. . | Pushing to the array: Person Satoshi = Person(172, &quot;Satoshi&quot;); people.push(Satoshi); . | In solidity, all functions are public by default. Good practice is to intially make all the functions private and then only make public the functions you want to expost to the world Convetion to start private functions with underscore (function _generateZombieID()) | Return values function sayHello() public returns (string memory) { } . If a function does not change any values, we can term it as a view function. [function sayHello() public view returns (string memory) {}] Pure functions =&gt; not accessing any data from the contract. . | Keccak256 and typecasting: Ethereum has the hash function keccak 256 built-in, which is a version of SHA3. keccak256 expects a single parameter of type bytes This means we have to “pack” any parameter before calling keccak256 | Compiler supports typecasting var = uint8(var) =&gt; This shit | Events are a way for your contract to communicate to your app front-end that something has happened on the blockchain, which can be listening for certain events and take actions when they happen Example declaration: event IntegersAdded(uint x, uint y, uint result); //Include input and ouputs to a function function add(uint _x, uint _y) public returns (uint) { uint result = _x + _y; emit IntegersAdded(_x, _y, result); return result; } . | . Solidity code from Lesson 1 . pragma solidity ^ 0.8.0; contract ZombieWorld { event NewZomie(uint zombieId, string name, uint dna); uint dnaDigits = 16; uint dnaModulus = 10 ** dnaDigits; struct Zombie { string name; uint dna; } Zombie[] public zombies; function _createZombie(string memory _name, uint _dna) private { zombies.push(Zombie(_name, _dna)); uint id = zombies.length - 1; emit NewZomie(id, _name, _dna); } function _generateRandomDna(string memory _str) private view returns (uint) { uint rand = uint(keccak256(abi.encodePacked(_str))); return rand % dnaModulus; } function createRandomZombie(string memory _name) public { uint randDna = _generateRandomDna(_name); _createZombie(_name, randDna); } } .",
            "url": "https://saxenism.com/web3/solidity/cryptozombies/beginner/2021/06/12/Cryptozombies-Lesson-1.html",
            "relUrl": "/web3/solidity/cryptozombies/beginner/2021/06/12/Cryptozombies-Lesson-1.html",
            "date": " • Jun 12, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Blockchain Engineer &amp; Consultant . A curious tinkerer, madly in love with the decentralised universe . A few things about me: . (Ex) Full-Stack Blockchain engineer @ sublime.finance | Consulted with a decentralised freelancing platform. Took the project from idea to contract deployment :P | Winner @ NFTHack2022 under Best use of Harmony NFT bridge | Winner of Creator Track @ Solana Building Out Loud hackathon | Ethereum India Fellow (v 2.0) under Track 1 | Solana Global Breakpoint Fellow @ Lisbon 2021 | Runner Up @ EtherPunk 2021. Awarded SuperFluid bounties | Won Filecoin,Polygon,NFTPort,Covalent,Livepeer &amp; Sublime prizes | Experienced with serverless development (Cloudflare) and twitter APIs | Authored Solana Anchor tutorials promoted by Solana Labs itself | Creating educational blockchain development tutorials | Mentor @ Sublime Finance in the ETHOnline 2021 hackathon | GSoC ‘21 &amp; ‘20 student dev with the R Project | Research Paper @ Biodiversity Information Science &amp; Standards. Link to paper | Azure AZ-900 certified cloud guy &gt;.&lt; | Published tech-author with leading Medium publications | Mentoring 200+ budding developers and helping navigate OSS | Multiple deployed MERN-stack and Flutter projects | Cyber Security Awareness speaker for CDAC and ISEA | Co-founder: Information Security Society of IIIT Bhubaneswar | Trained 250+ students in basics of cyber security | . Hit me up (on Twitter preferably) if you want to work with me or simply want to discuss why Black Clover is a GOATED modern-day classic. . See you around. .",
          "url": "https://saxenism.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://saxenism.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}